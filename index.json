[{"uri":"https://duykhanh07.github.io/workshop-fcaj/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"AWS Transfer Family SFTP connectors now support VPC-based connectivity Many organizations rely on the Secure File Transfer Protocol (SFTP) as the industry standard for exchanging critical business data. Traditionally, securely connecting to private SFTP servers required custom infrastructure, manual scripting, or exposing endpoints to the public internet.\nToday, AWS Transfer Family SFTP connectors now support connectivity to remote SFTP servers through Amazon Virtual Private Cloud (Amazon VPC) environments. You can transfer files between Amazon Simple Storage Service (Amazon S3) and private or public SFTP servers while applying the security controls and network configurations already defined in your VPC. This capability helps you integrate data sources across on-premises environments, partner-hosted private servers, or internet-facing endpoints, with the operational simplicity of a fully managed Amazon Web Services (AWS) service.\nNew capabilities with SFTP connectors The following are the key enhancements:\nConnect to private SFTP servers – SFTP connectors can now reach endpoints that are only accessible within your AWS VPC connection. These include servers hosted in your VPC or a shared VPC, on-premises systems connected over AWS Direct Connect, and partner-hosted servers connected through VPN tunnels. Security and compliance – All file transfers are routed through the security controls already applied in your VPC, such as AWS Network Firewall or centralized ingress and egress inspection. Private SFTP servers remain private and don’t need to be exposed to the internet. You can also present static Elastic IP or bring your own IP (BYOIP) addresses to meet partner allowlist requirements. Performance and simplicity – By using your own network resources such as NAT gateways, AWS Direct Connect or VPN connections, connectors can take advantage of higher bandwidth capacity for large-scale transfers. You can configure connectors in minutes through the AWS Management Console, AWS Command Line Interface (AWS CLI), or AWS SDKs without building custom scripts or third-party tools. How VPC- based SFTP connections work SFTP connectors use Amazon VPC Lattice resources to establish secure connectivity through your VPC. Key constructs include a resource configuration and a resource gateway. The resource configuration represents the target SFTP server, which you specify using a private IP address or public DNS name. The resource gateway provides SFTP connector access to these configurations, enabling file transfers to flow through your VPC and its security controls.\nThe following architecture diagram illustrates how traffic flows between Amazon S3 and remote SFTP servers.\nAs shown in the architecture, traffic flows from Amazon S3 through the SFTP connector into your VPC. A resource gateway is the entry point that handles inbound connections from the connector to your VPC resources. Outbound traffic is routed through your configured egress path, using Amazon VPC NAT gateways with Elastic IPs for public servers or AWS Direct Connect and VPN connections for private servers. You can use existing IP addresses from your VPC CIDR range, simplifying partner server allowlists. Centralized firewalls in the VPC enforce security policies, and customer-owned NAT gateways provide higher bandwidth for large-scale transfers.\nWhen to use this feature With this capability, developers and IT administrators can simplify workflows while meeting security and compliance requirements across a range of scenarios:\nHybrid environments – Transfer files between Amazon S3 and on-premises SFTP servers using AWS Direct Connect or AWS Site-to-Site VPN, without exposing endpoints to the internet. Partner integrations – Connect with business partners’ SFTP servers that are only accessible through private VPN tunnels or shared VPCs. This avoids building custom scripts or managing third-party tools, reducing operational complexity. Regulated industries – Route file transfers through centralized firewalls and inspection points in VPCs to comply with financial services, government, or healthcare security requirements. High-throughput transfers – Use your own network configurations such as NAT gateways, AWS Direct Connect, or VPN connections with Elastic IP or BYOIP to handle large-scale, high-bandwidth transfers while retaining IP addresses already on partner allowlists. Unified file transfer solution – Standardize on Transfer Family for both internal and external SFTP connectivity, reducing fragmentation across file transfer tools. Start building with SFTP connectors To begin transferring files with SFTP connectors through my VPC environment, I follow these steps:\nFirst, I configure my VPC Lattice resources. In the Amazon VPC console, under PrivateLink and Lattice in the navigation pane, I choose Resource gateways, choose Create resource gateway to create one to act as the ingress point into my VPC.\nNext, under PrivateLink and Lattice in the navigation pane, I choose Resource configuration and choose Create resource configuration to create a resource configuration for my target SFTP server. Specify the private IP address or public DNS name, and the port (typically 22).\nThen, I configure AWS Identity and Access Management (IAM) permissions. I ensure that the IAM role used for connector creation has transfer:* permissions, and VPC Lattice permissions (vpc-lattice:CreateServiceNetworkResourceAssociation, vpc-lattice:GetResourceConfiguration, vpc-lattice:AssociateViaAWSService). I update the trust policy on the IAM role to specify transfer.amazonaws.com as a trusted principal. This enables AWS Transfer Family to assume the role when creating and managing my SFTP connectors.\nAfter that, I create an SFTP connector through the AWS Transfer Family console. I choose SFTP Connectors and then choose Create SFTP connector.\nIn the Connector configuration section, I select VPC Lattice as the egress type, then provide the Amazon Resource Name (ARN) of the Resource Configuration, Access role, and Connector credentials. Optionally, include a trusted host key for enhanced security, or override the default port if my SFTP server uses a nonstandard port.\nNext, I test the connection. On the Actions menu, I choose Test connection to confirm that the connector can reach the target SFTP server.\nFinally, after the connector status is ACTIVE, I can begin file operations with my remote SFTP server programmatically by calling Transfer Family APIs such as StartDirectoryListing, StartFileTransfer, StartRemoteDelete, or StartRemoteMove. All traffic is routed through my VPC using my configured resources such as NAT gateways, AWS Direct Connect, or VPN connections together with my IP addresses and security controls.\nFor the complete set of options and advanced workflows, refer to the AWS Transfer Family documentation.\nNow available SFTP connectors with VPC-based connectivity are now available in 21 AWS Regions. Check the AWS Services by Region for the latest supported AWS Regions. You can now securely connect AWS Transfer Family SFTP connectors to private, on-premises, or internet-facing servers using your own VPC resources such as NAT gateways, Elastic IPs, and network firewalls.\n— Betty\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"AWS Weekly Roundup: Amazon Quick Suite, Amazon EC2, Amazon EKS, and more (October 13, 2025) This week I was at the inaugural AWS AI in Practice meetup from the AWS User Group UK. AI-assisted software development and agents were the focus of the evening! Next week I’ll be in Italy for Codemotion (Milan) and an AWS User Group meetup (Rome). My sessions there will be about AI agents and context engineering. I am also excited to try the new Amazon Quick Suite that brings AI-powered research, business intelligence, and automation capabilities into a single workspace.\nLast week’s launches Here are the launches that got my attention this week:\nAmazon Quick Suite – A new agentic teammate that quickly answers your questions at work and turns those insights into actions for you. Read more in Esra’s launch post. Amazon EC2 – General-purpose M8a instances powered by the 5th Generation AMD EPYC (codename Turin) processors and compute-optimized C8i and C8i-flex instances powered by custom Intel Xeon 6 processors are now available. Amazon EKS – EKS and EKS Distro now support Kubernetes version 1.34 with several improvements. AWS IAM Identity Center – AWS Key Management Service keys can now be used to encrypt identity data stored in IAM Identity Center organization instances. Amazon VPC Lattice – You can now configure the number of IPv4 addresses assigned to resource gateway elastic network interfaces (ENIs). The IPv4 addresses are used for network address translation and determine the maximum number of concurrent IPv4 connections to a resource Amazon Q Developer – Amazon Q Developer can help you get information about AWS product and service pricing, availability, and attributes, making it easier to select the right resources and estimate workload costs using natural language. More info in this blog post. Amazon RDS for Db2 – You can now perform native database-level backups, offering greater flexibility in database management and migration. AWS Service Quotas – Get notified of your quota usage with automatic quota management. Configure your preferred notifications channels, such as email, SMS, or Slack. Notifications are also available in AWS Health, and you can subscribe to related AWS Cloudtrail events for automation workflows. Amazon Connect – You can now programmatically enrich case data with the new case APIs to link related cases, add custom related items, and search across them. You can now also customize service level calculations to your specific needs. New capabilities that have just been introduced include copy and bulk edit of agent scheduling configuration and agent schedule adherence notifications. AWS Client VPN – Now supports MacOS Tahoe. Additional updates Here are some additional projects, blog posts, and news items that I found interesting:\nServerless ICYMI Q3 2025 – A quarterly recap of serverless news, in case you missed it. Best practices for migrating from Apache Airflow 2.x to Apache Airflow 3.x on Amazon MWAA – A guide to help get the benefit of the new release. Building self-managed RAG applications with Amazon EKS and Amazon S3 Vectors – A reference architecture for building and deploying a self-managed RAG application using open source tools such as Ray, Hugging Face, and LangChain. BBVA: Building a multi-region, multi-country global Data and ML Platform at scale – A six-part series of posts describing the journey to transform BBVA entire data analytics infrastructure with one of the largest and most complex cloud migrations in the banking sector. Customizing text content moderation with Amazon Nova – Fine-tune Amazon Nova for content moderation tasks tailored to your requirements using domain-specific training data and organization-specific moderation guidelines. Upcoming AWS events Check your calendars so that you can sign up for these upcoming events:\nAWS AI Agent Global Hackathon – This is your chance to dive deep into our powerful generative AI stack and create something truly awesome. From September 8th to October 20th, you have the opportunity to create AI agents using AWS suite of AI services, competing for over $45,000 in prizes and exclusive go-to-market opportunities. AWS Gen AI Lofts – You can learn AWS AI products and services with exclusive sessions, meet industry-leading experts, and have valuable networking opportunities with investors and peers. Register in your nearest city: Paris (October 7–21), London (Oct 13–21), and Tel Aviv (November 11–19). AWS Community Days – Join community-led conferences that feature technical discussions, workshops, and hands-on labs led by expert AWS users and industry leaders from around the world: Budapest (October 16). Join the AWS Builder Center to learn, build, and connect with builders in the AWS community. Browse here upcoming in-person events, developer-focused events, and events for startups.\nThat’s all for this week. Check back next Monday for another Weekly Roundup!\n– Danilo\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Announcing Amazon Quick Suite: your agentic teammate for answering questions and taking action Today, we’re announcing Amazon Quick Suite, a new agentic teammate that quickly answers your questions at work and turns those insights into actions for you. Instead of switching between multiple applications to gather data, find important signals and trends, and complete manual tasks, Quick Suite brings AI-powered research, business intelligence, and automation capabilities into a single workspace. You can now analyze data through natural language queries, find critical information across enterprise and external sources in minutes, and automate processes from simple tasks to complex multi-department workflows.\nHere’s a look into Quick Suite.\nBusiness users often need to gather data across multiple applications—pulling customer details, checking performance metrics, reviewing internal product information, and performing competitive intelligence. This fragmented process often requires consultation with specialized teams to analyze advanced datasets, and in some cases, must be repeated regularly, reducing efficiency and leading to incomplete insights for decision-making.\nQuick Suite helps you overcome these challenges by combining agentic teammates for research, business intelligence, and automation into a unified digital workspace for your day-to-day work.\nIntegrated capabilities that power productivity Quick Suite includes the following integrated capabilities:\nResearch – Quick Research accelerates complex research by combining enterprise knowledge, premium third-party data, and data from the internet for more comprehensive insights. Business intelligence – Quick Sight provides AI-powered business intelligence capabilities that transform data into actionable insights through natural language queries and interactive visualizations, helping everyone make faster decisions and achieve better business outcomes. Automation – Quick Flows and Quick Automate help users and technical teams to automate any business process from simple, routine tasks to complex multi-department workflows, enabling faster execution and reducing manual work across the organization. Let’s dive into some of these key capabilities.\nQuick Index: Your unified knowledge foundation Quick Index creates a secure, searchable repository that consolidates documents, files, and application data to power AI-driven insights and responses across your organization.\nAs a foundational component of Quick Suite, Quick Index operates in the background to bring together all your data—from databases and data warehouses to documents and email. This creates a single, intelligent knowledge base that makes AI responses more accurate and reduces time spent searching for information.\nQuick Index automatically indexes and prepares any uploaded files or unstructured data you add to your Quick Suite, enabling efficient searching, sorting, and data access. For example, when you search for a specific project update, Quick Index instantly returns results from uploaded documents, meeting notes, project files, and reference materials—all from one unified search instead of checking different repositories and file systems.\nTo learn more, visit the Quick Index overview page.\nQuick Research: From complex business challenges to expert-level insights Quick Research is a powerful agent that conducts comprehensive research across your enterprise data and external sources to deliver contextualized, actionable insights in minutes or hours — work that previously could take longer.\nQuick Research systematically breaks down complex questions into organized research plans. Starting with a simple prompt, it automatically creates detailed research frameworks that outline the approach and data sources needed for comprehensive analysis.\nAfter Quick Research creates the plan, you can easily refine it through natural language conversations. When you are happy with the plan, it works in the background to gather information from multiple sources, using advanced reasoning to validate findings and provide thorough analysis with citations.\nQuick Research integrates with your enterprise data connected to Quick Suite, the unified knowledge foundation that connects to your dashboards, documents, databases, and external sources, including Amazon S3, Snowflake, Google Drive, and Microsoft SharePoint. Quick Research grounds key insights to original sources and reveals clear reasoning paths, helping you verify accuracy, understand the logic behind recommendations, and present findings with confidence. You can trace findings back to their original sources and validate conclusions through source citations. This makes it ideal for complex topics requiring in-depth analysis.\nTo learn more, visit the Quick Research overview page.\nQuick Sight: AI-powered business intelligence Quick Sight provides AI-powered business intelligence capabilities that transform data into actionable insights through natural language queries and interactive visualizations.\nYou can create dashboards and executive summaries using conversational prompts, reducing dashboard development time while making advanced analytics accessible without specialized skills.\nQuick Sight helps you ask questions about your data in natural language and receive instant visualizations, executive summaries, and insights. This generative AI integration provides you with answers from your dashboards and datasets without requiring technical expertise.\nUsing the scenarios capability, you can perform what-if analysis in natural language with step-by-step guidance, exploring complex business scenarios and finding answers faster than before.\nAdditionally, you can respond to insights with one-click actions by creating tickets, sending alerts, updating records, or triggering automated workflows directly from your dashboards without switching applications.\nTo learn more, visit Quick Sight overview page.\nQuick Flows: Automation for everyone With Quick Flows, any user can automate repetitive tasks by describing their workflow using natural language without requiring any technical knowledge. Quick Flows fetches information from internal and external sources, takes action in business applications, generates content, and handles process-specific requirements.\nStarting with straightforward business requirements, it creates a multi-step flow including input steps for gathering information, reasoning groups for AI-powered processing, and output steps for generating and presenting results.\nAfter the flow is configured, you can share it with a single click to your coworkers and other teams. To execute the flow, users can open it from the library or invoke it from chat, provide the necessary inputs, and then chat with the agent to refine the outputs and further customize the results.\nTo learn more, visit the Quick Flows overview page.\nQuick Automate: Enterprise-scale process automation Quick Automate helps technical teams build and deploy sophisticated automation for complex, multistep processes that span departments, systems, and third-party integrations. Using AI-powered natural language processing, Quick Automate transforms complex business processes into multi-agent workflows that can be created merely by describing what you want to automate or uploading process documentation.\nWhile Quick Flows handles straightforward workflows, Quick Automate is designed for comprehensive and complex business processes like customer onboarding, procurement automations, or compliance procedures that involve multiple approval steps, system integrations, and cross-departmental coordination. Quick Automate offers advanced orchestration capabilities with extensive monitoring, debugging, versioning, and deployment features.\nQuick Automate then generates a comprehensive automation plan with detailed steps and actions. You will find a UI agent that understands natural language instructions to autonomously navigate websites, complete form inputs, extract data, and produces structured outputs for downstream automation steps.\nAdditionally, you can define a custom agent, complete with instructions, knowledge, and tools, to complete process-specific tasks using the visual building experience – no code required.\nQuick Automate includes enterprise-grade features such as user role management and human-in-the-loop capabilities that route specific tasks to users or groups for review and approval before continuing workflows. The service provides comprehensive observability with real-time monitoring, success rate tracking, and audit trails for compliance and governance.\nTo learn more, visit the Quick Automate overview page.\nAdditional foundational capabilities Quick Suite includes other foundational capabilities that deliver seamless data organization and contextual AI interactions across your enterprise.\nSpaces – Spaces provide a straightforward way for every business user to add their own context by uploading files or connecting to specific datasets and repositories specific to their work or to a particular function. For example, you might create a space for quarterly planning that includes budget spreadsheets, market research reports, and strategic planning documents. Or you could set up a product launch space that connects to your project management system and customer feedback databases. Spaces can scale from personal use to enterprise-wide deployment while maintaining access permissions and seamless integration with Quick Suite capabilities.\nChat agents – Quick Suite includes insights agents that you can use to interact with your data and workflows through natural language. Quick Suite includes a built-in agent to answer questions across all of your data and custom chat agents that you can configure with specific expertise and business context. Custom chat agents can be tailored for particular departments or use cases—such as a sales agent connected to your product catalog data and pricing information stored in a space or a compliance agent configured with your regulatory requirements and actions to request approvals.\nAdditional things to know If you’re an existing Amazon QuickSight customer – Amazon QuickSight customers will be upgraded to Quick Suite, a unified digital workspace that includes all your existing QuickSight business intelligence capabilities (now called “Quick Sight”) plus new agentic AI capabilities. This is an interface and capability change—your data connectivity, user access, content, security controls, user permissions, and privacy settings remain exactly the same. No data is moved, migrated, or changed.\nQuick Suite offers per-user subscription-based pricing with consumption-based charges for the Quick Index and other optional features. You can find more detail on the Quick Suite pricing page.\nNow available Amazon Quick Suite gives you a set of agentic teammates that helps you get the answers you need using all your data and move instantly from answers to action so you can focus on high value activities that drive better business and customer outcomes.\nVisit the getting started page to start using Amazon Quick Suite today.\nHappy building — Esra and Donnie\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Summary Report: “AWS First Cloud Journey Workforce OJT Fall 2025 Kick-off” Event Objectives Launch the AWS First Cloud Journey Workforce OJT Fall 2025 program Provide students with exposure to international-standard working environments Share best practices in Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics Connect students with AWS experts, alumni, and partner companies Speakers Nguyễn Trần Phước Bảo – Head of Corporate Relations, FPT University Nguyễn Gia Hưng – Head of Solutions Architect, AWS Vietnam Đỗ Huy Thắng – DevOps Lead, VNG Danh Hoàng Hiếu Nghị – GenAI Engineer, Renova Bùi Hồ Linh Nhi – AI Engineer, SoftwareOne Phạm Nguyễn Hải Anh – Cloud Engineer, G-Asia Pacific Nguyễn Đồng Thanh Hiệp – Principal Cloud Engineer, G-Asia Pacific Key Highlights Importance of OJT Kick-off Marks the official start of the Fall 2025 OJT program at AWS Bitexco Financial Tower Provides students with opportunities to learn, practice, and grow in a professional environment Insights from Experts Nguyễn Gia Hưng: Shared an overview of OJT at AWS and offered valuable career guidance Đỗ Huy Thắng: Delivered an inspiring talk on DevOps, highlighting its growth potential in Vietnam and globally Alumni: Shared real-world experiences, motivating students to embrace challenges with confidence Program Background Started in 2021, supporting over 2,000 students nationwide More than 150 graduates now working at leading tech companies in Vietnam and abroad Core mission: Build a high-quality generation of AWS Builders for Vietnam Connects students with AWS Study Group (47,000+ members) and partner enterprises Key Takeaways Student Benefits Gain hands-on experience in Cloud, DevOps, AI/ML, Security, Data \u0026amp; Analytics Learn professional working styles aligned with international standards Build networks with AWS experts, alumni, and partner companies Career Development Exposure to real-world case studies and industry best practices Opportunities to join top technology firms after graduation Encouragement to adopt a growth mindset and pursue continuous learning Applying to Work Practice Cloud skills through AWS OJT projects Explore DevOps as a career path with global opportunities Leverage alumni insights to prepare for challenges in professional environments Engage with AWS Study Group for ongoing learning and networking Event Experience Attending the AWS First Cloud Journey Workforce OJT Fall 2025 Kick-off was highly inspiring. Students experienced:\nLearning from experts Practical advice from AWS architects and industry leaders Real-world DevOps insights that broadened perspectives on career opportunities Hands-on exposure Understanding the importance of soft skills alongside technical expertise Learning how to adapt to international-standard work environments Networking Direct interaction with alumni who shared authentic OJT experiences Building connections with AWS experts and partner companies Lessons learned OJT is not only about technical training but also about personal growth Collaboration between universities and enterprises creates strong career pathways With the right mindset, students can achieve meaningful success in the tech industry Overall, the kick-off event provided both technical knowledge and motivational insights, empowering FPT University students to embark on their OJT journey with confidence and ambition.\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Le Duy Khanh\nPhone Number: 0389430144\nEmail: ldk11072003@gmail.com\nUniversity: Sai Gon University\nMajor: Information Technology\nClass: DCT1216\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 30/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.1-workshop-overview/","title":"Introduction","tags":[],"description":"","content":"1. What is the \u0026ldquo;AI Career Coach\u0026rdquo; Application? AI Career Coach is a platform designed to support job seekers, leveraging the power of Generative AI to streamline the most time-consuming tasks in the application process.\nBelow are the 4 main feature modules that we will build:\nA. Dashboard Where users get an overview of their industry/profession.\nB. AI Resume Builder An AI-integrated Markdown editor. Users input raw information, and the AI helps rephrase work experience descriptions to be professional and ATS (Applicant Tracking System) compliant.\nC. Cover Letter Generator Users only need to provide: \u0026ldquo;Job Position\u0026rdquo;, \u0026ldquo;Company Name\u0026rdquo;, and \u0026ldquo;Job Description (JD)\u0026rdquo;. The system will call Claude 3 to write a persuasive cover letter, personalized to that specific JD.\nD. Mock Interview The most interesting feature. The system generates multiple-choice questions based on the user\u0026rsquo;s industry. After the user answers, the system scores the performance and provides improvement advice.\n2. System Architecture This is the \u0026ldquo;backbone\u0026rdquo; of the workshop. We will apply a fully Serverless architecture on AWS.\nPlease look at the data flow diagram below:\nData Flow Analysis: Frontend Hosting: React source code (built) is stored on Amazon S3 and distributed globally via Amazon CloudFront to ensure the fastest page load speeds. Authentication: Users log in via Amazon Cognito. The Frontend receives a JWT Token to authenticate requests sent to the Server. API Routing: Amazon API Gateway acts as the entry point, receiving HTTP Requests from the Frontend, checking the Token (Authorizer), and routing to the correct handling Lambda Function. Backend Logic (Compute): We use 5 AWS Lambda functions written in Java 17 (Spring Cloud Function). Each function handles a distinct business logic (Microservices pattern). Database: Data is stored in Amazon DynamoDB using Single Table Design (sharing 1 table for User, Resume, Interview, etc.), optimized for extremely fast read/write performance. AI Integration: Lambda Functions requiring intelligence will call Amazon Bedrock to interact with the Claude 3 Haiku model. 3. Why Choose This Tech Stack? Why combine Java Spring Boot with Serverless?\nJava \u0026amp; Spring Cloud Function: Java is a popular enterprise language. Spring Cloud Function helps Java developers easily transition familiar Spring Boot code to a Serverless environment without relearning from scratch. AWS Lambda \u0026amp; SnapStart: Previously, Java was criticized for slow startup (Cold Start). With Lambda SnapStart, our Java code will start extremely fast, almost instantly. DynamoDB Single Table: This is an advanced DB design technique that helps reduce costs and increase query speed by minimizing data joins (which do not exist in NoSQL). Bedrock: Instead of managing expensive GPU servers to run AI, Bedrock provides an API to call top-tier models (like Claude, Llama) on a Serverless basis (pay-as-you-go). 4. Source Code Structure This project is organized as a Monorepo (containing both Frontend and Backend in the same repository) for easy management during the workshop.\nbackend/: Contains Java Spring Boot source code. frontend/: Contains React Vite source code. template.yaml: The Infrastructure as Code definition file for AWS SAM. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.4-backend-development/5.4.1-user-functions/","title":"User Functions","tags":[],"description":"","content":"In this lesson, we will build the first module: User Profile Management (User Profile).\nWe will follow the standard Spring Boot process:\nModel: Define data structure. Repository: Interact with DynamoDB. Service: Handle business logic. Function: Receive requests from API Gateway. 1. Model (Entity Layer) First, we need to map the Java object to the table in DynamoDB.\nWe use the Annotations of the AWS SDK v2 Enhanced Client.\n@Data @DynamoDbBean @NoArgsConstructor @AllArgsConstructor public class UserEntity { private String pk; // Format: USER#\u0026lt;cognito_sub\u0026gt; private String sk; // Format: METADATA // Core fields private String email; private String name; private String imageUrl; private String industry; // Link tới IndustryInsight (Lưu dạng chuỗi text) // Profile fields private String bio; private Integer experience; private List\u0026lt;String\u0026gt; skills; // DynamoDB hỗ trợ List\u0026lt;String\u0026gt; tự động // Timestamps (Lưu dạng ISO String cho dễ đọc: \u0026#34;2025-11-30T10:00:00Z\u0026#34;) private String createdAt; private String updatedAt; @DynamoDbPartitionKey @DynamoDbAttribute(\u0026#34;PK\u0026#34;) public String getPk() { return pk; } @DynamoDbSortKey @DynamoDbAttribute(\u0026#34;SK\u0026#34;) public String getSk() { return sk; } } Key Strategy:\nPK: USER#{userId} (Groups data by User). SK: METADATA (Identifies this as profile information). 2. Repository (Data Access Layer) This class is responsible for \u0026ldquo;talking\u0026rdquo; to DynamoDB.\nInherits from the parent class AbstractDynamoRepository\n@Repository public class UserRepository extends AbstractDynamoRepository\u0026lt;UserEntity\u0026gt; { public UserRepository(DynamoDbEnhancedClient client) { // Truyền Class type để Abstract Repository biết map vào object nào super(client, UserEntity.class); } } 3. Service (Business Logic Layer) This is where the business logic is contained.\n@Service public class UserService { private static final Logger logger = LoggerFactory.getLogger(UserService.class); // Định nghĩa các hằng số Key Pattern để tránh Hardcode rải rác private static final String USER_PK_PREFIX = \u0026#34;USER#\u0026#34;; private static final String METADATA_SK = \u0026#34;METADATA\u0026#34;; private final UserRepository userRepository; // Constructor Injection public UserService(UserRepository userRepository) { this.userRepository = userRepository; } /** * Lấy thông tin User Profile */ public UserEntity getUserProfile(String userId) { // 1. Validator: Kiểm tra đầu vào validateUserId(userId); // 2. Tạo Key chuẩn Single Table Design String pk = USER_PK_PREFIX + userId; logger.debug(\u0026#34;Fetching profile for user: {}\u0026#34;, userId); // 3. Gọi Repository (Đã có sẵn hàm findById) return userRepository.findById(pk, METADATA_SK); } /** * Cập nhật (hoặc tạo mới) User Profile */ public UserEntity updateUserProfile(String userId, String email, UpdateUserRequest request) { // 1. Validator validateUserId(userId); if (request == null) { throw new IllegalArgumentException(\u0026#34;Update request cannot be null\u0026#34;); } logger.info(\u0026#34;Processing profile update for user: {}\u0026#34;, userId); // 2. Lấy user cũ để kiểm tra tồn tại UserEntity user = getUserProfile(userId); // 3. Logic: Create if not exists (Upsert) if (user == null) { logger.info(\u0026#34;User not found via ID {}, creating new profile...\u0026#34;, userId); if (email == null || email.isEmpty()) { logger.warn(\u0026#34;Creating new user but Email is missing!\u0026#34;); } user = new UserEntity(); user.setPk(USER_PK_PREFIX + userId); user.setSk(METADATA_SK); user.setCreatedAt(Instant.now().toString()); user.setEmail(email); // Chỉ set email khi tạo mới } // 4. Mapping dữ liệu từ DTO sang Entity (Chỉ update nếu có dữ liệu) boolean isUpdated = false; if (hasValue(request.getIndustry())) { user.setIndustry(request.getIndustry()); isUpdated = true; } if (hasValue(request.getBio())) { user.setBio(request.getBio()); isUpdated = true; } if (request.getExperience() != null) { user.setExperience(request.getExperience()); isUpdated = true; } if (request.getSkills() != null \u0026amp;\u0026amp; !request.getSkills().isEmpty()) { user.setSkills(request.getSkills()); isUpdated = true; } // 5. Lưu xuống DB user.setUpdatedAt(Instant.now().toString()); // Dùng hàm save của Repository (nó sẽ log debug bên trong) userRepository.save(user); logger.info(\u0026#34;Profile updated successfully for user: {}\u0026#34;, userId); return user; } // Thêm hàm này vào UserService.java public Map\u0026lt;String, Boolean\u0026gt; checkOnboardingStatus(String userId) { // 1. Validator input if (userId == null || userId.trim().isEmpty()) { logger.error(\u0026#34;CheckOnboardingStatus failed: UserId is null/empty\u0026#34;); throw new IllegalArgumentException(\u0026#34;User ID required\u0026#34;); } // 2. Tạo Key chuẩn String pk = \u0026#34;USER#\u0026#34; + userId; String sk = \u0026#34;METADATA\u0026#34;; logger.info(\u0026#34;Checking onboarding status for User: {}\u0026#34;, userId); // 3. Gọi Repo lấy User UserEntity user = userRepository.findById(pk, sk); // 4. Logic kiểm tra (Giống hệt logic if(!user) throw Error trong JS của bạn) if (user == null) { logger.warn(\u0026#34;User not found in DB: {}\u0026#34;, userId); throw new RuntimeException(\u0026#34;User not found\u0026#34;); } // 5. Logic xác định isOnboarded (Có industry = đã onboard) boolean isOnboarded = user.getIndustry() != null \u0026amp;\u0026amp; !user.getIndustry().trim().isEmpty(); logger.info(\u0026#34;User {} onboarding status: {}\u0026#34;, userId, isOnboarded); return Map.of(\u0026#34;isOnboarded\u0026#34;, isOnboarded); } // --- Helper Methods --- private void validateUserId(String userId) { if (userId == null || userId.trim().isEmpty()) { logger.error(\u0026#34;Validation failed: UserId is null or empty\u0026#34;); throw new IllegalArgumentException(\u0026#34;UserId cannot be null or empty\u0026#34;); } } private boolean hasValue(String value) { return value != null \u0026amp;\u0026amp; !value.trim().isEmpty(); } } 4. Function (Controller Layer) Finally, we write the Lambda Handler to receive HTTP Requests from API Gateway, extract information, and call the Service.\n@Configuration public class UserFunctions { private static final Logger logger = LoggerFactory.getLogger(UserFunctions.class); private final UserService userService; private final ObjectMapper objectMapper; public UserFunctions(UserService userService) { this.userService = userService; this.objectMapper = new ObjectMapper(); this.objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); this.objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); } //Hàm tổng (ROUTER FUNCTION) để điều phối @Bean public Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; profileHandler() { return event -\u0026gt; { try { // 1. Lấy thông tin cơ bản String httpMethod = extractHttpMethod(event); String path = extractPath(event); // \u0026lt;--- Hàm mới để lấy path logger.info(\u0026#34;Routing Request -\u0026gt; Path: {}, Method: {}\u0026#34;, path, httpMethod); Map\u0026lt;String, String\u0026gt; headers = normalizeHeaders(event); String userId = extractUserIdOrThrow(headers); String email = extractEmail(headers); // 2. ROUTING LOGIC (Bộ điều phối) // TH1: Check Onboarding Status if (path.endsWith(\u0026#34;/onboarding\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(httpMethod)) { return handleGetOnboardingStatus(userId); } // TH2: Get Profile if (path.endsWith(\u0026#34;/profile\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(httpMethod)) { return handleGetProfile(userId); } // TH3: Update Profile if (path.endsWith(\u0026#34;/profile\u0026#34;) \u0026amp;\u0026amp; \u0026#34;POST\u0026#34;.equalsIgnoreCase(httpMethod)) { return handleUpdateProfile(userId, email, event); } return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Route not found: \u0026#34; + path)); } catch (SecurityException e) { return buildResponse(401, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (IllegalArgumentException e) { // Bắt lỗi user not found từ service return buildResponse(400, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (Exception e) { logger.error(\u0026#34;System Error\u0026#34;, e); return buildResponse(500, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } }; } // Các hàm nghiệp vụ private Map\u0026lt;String, Object\u0026gt; handleGetProfile(String userId) { logger.info(\u0026#34;Executing GET logic for User: {}\u0026#34;, userId); UserEntity user = userService.getUserProfile(userId); if (user == null) { return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Profile not found\u0026#34;)); } return buildResponse(200, user); } private Map\u0026lt;String, Object\u0026gt; handleUpdateProfile(String userId, String email, Map\u0026lt;String, Object\u0026gt; event) throws Exception { logger.info(\u0026#34;Executing POST logic for User: {}\u0026#34;, userId); String bodyString = extractBodyContent(event); if (bodyString == null || bodyString.trim().isEmpty()) { return buildResponse(400, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Request body is empty\u0026#34;)); } logger.debug(\u0026#34;Request Body: {}\u0026#34;, bodyString); UpdateUserRequest request = objectMapper.readValue(bodyString, UpdateUserRequest.class); UserEntity updatedUser = userService.updateUserProfile(userId, email, request); return buildResponse(200, updatedUser); } private Map\u0026lt;String, Object\u0026gt; handleGetOnboardingStatus(String userId) { try { Map\u0026lt;String, Boolean\u0026gt; result = userService.checkOnboardingStatus(userId); return buildResponse(200, result); } catch (RuntimeException e) { // Nếu lỗi là \u0026#34;User not found\u0026#34;, trả về 404 cho đúng chuẩn REST if (\u0026#34;User not found\u0026#34;.equals(e.getMessage())) { return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;User not found\u0026#34;)); } throw e; // Ném tiếp để handler chung xử lý 500 } } // --- CÁC HÀM TIỆN ÍCH (HELPERS) --- private String extractHttpMethod(Map\u0026lt;String, Object\u0026gt; event) { // Trong API Gateway V2, method nằm ở: requestContext -\u0026gt; http -\u0026gt; method try { Map\u0026lt;String, Object\u0026gt; requestContext = (Map\u0026lt;String, Object\u0026gt;) event.get(\u0026#34;requestContext\u0026#34;); if (requestContext != null) { Map\u0026lt;String, Object\u0026gt; http = (Map\u0026lt;String, Object\u0026gt;) requestContext.get(\u0026#34;http\u0026#34;); if (http != null \u0026amp;\u0026amp; http.get(\u0026#34;method\u0026#34;) != null) { return http.get(\u0026#34;method\u0026#34;).toString(); } } // Fallback cho một số trường hợp test local hoặc format khác if (event.get(\u0026#34;httpMethod\u0026#34;) != null) { return event.get(\u0026#34;httpMethod\u0026#34;).toString(); } } catch (Exception e) { logger.warn(\u0026#34;Could not extract HTTP method from event\u0026#34;, e); } return \u0026#34;UNKNOWN\u0026#34;; } private String extractPath(Map\u0026lt;String, Object\u0026gt; event) { if (event.get(\u0026#34;rawPath\u0026#34;) != null) { return event.get(\u0026#34;rawPath\u0026#34;).toString(); } // Fallback nếu event cấu trúc khác return \u0026#34;/unknown\u0026#34;; } // ========================================================================= // HELPER METHODS (PRIVATE) // ========================================================================= /** * Chuẩn hóa Header về dạng Map\u0026lt;String, String\u0026gt; và lowercase key để dễ tìm */ private Map\u0026lt;String, String\u0026gt; normalizeHeaders(Map\u0026lt;String, Object\u0026gt; event) { Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); Object headersObj = event.get(\u0026#34;headers\u0026#34;); logger.info(\u0026#34;DEBUG RAW HEADERS TYPE: {}\u0026#34;, (headersObj != null ? headersObj.getClass().getName() : \u0026#34;null\u0026#34;)); logger.info(\u0026#34;DEBUG RAW HEADERS CONTENT: {}\u0026#34;, headersObj); if (headersObj instanceof Map) { Map\u0026lt;?, ?\u0026gt; rawMap = (Map\u0026lt;?, ?\u0026gt;) headersObj; for (Map.Entry\u0026lt;?, ?\u0026gt; entry : rawMap.entrySet()) { if (entry.getKey() != null \u0026amp;\u0026amp; entry.getValue() != null) { headers.put(entry.getKey().toString().toLowerCase(), entry.getValue().toString()); } } } logger.info(\u0026#34;DEBUG NORMALIZED HEADERS: {}\u0026#34;, headers); return headers; } /** * Trích xuất và giải mã Body từ Event (xử lý cả Base64) */ private String extractBodyContent(Map\u0026lt;String, Object\u0026gt; event) { Object bodyObj = event.get(\u0026#34;body\u0026#34;); if (bodyObj == null) return null; String bodyString; if (bodyObj instanceof String) { bodyString = (String) bodyObj; } else { // Trường hợp Spring đã lỡ parse thành Map try { bodyString = objectMapper.writeValueAsString(bodyObj); } catch (Exception e) { logger.warn(\u0026#34;Failed to convert body object to string\u0026#34;, e); return \u0026#34;{}\u0026#34;; } } // Xử lý Base64 nếu AWS API Gateway bật tính năng này Object isBase64Obj = event.get(\u0026#34;isBase64Encoded\u0026#34;); if (isBase64Obj != null \u0026amp;\u0026amp; Boolean.parseBoolean(isBase64Obj.toString())) { try { bodyString = new String(Base64.getDecoder().decode(bodyString)); } catch (Exception e) { logger.error(\u0026#34;Failed to decode Base64 body\u0026#34;, e); throw new RuntimeException(\u0026#34;Invalid Base64 body\u0026#34;); } } return bodyString; } /** * Tạo Response chuẩn cho API Gateway */ private Map\u0026lt;String, Object\u0026gt; buildResponse(int statusCode, Object body) { Map\u0026lt;String, Object\u0026gt; response = new HashMap\u0026lt;\u0026gt;(); response.put(\u0026#34;statusCode\u0026#34;, statusCode); Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); headers.put(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); // CORS Headers (Nếu cần thiết, dù API Gateway thường đã xử lý) headers.put(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); response.put(\u0026#34;headers\u0026#34;, headers); try { String jsonBody = objectMapper.writeValueAsString(body); response.put(\u0026#34;body\u0026#34;, jsonBody); } catch (Exception e) { response.put(\u0026#34;statusCode\u0026#34;, 500); response.put(\u0026#34;body\u0026#34;, \u0026#34;{\\\u0026#34;error\\\u0026#34;: \\\u0026#34;JSON Serialization Error\\\u0026#34;}\u0026#34;); } return response; } // --- SECURITY HELPERS --- private String extractUserIdOrThrow(Map\u0026lt;String, String\u0026gt; headers) { String sub = extractClaim(headers, \u0026#34;sub\u0026#34;); if (sub == null) { throw new SecurityException(\u0026#34;Missing \u0026#39;sub\u0026#39; claim in token or Invalid Token\u0026#34;); } return sub; } private String extractEmail(Map\u0026lt;String, String\u0026gt; headers) { return extractClaim(headers, \u0026#34;email\u0026#34;); } private String extractClaim(Map\u0026lt;String, String\u0026gt; headers, String claimKey) { // Tìm header Authorization (đã được normalize về chữ thường) String authHeader = headers.get(\u0026#34;authorization\u0026#34;); logger.info(\u0026#34;DEBUG AUTH HEADER FOUND: {}\u0026#34;, authHeader); if (authHeader == null || !authHeader.startsWith(\u0026#34;Bearer \u0026#34;)) { logger.warn(\u0026#34;Authorization header missing or invalid format\u0026#34;); // Thay vì trả về test ID, ta trả về null để hàm gọi ném lỗi 401 return null; } try { String token = authHeader.substring(7); String[] parts = token.split(\u0026#34;\\\\.\u0026#34;); if (parts.length \u0026lt; 2) return null; String payloadJson = new String(Base64.getUrlDecoder().decode(parts[1])); JsonNode node = objectMapper.readTree(payloadJson); if (node.has(claimKey)) { return node.get(claimKey).asText(); } } catch (Exception e) { logger.error(\u0026#34;Token decoding failed: {}\u0026#34;, e.getMessage()); } return null; } } "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Typically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1: Getting familiar with AWS and basic AWS services\nWeek 2: Researching and practicing the deployment of AWS core infrastructure services, including VPC network design, EC2 server management, and Site-to-Site VPN setup\nWeek 3: Practicing advanced VPN configuration and in-depth EC2 management, while deploying real-world applications on multiple platforms and applying IAM policies to secure resources\nWeek 4: Mastering storage and content delivery services (S3, CloudFront), relational database management (RDS), practicing within the Cloud9 environment, and rapid application deployment with Amazon Lightsail\nWeek 5: Building scalable and load-balanced systems (Auto Scaling, ELB), deploying web applications connected to RDS, establishing in-depth monitoring via CloudWatch, and managing advanced routing with Route 53\nWeek 6: Optimizing operations and costs through auto-scaling WordPress deployment, applying Lambda for resource management, monitoring systems with Grafana, and practicing advanced administration using Tags, IAM, and Systems Manager\nWeek 7: Managing secure connections via Systems Manager, automating infrastructure with advanced CloudFormation, and setting up a centralized identity system (IAM Identity Center) for the entire AWS Organization\nWeek 8: System security and governance through advanced identity management (IAM Identity Center, Permission Boundary), deploying application protection layers (Security Hub, WAF), and establishing encryption, log monitoring, and automated backup mechanisms (KMS, CloudTrail, Athena, AWS Backup)\nWeek 9: Multi-VPC networking (Peering, Transit Gateway), deploying Container applications on ECS, building comprehensive automated CI/CD pipelines (AWS Code Suite, GitLab/GitHub), and setting up Hybrid Cloud storage solutions\nWeek 10: Mastering Amazon DynamoDB from advanced design patterns to Serverless and AI integration, alongside practicing system cost optimization and automated deployment of the TravelBuddy application on Elastic Beanstalk\nWeek 11: Focus on designing the Serverless architecture, DynamoDB data model, and user interface, while setting up the development environment and basic AWS SAM infrastructure.\nWeek 12: Develop and deploy the complete Backend with AWS Lambda (Java), integrate Amazon Bedrock AI for content processing, and finalize database interactions.\nWeek 13: Build the complete React Frontend, integrate authentication and Backend APIs, then package and deploy the entire system to the live environment ready for demonstration.\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.1-week1/","title":"Worklog Week 1","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of the First Cloud Journey. Understand basic AWS services and how to use the AWS Management Console \u0026amp; AWS CLI. Tasks to be implemented this week: Day Task Start Date Completion Date Resources 2 - Get to know the FCJ members - Read and take note of the rules and regulations at the internship unit 08/09/2025 08/09/2025 3 - Learn about AWS and its service categories + Compute + Storage + Networking + Database + \u0026hellip; 09/09/2025 09/09/2025 cloudjourney.awsstudygroup.com and AWS Study Group YouTube 4 - Create an AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install and configure AWS CLI + Use AWS CLI 10/09/2025 10/09/2025 cloudjourney.awsstudygroup.com and AWS Study Group YouTube 5 - Manage costs using AWS Budgets - Request support via AWS Support - Manage access permissions using AWS Identity and Access Management (IAM) 11/09/2025 11/09/2025 cloudjourney.awsstudygroup.com 6 - Practice: + Create Cost Budget + Create Usage Budget + Create RI Budget + Create IAM Group and IAM User + Create IAM Role and OperatorUser + Switch Role for OperatorUser 12/09/2025 12/09/2025 cloudjourney.awsstudygroup.com and AWS Study Group YouTube Week 1 Achievements: Understood what AWS is and the basic service categories:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the local machine, including:\nSetting up Access Key and Secret Key Configuring default Region Checking configuration and account information Set up and managed costs through AWS Budgets:\nCost Budget Usage Budget RI Budget Managed user access using AWS IAM:\nCreated IAM Group, IAM User, and IAM Role Assigned permissions and switched roles for OperatorUser "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.4-backend-development/5.4.2-industry-functions/","title":"Industry Functions","tags":[],"description":"","content":"In the final lesson of the Backend section, we will build the Industry Insight feature.\nThis feature allows users to enter a profession (e.g., \u0026ldquo;React Developer\u0026rdquo;) and receive information such as:\nAverage salary. Required skills. Recruitment trends. Strategy: Cache-First Calling AI (Bedrock) incurs a cost for each token. Market information does not change every second. Therefore, we will apply the following strategy:\nUser asks about \u0026ldquo;Java Developer\u0026rdquo;. Check DynamoDB to see if this information already exists. If YES: Return immediately (Fast, Cheap). If NO: Call Bedrock for analysis -\u0026gt; Save to DB -\u0026gt; Return (Slightly slower, but only incurs cost once). 1. Model (Entity Layer) Define the data structure to store market analysis results in DynamoDB.\n@Data @DynamoDbBean public class IndustryInsightEntity { private String pk; // Format: INDUSTRY#\u0026lt;tên_ngành\u0026gt; (Ví dụ: INDUSTRY#tech-software) private String sk; // Format: METADATA // AI Bedrock Generated Data private Float growthRate; private String demandLevel; // \u0026#34;High\u0026#34;, \u0026#34;Medium\u0026#34;, \u0026#34;Low\u0026#34; private String marketOutlook; private List\u0026lt;String\u0026gt; topSkills; private List\u0026lt;String\u0026gt; keyTrends; private List\u0026lt;String\u0026gt; recommendedSkills; // Nested JSON cho lương private List\u0026lt;SalaryRangeItem\u0026gt; salaryRanges; private String lastUpdated; private String nextUpdate; @DynamoDbPartitionKey @DynamoDbAttribute(\u0026#34;PK\u0026#34;) public String getPk() { return pk; } @DynamoDbSortKey @DynamoDbAttribute(\u0026#34;SK\u0026#34;) public String getSk() { return sk; } // Inner Class cho dải lương @Data @DynamoDbBean public static class SalaryRangeItem { private String role; private Float min; private Float max; private Float median; private String location; } } Key Naming Rules:\nPK: INSIGHT#{lowercase_industry_name} (Example: INSIGHT#java-developer). SK: METADATA. 2. Repository (Data Access Layer) Interact with DynamoDB to search for and store Insights.\nInherits from the parent class AbstractDynamoRepository\n@Repository public class IndustryInsightRepository extends AbstractDynamoRepository\u0026lt;IndustryInsightEntity\u0026gt; { public IndustryInsightRepository(DynamoDbEnhancedClient client) { super(client, IndustryInsightEntity.class); } /** * Tìm Insight dựa trên tên ngành. * PK: INDUSTRY#\u0026lt;industryName\u0026gt; * SK: METADATA */ public IndustryInsightEntity findByIndustry(String industryName) { if (industryName == null || industryName.trim().isEmpty()) { return null; } // Chuẩn hóa key (ví dụ: lowercase hoặc slugify nếu cần thiết) // Ở đây giả định lưu nguyên văn chuỗi String pk = \u0026#34;INDUSTRY#\u0026#34; + industryName; String sk = \u0026#34;METADATA\u0026#34;; return findById(pk, sk); } } 3. Service (AI Integration Layer) Where logic is processed in combination with BedrockService to perform AI-powered statistical functions.\n@Service public class IndustryInsightService { private static final Logger logger = LoggerFactory.getLogger(IndustryInsightService.class); private final UserRepository userRepository; private final IndustryInsightRepository insightRepository; private final BedrockService bedrockService; public IndustryInsightService(UserRepository userRepository, IndustryInsightRepository insightRepository, BedrockService bedrockService) { this.userRepository = userRepository; this.insightRepository = insightRepository; this.bedrockService = bedrockService; } public IndustryInsightEntity getIndustryInsights(String userId) { // 1. Validate User ID if (userId == null || userId.isEmpty()) { throw new IllegalArgumentException(\u0026#34;User ID is required\u0026#34;); } // 2. Lấy thông tin User để biết họ làm ngành gì // PK: USER#\u0026lt;id\u0026gt;, SK: METADATA UserEntity user = userRepository.findById(\u0026#34;USER#\u0026#34; + userId, \u0026#34;METADATA\u0026#34;); if (user == null) { logger.error(\u0026#34;User not found: {}\u0026#34;, userId); throw new RuntimeException(\u0026#34;User not found\u0026#34;); } // 3. Kiểm tra xem User đã chọn ngành chưa String industry = user.getIndustry(); if (industry == null || industry.trim().isEmpty()) { logger.warn(\u0026#34;User {} has not selected an industry yet\u0026#34;, userId); // Có thể throw lỗi hoặc trả về null tùy logic frontend throw new RuntimeException(\u0026#34;User has not selected an industry\u0026#34;); } // 4. Tìm Insight trong DB logger.info(\u0026#34;Fetching insights for industry: {}\u0026#34;, industry); IndustryInsightEntity insight = insightRepository.findByIndustry(industry); // 5. Nếu chưa có hoặc (Optional: đã hết hạn cache), gọi AI tạo mới // Ở đây logic gốc là \u0026#34;If no insights exist\u0026#34;, tôi giữ nguyên logic đó. if (insight == null) { logger.info(\u0026#34;Insight not found for \u0026#39;{}\u0026#39;. Generating via Bedrock AI...\u0026#34;, industry); // Gọi AI insight = bedrockService.generateIndustryInsights(industry); // Bổ sung các thông tin quản lý DB insight.setPk(\u0026#34;INDUSTRY#\u0026#34; + industry); insight.setSk(\u0026#34;METADATA\u0026#34;); insight.setLastUpdated(Instant.now().toString()); // Set next update = now + 7 days insight.setNextUpdate(Instant.now().plus(7, ChronoUnit.DAYS).toString()); // Lưu vào DB insightRepository.save(insight); logger.info(\u0026#34;Saved new insights for \u0026#39;{}\u0026#39;\u0026#34;, industry); } else { logger.info(\u0026#34;Found existing insights for \u0026#39;{}\u0026#39; in DB\u0026#34;, industry); } return insight; } } 4. Function (Controller Layer) The final Lambda function to build the API.\n@Configuration public class IndustryFunctions { private static final Logger logger = LoggerFactory.getLogger(IndustryFunctions.class); private final IndustryInsightService insightService; private final ObjectMapper objectMapper; public IndustryFunctions(IndustryInsightService insightService) { this.insightService = insightService; this.objectMapper = new ObjectMapper(); this.objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); this.objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); } /** * HÀM TỔNG (DISPATCHER) CHO INDUSTRY * Quản lý tất cả route liên quan đến /industry-insights */ @Bean public Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; industryInsightHandler() { return event -\u0026gt; { try { String path = extractPath(event); String method = extractHttpMethod(event); logger.info(\u0026#34;Industry Handler -\u0026gt; Path: {}, Method: {}\u0026#34;, path, method); // Chuẩn hóa Header \u0026amp; Auth Map\u0026lt;String, String\u0026gt; headers = normalizeHeaders(event); String userId = extractUserIdOrThrow(headers); // --- ROUTING LOGIC --- // Route 1: GET /industry-insights if (path.endsWith(\u0026#34;/industry-insights\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(method)) { return handleGetIndustryInsights(userId); } // Route 2 (Ví dụ tương lai): POST /industry-insights/refresh (Force update AI) // if (path.endsWith(\u0026#34;/refresh\u0026#34;) ...) { return handleRefresh(userId); } return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Route not found in Industry Function\u0026#34;)); } catch (SecurityException e) { return buildResponse(401, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (Exception e) { logger.error(\u0026#34;System Error\u0026#34;, e); return buildResponse(500, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } }; } // --- LOGIC CON --- private Map\u0026lt;String, Object\u0026gt; handleGetIndustryInsights(String userId) { IndustryInsightEntity result = insightService.getIndustryInsights(userId); return buildResponse(200, result); } // --- CÁC HÀM HELPER (Copy từ UserFunctions sang hoặc gom vào 1 file Utils dùng chung) --- // (Để code ngắn gọn ở đây mình ví dụ các hàm quan trọng, bạn copy phần decode token từ UserFunctions sang nhé) private String extractPath(Map\u0026lt;String, Object\u0026gt; event) { return event.get(\u0026#34;rawPath\u0026#34;) != null ? event.get(\u0026#34;rawPath\u0026#34;).toString() : \u0026#34;\u0026#34;; } private String extractHttpMethod(Map\u0026lt;String, Object\u0026gt; event) { Map\u0026lt;String, Object\u0026gt; req = (Map) event.get(\u0026#34;requestContext\u0026#34;); if (req != null) { Map\u0026lt;String, Object\u0026gt; http = (Map) req.get(\u0026#34;http\u0026#34;); if (http != null) return http.get(\u0026#34;method\u0026#34;).toString(); } return \u0026#34;GET\u0026#34;; } private Map\u0026lt;String, String\u0026gt; normalizeHeaders(Map\u0026lt;String, Object\u0026gt; event) { Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); Object headersObj = event.get(\u0026#34;headers\u0026#34;); if (headersObj instanceof Map) { Map\u0026lt;?, ?\u0026gt; rawMap = (Map\u0026lt;?, ?\u0026gt;) headersObj; for (Map.Entry\u0026lt;?, ?\u0026gt; entry : rawMap.entrySet()) { headers.put(entry.getKey().toString().toLowerCase(), entry.getValue().toString()); } } return headers; } private String extractUserIdOrThrow(Map\u0026lt;String, String\u0026gt; headers) { // ... Logic extract token giống hệt UserFunctions ... // (Lưu ý: Bạn nên tạo class JwtUtils để tái sử dụng đoạn này đỡ phải copy paste) String authHeader = headers.get(\u0026#34;authorization\u0026#34;); if (authHeader != null \u0026amp;\u0026amp; authHeader.startsWith(\u0026#34;Bearer \u0026#34;)) { try { String token = authHeader.substring(7); String[] parts = token.split(\u0026#34;\\\\.\u0026#34;); String payloadJson = new String(Base64.getUrlDecoder().decode(parts[1])); // Nhớ dùng Base64UrlDecoder return new ObjectMapper().readTree(payloadJson).get(\u0026#34;sub\u0026#34;).asText(); } catch (Exception e) { logger.error(\u0026#34;Token error\u0026#34;, e); } } throw new SecurityException(\u0026#34;Invalid Token\u0026#34;); } private Map\u0026lt;String, Object\u0026gt; buildResponse(int statusCode, Object body) { Map\u0026lt;String, Object\u0026gt; response = new HashMap\u0026lt;\u0026gt;(); response.put(\u0026#34;statusCode\u0026#34;, statusCode); Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); headers.put(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); response.put(\u0026#34;headers\u0026#34;, headers); try { response.put(\u0026#34;body\u0026#34;, objectMapper.writeValueAsString(body)); } catch (Exception e) { response.put(\u0026#34;statusCode\u0026#34;, 500); response.put(\u0026#34;body\u0026#34;, \u0026#34;{}\u0026#34;); } return response; } } "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.2-prerequiste/","title":"Prerequiste","tags":[],"description":"","content":"To build and deploy the AI Career Coach application, we need to set up a robust development environment. Please ensure you install all the tools below before diving into the code.\nℹ️ Important Note: This project requires you to have an AWS (Amazon Web Services) account. If you don\u0026rsquo;t have one, please sign up for an account here. A Free Tier account is sufficient to complete this workshop.\n1. Install Runtime (Programming Language) A. Java 17 (JDK) Our Backend uses Spring Boot 3, which requires a minimum of Java 17.\nDownload: Visit Oracle JDK 17 or Amazon Corretto 17. Install: Run the installer file for your operating system (Windows/Mac/Linux). Verify: Open Terminal (or CMD/PowerShell) and type the command: java -version Expected Result: You will see version 17.x.x displayed.\nB. Node.js \u0026amp; npm The React Frontend (Vite) requires a Node.js environment.\nDownload: Visit Node.js and download the LTS (Long Term Support) version (e.g., v18 or v20). Verify: Open Terminal (or CMD/PowerShell) and type the command: node -v npm -v 2. Install AWS Tools These are the tools that help us interact with AWS Cloud and deploy Serverless applications.\nA. AWS CLI (Command Line Interface) The official AWS command line tool.\nWindows: Download the MSI installer here. MacOS: Download the PKG file here. Linux: See detailed instructions here. Verify installation:\naws --version B. AWS SAM CLI (Serverless Application Model) A tool that makes it easier to build, test, and deploy Serverless applications (Lambda, DynamoDB\u0026hellip;).\nInstallation instructions: See official AWS SAM documentation Verify installation: sam --version 3. Configure AWS Credentials After installing AWS CLI, you need to connect it to your AWS account via an Access Key.\nStep 1: Create Access Key\nLog in to the AWS Console. Find the IAM service -\u0026gt; Select Users -\u0026gt; Select your User (or create a new one). Go to the Security credentials tab -\u0026gt; Click Create access key. Select Use case: Command Line Interface (CLI). Download the .csv file containing the Access Key ID and Secret Access Key to your machine. Step 2: Configure on machine\nOpen Terminal and run the command:\naws configure Enter the following information:\nAWS Access Key ID: [Paste your Key ID] AWS Secret Access Key: [Paste your Secret Key] Default region name: ap-southeast-1 (Singapore) (Or the region closest to you) Default output format: json 4. Activate AI Model (Important) The project uses Anthropic\u0026rsquo;s Claude 3 Haiku model via Amazon Bedrock. By default, this access is disabled.\nLog in to the AWS Console, search for the Amazon Bedrock service. Ensure you are in the configured Region (e.g., Singapore). In the left menu, select Model catalog. Find the provider Anthropic. ℹ️ Note: You need to submit the \u0026ldquo;Use Case Details\u0026rdquo; form first. Enter \u0026ldquo;Personal Project\u0026rdquo; for the purpose of learning.\nCheck Claude 3 Haiku. If Open in playground is orange, it is ready to use. 5. IDE \u0026amp; Extensions (Recommended) To code most efficiently, you should use Visual Studio Code (VS Code) or IntelliJ IDEA.\nIf using VS Code, install the following Extensions:\nExtension Pack for Java: Supports Java/Spring Boot coding. ES7+ React/Redux/React-Native snippets: Supports fast React coding. AWS Toolkit: Manage AWS resources right inside VS Code. YAML: Supports syntax highlighting for the template.yaml file. ✅ Verification Checklist Before moving to the next lesson, make sure you have checked off the following items:\nInstalled Java 17 (java -version). Installed Node.js (node -v). Installed AWS SAM CLI (sam --version). Ran aws configure successfully. Saw Open in playground for Claude 3 Haiku on AWS Bedrock. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/2-proposal/","title":"Proposal","tags":[],"description":"","content":"AI Career Coach 1. Executive Summary The AI Career Coach platform is designed for job seekers and fresh graduates to optimize the application process and enhance job opportunities. The system operates as an intelligent virtual assistant, supporting from building profiles (CV), writing cover letters to interview practice. The platform leverages the power of AWS Serverless to ensure automatic scalability and Amazon Bedrock (Generative AI) for deep content personalization. The system ensures user personal information security through Amazon Cognito.\n2. Problem Statement Current Problem Job seekers currently spend too much time manually editing CVs for each application position. Writing cover letters is often stereotypical, lacking highlights. Additionally, providing candidates with an environment to practice professional knowledge and analyze industry insights regarding their own career as quickly as possible. Solution The platform uses a comprehensive AWS Serverless architecture to solve the above problems:\nAmazon S3 \u0026amp; CloudFront: Store and distribute the web interface (SPA) at high speed. Amazon Cognito: Manage identity and authenticate users securely. Amazon API Gateway \u0026amp; AWS Lambda (Java Spring Cloud Function): Handle business logic according to Microservices architecture (User, Resume, Cover Letter, Interview). Amazon DynamoDB: Store profile data, assessment tests, and industry information with low latency. Amazon Bedrock: The heart of the system, providing the ability to upgrade CVs, draft Cover Letters, and generate interview questions according to real-world contexts. The platform focuses deeply on the \u0026ldquo;AI Personalization\u0026rdquo; feature; users not only store CVs but are also supported by AI. Key features include: CV upgrading, AI-based cover letter writing based on JD, taking knowledge review quizzes, industry trend reports. Benefits and Return on Investment (ROI) Reduce a lot of time writing cover letters and editing CVs. Leverage AWS Free Tier for Lambda, DynamoDB, and Cognito; costs mainly come from Bedrock API calls. Estimated operating cost is about 3-5 USD/month for personal use or small scale (under 1000 AI requests/month). The biggest value lies not in direct cash but in shortening cover letter writing and CV editing. No initial hardware costs.\n3. Solution Architecture The platform applies a fully AWS Serverless architecture to optimize scalability and maintenance costs. The user interface is distributed globally through Amazon CloudFront and S3. The backend system uses Microservices architecture with AWS Lambda (Java Spring Cloud Function) to handle business logic and Amazon Bedrock to integrate artificial intelligence. Profile and assessment data is centrally managed by Amazon DynamoDB, ensuring high performance and security. AWS Services Used\nAmazon CloudFront \u0026amp; S3: Store and distribute Web interface with low latency. Amazon Cognito: Manage identity, sign-up/sign-in, and secure user authentication. Amazon API Gateway: REST API gateway managing traffic and routing requests to the correct Lambda Service. AWS Lambda: Handle business logic (5 services: User, Resume, Cover Letter, Interview, Industry) on Java Spring environment. Amazon DynamoDB: NoSQL database storing user information, resumes, and assessment history (1 tables). Amazon Bedrock: Provide foundation models (Claude 3 Haiku/Sonnet) to analyze and generate content. Component Design\nUser Interface (Frontend): Next.js Single Page Application (SPA) interacting with backend through RESTful APIs. Access Management: Amazon Cognito (User Pool) authenticates users and issues JWT Tokens for API requests. Central Processing: AWS Lambda executes Spring Cloud Function functions, connecting with Bedrock to handle intelligent tasks (creating quizzes, fixing CVs). Data Layer: DynamoDB is organized using a \u0026lsquo;single-table\u0026rsquo; design to optimize data organization and enable efficient querying. Artificial Intelligence: Amazon Bedrock receives context from Lambda, performs inference, and returns consultation results or text content. 4. Technical Implementation Implementation Phases The project is divided into 2 major phases, focusing on designing optimal Serverless architecture for Java and integrating Generative AI:\nResearch, Design, and Feasibility Assessment: Design AWS Serverless data flow diagrams, define Microservices separation strategy with Spring Cloud Function. Select suitable AI model (Claude 3 Haiku) based on accuracy and speed benchmarks. Use AWS Pricing Calculator to estimate costs for Lambda (Java runtime), DynamoDB (Read/Write capacity), and most importantly, Amazon Bedrock Token costs. Set up expected budget (AWS Budget) to ensure the project stays within Free Tier limits or lowest cost. (Month 2) Development, Optimization, and Operation: Build Lambda functions using Java (Spring Boot 3), configure DynamoDB Multi-table, and write Prompt Engineering for Bedrock to optimize output results for CV/Interview. Integrate Frontend (Next.js) with API Gateway and Cognito, perform Integration Test for the whole system before Go-live. (Month 3) Technical Requirements\nBackend Services (Java Serverless): Proficient in Java 17/21 and Spring Cloud Function to write code according to the functional model. Deep understanding of AWS Lambda SnapStart mechanism to optimize Java application startup time (reducing latency from seconds to milliseconds). Generative AI \u0026amp; Data: Advanced Prompt Engineering skills to control Claude 3 model on Amazon Bedrock to return accurate JSON format. Effective DynamoDB schema design (Partition Key/Sort Key) for assessment history and user profile queries. Infrastructure \u0026amp; Security: Use Amazon Cognito to manage User Pool and JWT authentication. Configure Amazon API Gateway to map requests and handle CORS for Frontend. Deploy Frontend (Next.js) to Amazon S3 and distribute via CloudFront. 5. Roadmap \u0026amp; Milestones Internship (Month 1–3): - Month 1: Learn AWS and upgrade hardware. - Month 2: Design and adjust architecture. - Month 3: Deploy, test, put into use. Post-deployment: Research further to expand more functions. 6. Budget Estimation Costs can be viewed on AWS Pricing Calculator Infrastructure Costs (Region: Asia Pacific - Singapore)\nAmazon Bedrock: 2.70 USD/month (AI model, processing ~1,000 token input/output per request). Amazon CloudFront: 0.85 USD/month (Data transfer to internet 10 GB). Amazon DynamoDB: 0.28 USD/month (Storage 1 GB, Standard mode). AWS Lambda: 0.13 USD/month (4,000 requests, 512 MB temporary memory). Amazon S3: 0.05 USD/month (Storage 1 GB, 4,000 PUT/GET requests). Total: 4.01 USD/month, equivalent to 48.12 USD/12 months. 7. Risk Assessment Risk Matrix\nAI Hallucination: High Impact, Medium Probability. (AI gives misleading advice or fabricates information in CV). Cost Overrun: Medium Impact, Low Probability. (Due to Bedrock token fees if request volume increases suddenly). System Latency (Cold Start): Medium Impact, Low Probability. (Due to the nature of Java Lambda functions when starting up). Mitigation Strategies\nAccurate AI: Optimize Prompt Engineering with specific context, set low Temperature parameters (0.1 - 0.2) to reduce randomness. Add disclaimer warnings for users. Cost Control: Set up AWS Budgets to alert when costs reach 80% of the allowed threshold. Performance: Enable AWS Lambda SnapStart feature to reduce Java startup time from seconds to milliseconds. Contingency Plan\nAI Service Incident: Design the system to \u0026ldquo;fail gracefully\u0026rdquo; (friendly error notification) or return available templates if Amazon Bedrock is interrupted. Data Recovery: Enable DynamoDB Point-in-Time Recovery (PITR) feature to restore user data in case of accidental deletion or application errors. 8. Expected Outcomes Technical Improvements: Automate 90% of the application profile preparation process (from editing CVs to writing cover letters), completely replacing time-consuming manual drafting. The system achieves low latency (milliseconds) thanks to Java SnapStart optimization, capable of handling high loads without infrastructure intervention. Long-term Value: Successfully build a sample architecture framework for Java Serverless applications combined with GenAI on AWS, reusable for enterprise projects. Create a real-world environment to test and refine complex Prompt Engineering techniques, serving the specialized development direction of AI Engineer.\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.2-week2/","title":"Worklog Week 2","tags":[],"description":"","content":"Week 2 Objectives: Understand and practice AWS core infrastructure services, including VPC, EC2, and Site-to-Site VPN. Learn how to design, configure, and secure a basic VPC network. Deploy and manage EC2 Instances within Public and Private Subnets. Grasp the concept of network connectivity between on-premises and AWS Cloud through Site-to-Site VPN. Tasks to be implemented this week: Day Task Start Date Completion Date Resources 2 - Learn the basics of VPC: + Subnets + Route Table + Internet Gateway + NAT Gateway + Security Groups + Network Access Control Lists - Practice: Build a VPC environment by deploying essential AWS networking components (VPC, Subnets, Route Table, Internet Gateway, Security Groups, VPC Flow Logs) and design a secure, scalable network structure. 15/09/2025 15/09/2025 cloudjourney.awsstudygroup.com and AWS Study Group YouTube 3 - Learn the fundamentals of EC2: + Concept, features, and operation of EC2 + Instance types (General Purpose, Compute Optimized, Memory Optimized, etc.) + Concepts of AMI, EBS, Security Group, and Key Pair + Network, storage, and access configuration for EC2 Instances + Instance lifecycle management (Start, Stop, Reboot, Terminate) 16/09/2025 16/09/2025 cloudjourney.awsstudygroup.com 4 - Learn about VPC Reachability Analyzer, EC2 Instance Connect Endpoint, AWS Systems Manager Session Manager, and CloudWatch Monitoring - Practice: Deploy Amazon EC2 Instances + Create EC2 instances in Public and Private Subnets + Connect via SSH + Create Elastic IP + Create NAT Gateway + Configure Route Table for Private Subnet + Analyze connections using VPC Reachability Analyzer + Deploy EIC Endpoint 17/09/2025 18/09/2025 cloudjourney.awsstudygroup.com 5 - Learn about AWS Site-to-Site VPN: + Virtual Private Gateway (VPG) + Customer Gateway (CGW) 18/09/2025 18/09/2025 cloudjourney.awsstudygroup.com 6 - Practice: + Configure VPC for Site-to-Site VPN + Deploy EC2 Instance for Customer Gateway + Create Virtual Private Gateway + Create Customer Gateway + Establish VPN connection between VPC and on-premises environment + Configure Customer Gateway + Adjust AWS VPN Tunnel settings 19/09/2025 19/09/2025 cloudjourney.awsstudygroup.com Week 2 Achievements: Gained a solid understanding of VPC architecture and core components, including Subnet, Route Table, Internet Gateway, NAT Gateway, Security Group, and Network ACL. Built a basic, scalable VPC model with secure access between subnets. Mastered fundamental knowledge of Amazon EC2, including: Instance classification and AMI selection Configuration of storage (EBS), security (Security Group, Key Pair), and networking (Elastic IP, Route Table) Instance lifecycle management (launch, connect, stop, terminate) Practiced deploying EC2 Instances in Public and Private Subnets, connecting via SSH, and managing access through Instance Connect Endpoint. Learned how to use VPC Reachability Analyzer and CloudWatch for monitoring and analyzing network connections. Understood the concepts, components, and setup process of Site-to-Site VPN between on-premises and AWS Cloud. Successfully practiced creating a secure VPN connection between Customer Gateway and Virtual Private Gateway, extending the on-premises network to AWS Cloud. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.3-infrastructure-as-code/","title":"Infrastructure as Code","tags":[],"description":"","content":"Instead of manually clicking hundreds of times on the AWS Console to create Databases, Lambda, API Gateway, etc., we will use the Infrastructure as Code (IaC) method.\nWith AWS SAM (Serverless Application Model), the entire system architecture is defined in a single file: template.yaml.\n1. Global Configuration (Globals) To avoid code repetition (Don\u0026rsquo;t Repeat Yourself), we define common parameters for all Lambda functions in the Globals section.\nYAML Globals: Function: Timeout: 60 # Tăng lên 60s vì gọi AI Bedrock có thể lâu MemorySize: 2048 # Java cần RAM khá để chạy mượt Runtime: java17 Architectures: [x86_64] Environment: Variables: TABLE_NAME: !Ref CoreTable # ID của model Bedrock (Claude 3 Haiku) BEDROCK_MODEL_ID: \u0026#34;anthropic.claude-3-haiku-20240307-v1:0\u0026#34; With Java, more RAM equates to a stronger CPU and shorter startup time (Cold Start). Combined with the SnapStart feature, the application will respond instantly.\n2. Backend Definition (Lambda Functions) Each of our features corresponds to an AWS::Serverless::Function resource.\nYou can view the Lambda definitions in template.yaml at this github link\nExample with the Cover Letter function:\nYAML CoverLetterFunction: Type: AWS::Serverless::Function Properties: CodeUri: backend/target/backend-0.0.1-SNAPSHOT-aws.jar Handler: org.springframework.cloud.function.adapter.aws.FunctionInvoker::handleRequest Timeout: 60 # Gọi AI nên cần timeout lâu MemorySize: 2048 SnapStart: ApplyOn: PublishedVersions Policies: - DynamoDBCrudPolicy: TableName: !Ref CoreTable - Statement: - Effect: Allow Action: - bedrock:InvokeModel - bedrock:InvokeModelWithResponseStream # Thêm quyền Marketplace để sửa lỗi AccessDenied - aws-marketplace:ViewSubscriptions - aws-marketplace:Subscribe - aws-marketplace:Unsubscribe Resource: \u0026#34;*\u0026#34; Environment: Variables: TABLE_NAME: !Ref CoreTable BEDROCK_MODEL_ID: \u0026#34;anthropic.claude-3-haiku-20240307-v1:0\u0026#34; # Chạy hàm coverLetterHandler SPRING_CLOUD_FUNCTION_DEFINITION: coverLetterHandler Events: # 1. Generate (POST) GenerateCoverLetter: Type: HttpApi Properties: ApiId: !Ref HttpApi Path: /cover-letters Method: POST Auth: Authorizer: CognitoAuthorizer # 2. List All (GET) ListCoverLetters: Type: HttpApi Properties: ApiId: !Ref HttpApi Path: /cover-letters Method: GET Auth: Authorizer: CognitoAuthorizer # 3. Get One (GET /{id}) GetOneCoverLetter: Type: HttpApi Properties: ApiId: !Ref HttpApi Path: /cover-letters/{id} Method: GET Auth: Authorizer: CognitoAuthorizer # 4. Delete (DELETE /{id}) DeleteCoverLetter: Type: HttpApi Properties: ApiId: !Ref HttpApi Path: /cover-letters/{id} Method: DELETE Auth: Authorizer: CognitoAuthorizer The most important note regarding Lambda functions is: does the code run with the correct logic but still encounter an AccessDenied error? That is because Lambda by default has no permissions to do anything. We must grant specific permissions:\nbedrock:InvokeModel: Allows Lambda to send prompts to the Claude 3 model. bedrock:InvokeModelWithResponseStream: Allows calling the model in streaming mode (data returned in a stream — token by token). Used for applications that need to receive output incrementally (streaming responses). aws-marketplace:ViewSubscriptions: Allows viewing the subscription status of products on the AWS Marketplace for the account (lists existing subscriptions). Needed to check if the account has subscribed to third-party models. aws-marketplace:Subscribe: Because Claude 3 is a third-party model (Anthropic), Lambda needs permission to check if your AWS account has subscribed to this model. Without this permission, Bedrock will refuse service. aws-marketplace:Unsubscribe: Allows unsubscribing from a product on the Marketplace. 3. Database \u0026amp; Auth Definition DynamoDB (Single Table) We declare the table with the PAY_PER_REQUEST (Serverless) billing mode — pay only for what you use, with no maintenance costs when no one is using it.\nYAML CoreTable: Type: AWS::DynamoDB::Table Properties: TableName: AICareerCoachDB BillingMode: PAY_PER_REQUEST AttributeDefinitions: - AttributeName: PK AttributeType: S - AttributeName: SK AttributeType: S - AttributeName: GSI1_PK AttributeType: S - AttributeName: GSI1_SK AttributeType: S KeySchema: - AttributeName: PK KeyType: HASH - AttributeName: SK KeyType: RANGE GlobalSecondaryIndexes: - IndexName: GSI1 KeySchema: - AttributeName: GSI1_PK KeyType: HASH - AttributeName: GSI1_SK KeyType: RANGE Projection: ProjectionType: ALL 4. Cognito User Pool Where users are managed. We configure AutoVerifiedAttributes: [email] to automatically send verification emails upon registration.\nYAML UserPool: Type: AWS::Cognito::UserPool Properties: UserPoolName: CareerCoachUsers AutoVerifiedAttributes: [email] UsernameAttributes: [email] Policies: PasswordPolicy: MinimumLength: 8 # Kích hoạt Trigger sau khi đăng ký để lưu vào DynamoDB LambdaConfig: PostConfirmation: !GetAtt PostSignupTriggerFunction.Arn UserPoolClient: Type: AWS::Cognito::UserPoolClient Properties: ClientName: ReactClient UserPoolId: !Ref UserPool GenerateSecret: false # Web App (React) không dùng Secret ExplicitAuthFlows: [ALLOW_USER_SRP_AUTH, ALLOW_REFRESH_TOKEN_AUTH] # Lambda nhỏ (NodeJS) để hứng sự kiện đăng ký và lưu user vào DB # (Dùng Nodejs cho cái này vì nó khởi động cực nhanh và nhẹ) PostSignupTriggerFunction: Type: AWS::Serverless::Function Properties: Runtime: nodejs18.x MemorySize: 128 Timeout: 5 Handler: index.handler InlineCode: | const { DynamoDBClient, PutItemCommand } = require(\u0026#34;@aws-sdk/client-dynamodb\u0026#34;); const client = new DynamoDBClient({}); exports.handler = async (event) =\u0026gt; { if (event.triggerSource === \u0026#34;PostConfirmation_ConfirmSignUp\u0026#34;) { const userId = event.request.userAttributes.sub; const email = event.request.userAttributes.email; const params = { TableName: process.env.TABLE_NAME, Item: { PK: { S: `USER#${userId}` }, SK: { S: \u0026#34;METADATA\u0026#34; }, email: { S: email }, createdAt: { S: new Date().toISOString() } } }; try { await client.send(new PutItemCommand(params)); } catch (err) { console.error(err); } } return event; }; Environment: Variables: TABLE_NAME: !Ref CoreTable Policies: - DynamoDBCrudPolicy: TableName: !Ref CoreTable # Cấp quyền cho Cognito được gọi Lambda Trigger PostSignupTriggerPermission: Type: AWS::Lambda::Permission Properties: Action: lambda:InvokeFunction FunctionName: !Ref PostSignupTriggerFunction Principal: cognito-idp.amazonaws.com SourceArn: !GetAtt UserPool.Arn 5. Frontend Hosting (S3 + CloudFront OAC) This is currently the most modern and secure hosting architecture for Static Web.\nComponents:\nS3 Bucket: Stores index.html, js, css files. PublicAccessBlock mode is enabled (Blocks direct access from the internet). CloudFront Distribution: CDN that helps cache content and provides HTTPS. Origin Access Control (OAC): Uses OAC. This acts as the intermediary bodyguard. It signs requests sent from CloudFront to S3. Result: Users are forced to go through CloudFront (with HTTPS, with Cache). If they intentionally try to access the S3 link directly, they will be blocked (403 Forbidden).\nYAML # Cấu hình bảo mật mới (OAC) CloudFrontOriginAccessControl: Type: AWS::CloudFront::OriginAccessControl Properties: OriginAccessControlConfig: Description: \u0026#34;Access Control for CV Analyzer\u0026#34; Name: !Sub \u0026#34;OAC-${FrontendBucket}\u0026#34; OriginAccessControlOriginType: s3 SigningBehavior: always SigningProtocol: sigv4 YAML FrontendBucket: Type: AWS::S3::Bucket Properties: BucketName: !Sub \u0026#34;career-coach-frontend-${AWS::AccountId}\u0026#34; # Thêm ID tài khoản để chắc chắn không trùng tên PublicAccessBlockConfiguration: BlockPublicAcls: true BlockPublicPolicy: true IgnorePublicAcls: true RestrictPublicBuckets: true FrontendBucketPolicy: Type: AWS::S3::BucketPolicy Properties: Bucket: !Ref FrontendBucket PolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Sid: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34; Effect: Allow Principal: Service: \u0026#34;cloudfront.amazonaws.com\u0026#34; # Dùng Service Principal chuẩn (Luôn tồn tại) Action: \u0026#34;s3:GetObject\u0026#34; Resource: !Sub \u0026#34;${FrontendBucket.Arn}/*\u0026#34; Condition: StringEquals: \u0026#34;AWS:SourceArn\u0026#34;: !Sub \u0026#34;arn:aws:cloudfront::${AWS::AccountId}:distribution/${FrontendDistribution}\u0026#34; FrontendDistribution: Type: AWS::CloudFront::Distribution Properties: DistributionConfig: Enabled: true DefaultRootObject: index.html Origins: - DomainName: !GetAtt FrontendBucket.RegionalDomainName # Lưu ý dùng RegionalDomainName Id: S3Origin OriginAccessControlId: !GetAtt CloudFrontOriginAccessControl.Id # Trỏ vào OAC mới S3OriginConfig: OriginAccessIdentity: \u0026#34;\u0026#34; # Để trống dòng này vì đã dùng OAC DefaultCacheBehavior: TargetOriginId: S3Origin ViewerProtocolPolicy: redirect-to-https AllowedMethods: [GET, HEAD, OPTIONS] CachedMethods: [GET, HEAD, OPTIONS] ForwardedValues: QueryString: false Cookies: Forward: none CustomErrorResponses: - ErrorCode: 403 ResponseCode: 200 ResponsePagePath: /index.html - ErrorCode: 404 ResponseCode: 200 ResponsePagePath: /index.html 6. Outputs After deployment is complete, CloudFormation will return important parameters for us to configure the Frontend.\nYAML Outputs: ApiEndpoint: Description: \u0026#34;API URL để dán vào Frontend .env\u0026#34; Value: !Sub \u0026#34;https://${HttpApi}.execute-api.${AWS::Region}.amazonaws.com\u0026#34; CognitoUserPoolId: Description: \u0026#34;User Pool ID\u0026#34; Value: !Ref UserPool CognitoClientId: Description: \u0026#34;App Client ID\u0026#34; Value: !Ref UserPoolClient WebsiteURL: Description: \u0026#34;URL trang web React của bạn (CloudFront)\u0026#34; Value: !GetAtt FrontendDistribution.DomainName S3BucketName: Description: \u0026#34;Tên Bucket để upload code Frontend\u0026#34; Value: !Ref FrontendBucket "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.4-backend-development/5.4.3-resume-functions/","title":"Resume Functions","tags":[],"description":"","content":"In this lesson, we will build the Resume Function. This is not just a place to store CV content but also a \u0026ldquo;writing assistant\u0026rdquo; for users.\nKey Features: Storage: Save the entire CV content in Markdown format to DynamoDB. Why Markdown? Because it is lightweight, easy to format, and easy to convert to PDF. Improvement: Send raw experience descriptions to AI (Claude 3) to rewrite them more professionally. 1. Model (Entity Layer) Define the structure for storing CVs in DynamoDB.\n@Data @DynamoDbBean public class ResumeEntity { private String pk; // Format: USER#\u0026lt;cognito_sub\u0026gt; private String sk; // Format: RESUME private String content; // Markdown text private Double atsScore; // Điểm số ATS private String feedback; // Feedback từ Bedrock AI private String createdAt; private String updatedAt; @DynamoDbPartitionKey @DynamoDbAttribute(\u0026#34;PK\u0026#34;) public String getPk() { return pk; } @DynamoDbSortKey @DynamoDbAttribute(\u0026#34;SK\u0026#34;) public String getSk() { return sk; } } Key Strategy:\nPK: USER#{userId} (Linked to the user). SK: RESUME (Each user has only 1 main CV draft in this context). 2. Repository (Data Access Layer) Inherits from the parent class AbstractDynamoRepository.\n@Repository public class ResumeRepository extends AbstractDynamoRepository\u0026lt;ResumeEntity\u0026gt; { public ResumeRepository(DynamoDbEnhancedClient client) { super(client, ResumeEntity.class); } // Tìm Resume theo UserID (Quan hệ 1-1) // PK: USER#\u0026lt;userId\u0026gt;, SK: RESUME public ResumeEntity findByUserId(String userId) { String pk = \u0026#34;USER#\u0026#34; + userId; String sk = \u0026#34;RESUME\u0026#34;; return findById(pk, sk); } } 3. Service This is the most interesting part. The improveWithAI function will call Amazon Bedrock.\nCombine with BedrockService to implement the improveWithAI function using AI\n@Service public class ResumeService { private static final Logger logger = LoggerFactory.getLogger(ResumeService.class); private final ResumeRepository resumeRepository; private final UserRepository userRepository; private final BedrockService bedrockService; public ResumeService(ResumeRepository resumeRepository, UserRepository userRepository, BedrockService bedrockService) { this.resumeRepository = resumeRepository; this.userRepository = userRepository; this.bedrockService = bedrockService; } // 1. Save Resume (Upsert) public ResumeEntity saveResume(String userId, String content) { if (content == null || content.trim().isEmpty()) { throw new IllegalArgumentException(\u0026#34;Resume content cannot be empty\u0026#34;); } // Kiểm tra user có tồn tại không // (Tùy chọn: nếu tin tưởng token thì có thể bỏ qua bước này để tiết kiệm 1 RCU) ResumeEntity resume = resumeRepository.findByUserId(userId); if (resume == null) { logger.info(\u0026#34;Creating new resume for user: {}\u0026#34;, userId); resume = new ResumeEntity(); resume.setPk(\u0026#34;USER#\u0026#34; + userId); resume.setSk(\u0026#34;RESUME\u0026#34;); resume.setCreatedAt(Instant.now().toString()); } else { logger.info(\u0026#34;Updating existing resume for user: {}\u0026#34;, userId); } resume.setContent(content); resume.setUpdatedAt(Instant.now().toString()); resumeRepository.save(resume); return resume; } // 2. Get Resume public ResumeEntity getResume(String userId) { logger.debug(\u0026#34;Fetching resume for user: {}\u0026#34;, userId); return resumeRepository.findByUserId(userId); } // 3. Improve Content with AI public String improveWithAI(String userId, String currentContent, String type) { // Validation if (currentContent == null || currentContent.isEmpty()) throw new IllegalArgumentException(\u0026#34;Current content is required\u0026#34;); if (type == null || type.isEmpty()) throw new IllegalArgumentException(\u0026#34;Type is required\u0026#34;); // Lấy thông tin User để biết Industry UserEntity user = userRepository.findById(\u0026#34;USER#\u0026#34; + userId, \u0026#34;METADATA\u0026#34;); if (user == null) throw new RuntimeException(\u0026#34;User not found\u0026#34;); String industry = user.getIndustry(); if (industry == null) industry = \u0026#34;General Professional\u0026#34;; // Fallback nếu chưa có ngành logger.info(\u0026#34;Improving resume section \u0026#39;{}\u0026#39; for industry \u0026#39;{}\u0026#39;\u0026#34;, type, industry); // Tạo Prompt cho Bedrock (Claude 3) String prompt = String.format(\u0026#34;\u0026#34;\u0026#34; As an expert resume writer, improve the following %s description for a %s professional. Make it more impactful, quantifiable, and aligned with industry standards. Current content: \u0026#34;%s\u0026#34; Requirements: 1. Use action verbs 2. Include metrics and results where possible 3. Highlight relevant technical skills 4. Keep it concise but detailed 5. Focus on achievements over responsibilities 6. Use industry-specific keywords Format the response as a single paragraph without any additional text or explanations. \u0026#34;\u0026#34;\u0026#34;, type, industry, currentContent); // Gọi AI return bedrockService.generateTextCorrection(prompt); } } 4. Function (Controller Layer) This module needs to handle 3 main flows: Get CV, Save CV, and Call AI.\n@Configuration public class ResumeFunctions { private static final Logger logger = LoggerFactory.getLogger(ResumeFunctions.class); private final ResumeService resumeService; private final ObjectMapper objectMapper; public ResumeFunctions(ResumeService resumeService) { this.resumeService = resumeService; // --- CẤU HÌNH JACKSON THỦ CÔNG (THEO YÊU CẦU) --- this.objectMapper = new ObjectMapper(); // Cho phép đọc/ghi trực tiếp vào field (kể cả private) this.objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); // Bỏ qua lỗi nếu JSON có trường thừa this.objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); } /** * HÀM TỔNG (ROUTER) CHO RESUME */ @Bean public Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; resumeHandler() { return event -\u0026gt; { try { String path = extractPath(event); String method = extractHttpMethod(event); logger.info(\u0026#34;Resume Handler -\u0026gt; Path: {}, Method: {}\u0026#34;, path, method); Map\u0026lt;String, String\u0026gt; headers = normalizeHeaders(event); String userId = extractUserIdOrThrow(headers); // --- ROUTING --- // 1. GET /resume if (path.endsWith(\u0026#34;/resume\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(method)) { return handleGetResume(userId); } // 2. POST /resume (Save) if (path.endsWith(\u0026#34;/resume\u0026#34;) \u0026amp;\u0026amp; \u0026#34;POST\u0026#34;.equalsIgnoreCase(method)) { return handleSaveResume(userId, event); } // 3. POST /resume/improve (AI Improve) if (path.endsWith(\u0026#34;/resume/improve\u0026#34;) \u0026amp;\u0026amp; \u0026#34;POST\u0026#34;.equalsIgnoreCase(method)) { return handleImproveResume(userId, event); } return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Route not found\u0026#34;)); } catch (SecurityException e) { return buildResponse(401, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (IllegalArgumentException e) { return buildResponse(400, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (Exception e) { logger.error(\u0026#34;System Error\u0026#34;, e); return buildResponse(500, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } }; } // --- LOGIC CON --- private Map\u0026lt;String, Object\u0026gt; handleGetResume(String userId) { ResumeEntity resume = resumeService.getResume(userId); // Nếu chưa có resume, trả về null (frontend sẽ hiển thị form trống) return buildResponse(200, resume); } private Map\u0026lt;String, Object\u0026gt; handleSaveResume(String userId, Map\u0026lt;String, Object\u0026gt; event) throws Exception { String bodyString = extractBodyContent(event); // Parse thủ công để lấy field \u0026#39;content\u0026#39; JsonNode node = objectMapper.readTree(bodyString); if (!node.has(\u0026#34;content\u0026#34;)) { throw new IllegalArgumentException(\u0026#34;Field \u0026#39;content\u0026#39; is required\u0026#34;); } String content = node.get(\u0026#34;content\u0026#34;).asText(); ResumeEntity saved = resumeService.saveResume(userId, content); return buildResponse(200, saved); } private Map\u0026lt;String, Object\u0026gt; handleImproveResume(String userId, Map\u0026lt;String, Object\u0026gt; event) throws Exception { String bodyString = extractBodyContent(event); JsonNode node = objectMapper.readTree(bodyString); if (!node.has(\u0026#34;current\u0026#34;) || !node.has(\u0026#34;type\u0026#34;)) { throw new IllegalArgumentException(\u0026#34;Fields \u0026#39;current\u0026#39; and \u0026#39;type\u0026#39; are required\u0026#34;); } String current = node.get(\u0026#34;current\u0026#34;).asText(); String type = node.get(\u0026#34;type\u0026#34;).asText(); String improvedContent = resumeService.improveWithAI(userId, current, type); // Trả về JSON đơn giản return buildResponse(200, Map.of(\u0026#34;improvedContent\u0026#34;, improvedContent)); } // --- HELPERS (Đã được chuẩn hóa và format đẹp) --- private String extractPath(Map\u0026lt;String, Object\u0026gt; event) { return event.get(\u0026#34;rawPath\u0026#34;) != null ? event.get(\u0026#34;rawPath\u0026#34;).toString() : \u0026#34;\u0026#34;; } private String extractHttpMethod(Map\u0026lt;String, Object\u0026gt; event) { try { Map req = (Map) event.get(\u0026#34;requestContext\u0026#34;); if (req != null) { Map http = (Map) req.get(\u0026#34;http\u0026#34;); if (http != null) return http.get(\u0026#34;method\u0026#34;).toString(); } } catch (Exception e) { /* ignore */ } return \u0026#34;GET\u0026#34;; } private Map\u0026lt;String, String\u0026gt; normalizeHeaders(Map\u0026lt;String, Object\u0026gt; event) { Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); Object headersObj = event.get(\u0026#34;headers\u0026#34;); if (headersObj instanceof Map) { Map\u0026lt;?, ?\u0026gt; rawMap = (Map\u0026lt;?, ?\u0026gt;) headersObj; for (Map.Entry\u0026lt;?, ?\u0026gt; entry : rawMap.entrySet()) { if (entry.getKey() != null \u0026amp;\u0026amp; entry.getValue() != null) { headers.put(entry.getKey().toString().toLowerCase(), entry.getValue().toString()); } } } return headers; } private String extractUserIdOrThrow(Map\u0026lt;String, String\u0026gt; headers) { String authHeader = headers.get(\u0026#34;authorization\u0026#34;); if (authHeader == null || !authHeader.startsWith(\u0026#34;Bearer \u0026#34;)) { throw new SecurityException(\u0026#34;Missing or invalid Authorization header\u0026#34;); } try { String token = authHeader.substring(7); String[] parts = token.split(\u0026#34;\\\\.\u0026#34;); if (parts.length \u0026lt; 2) throw new SecurityException(\u0026#34;Invalid JWT format\u0026#34;); // QUAN TRỌNG: Dùng Base64UrlDecoder String payloadJson = new String(Base64.getUrlDecoder().decode(parts[1])); return objectMapper.readTree(payloadJson).get(\u0026#34;sub\u0026#34;).asText(); } catch (Exception e) { throw new SecurityException(\u0026#34;Token validation failed\u0026#34;); } } private String extractBodyContent(Map\u0026lt;String, Object\u0026gt; event) { Object bodyObj = event.get(\u0026#34;body\u0026#34;); if (bodyObj == null) return null; String bodyString; if (bodyObj instanceof String) { bodyString = (String) bodyObj; } else { try { bodyString = objectMapper.writeValueAsString(bodyObj); } catch (Exception e) { return \u0026#34;{}\u0026#34;; } } Object isBase64Obj = event.get(\u0026#34;isBase64Encoded\u0026#34;); if (isBase64Obj != null \u0026amp;\u0026amp; Boolean.parseBoolean(isBase64Obj.toString())) { try { bodyString = new String(Base64.getDecoder().decode(bodyString)); } catch (Exception e) { throw new RuntimeException(\u0026#34;Invalid Base64 body\u0026#34;); } } return bodyString; } private Map\u0026lt;String, Object\u0026gt; buildResponse(int statusCode, Object body) { Map\u0026lt;String, Object\u0026gt; response = new HashMap\u0026lt;\u0026gt;(); response.put(\u0026#34;statusCode\u0026#34;, statusCode); response.put(\u0026#34;headers\u0026#34;, Map.of(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;)); try { response.put(\u0026#34;body\u0026#34;, objectMapper.writeValueAsString(body)); } catch (Exception e) { response.put(\u0026#34;statusCode\u0026#34;, 500); response.put(\u0026#34;body\u0026#34;, \u0026#34;{\\\u0026#34;error\\\u0026#34;: \\\u0026#34;JSON Serialization Error\\\u0026#34;}\u0026#34;); } return response; } } "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Below are the blog posts I have translated:\nBlog 1 - AWS Transfer Family SFTP connectors now support VPC-based connectivity This blog announces that AWS Transfer Family SFTP connectors now support VPC-based connectivity, enabling secure file transfers between Amazon S3 and private or public SFTP servers without exposing endpoints to the internet. By leveraging existing VPC resources like NAT gateways, VPNs, and firewalls, users can integrate on-premises systems and partner-hosted servers while maintaining compliance and performance. Configuration is streamlined via AWS Console or CLI, making it easier to manage hybrid environments and regulated workloads.\nBlog 2 - AWS Weekly Roundup: Amazon Quick Suite, Amazon EC2, Amazon EKS, and more (October 13, 2025) This blog highlights the latest AWS updates as of October 13, 2025, including the launch of Amazon Quick Suite—an AI-powered workspace for research and automation—and new EC2 instances using AMD and Intel processors. It also covers Kubernetes 1.34 support in Amazon EKS, enhanced encryption in IAM Identity Center, and improvements in Amazon VPC Lattice, Amazon RDS for Db2, and Amazon Connect. Additionally, it announces upcoming AWS events like the AI Agent Global Hackathon and Gen AI Lofts across Europe.\nBlog 3 - Announcing Amazon Quick Suite: your agentic teammate for answering questions and taking action This blog introduces Amazon Quick Suite, a new AI-powered digital workspace that acts as your agentic teammate to answer questions and automate tasks. It combines research, business intelligence, and automation tools—like Quick Research, Quick Sight, Quick Flows, and Quick Automate—into a unified platform. With natural language queries, users can analyze data, generate insights, and streamline workflows across departments. Features like Quick Index and custom chat agents further enhance productivity by centralizing knowledge and enabling contextual AI interactions across the enterprise.\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.3-week3/","title":"Worklog Week 3","tags":[],"description":"","content":"Week 3 Objectives: Understand and practice advanced configurations of VPN and EC2 on AWS. Learn how to set up advanced VPN with StrongSwan, Transit Gateway, and BGP Dynamic Routing to extend network connectivity between regions and systems. Master advanced EC2 management and operation: changing instance types, creating custom AMIs, and recovering access when losing a Key Pair. Deploy real-world applications (Node.js and User Management) on Amazon Linux 2 and Windows Server 2022. Manage access control and resource usage limits with IAM Policy to enhance system security. Tasks to Implement This Week: Day Task Start Date Completion Date Reference 2 - Study advanced VPN configuration basics: + StrongSwan replacement setup + Advanced security configuration + BGP Dynamic Routing setup + Advanced monitoring and troubleshooting + Production deployment checklist - Explore common VPN setup issues and solutions for different OS environments - Practice: Configure VPN using StrongSwan with Transit Gateway + Create Customer Gateway + Create Transit Gateway + Create VPN connection + Create Transit Gateway Attachment + Configure Route Tables for Transit Gateway and VPC + Configure Customer Gateway 22/09/2025 22/09/2025 cloudjourney.awsstudygroup.com 3 - Review EC2 fundamentals: + Concepts, features, and how EC2 works + Instance types (General Purpose, Compute Optimized, Memory Optimized, etc.) + AMI, EBS, Security Group, Key Pair + Network, storage, and access configurations + Lifecycle management (Start, Stop, Reboot, Terminate) - Practice: + Create VPC and Security Groups for Linux and Windows + Launch a Microsoft Windows Server 2022 instance + Connect from local PC to Windows Server 2022 instance + Launch an Amazon Linux 2 instance + Connect to Amazon Linux 2 instance using MobaXterm and PuTTY 23/09/2025 23/09/2025 cloudjourney.awsstudygroup.com 4 - Practice: Advanced work with Amazon EC2 and related components + Change EC2 instance type + Create EC2 Snapshot + Create custom AMI + Launch new instance from custom AMI + Recover access when Key Pair is lost (Linux - User Data, Windows - SSM) - Research: + Desktop Interface for EC2 Ubuntu 22.04 + EBS Snapshots Archive + AMI Sharing 24/09/2025 24/09/2025 cloudjourney.awsstudygroup.com 5 - Practice: Deploy a Node.js application on Amazon Linux 2 + Prepare LAMP Web Server + Verify LAMP Web Server + Configure database server security + Install phpMyAdmin + Deploy application on Linux instance - Practice: Deploy AWS User Management application on Amazon EC2 (Windows Server 2022) + Install XAMPP on Microsoft Windows Server 2022 Base instance + Deploy application on Windows Server 2022 instance 25/09/2025 26/09/2025 cloudjourney.awsstudygroup.com 6 - Learn about resource usage limitation with IAM service - Practice: + Allow EC2 usage in Singapore region only + Restrict EC2 usage by Instance Family and Instance Type + Restrict EBS Volume Storage Type + Restrict EC2 deletion by company IP address + Restrict EC2 deletion by time window 26/09/2025 26/09/2025 cloudjourney.awsstudygroup.com Week 3 Achievements: Gained deeper understanding of advanced VPN configuration and security, including StrongSwan, Transit Gateway, BGP Dynamic Routing, and monitoring/troubleshooting techniques. Successfully implemented VPN connections across multiple VPCs with flexible and reliable architectures. Strengthened knowledge and hands-on skills in EC2 for both Linux and Windows: Created, configured, and connected to EC2 instances. Managed EC2 resources (EBS, Security Group, AMI). Recovered access using User Data and SSM Session Manager. Managed custom AMIs, snapshots, and recovery processes. Deployed real-world applications (Node.js and User Management) on Amazon Linux 2 and Windows Server 2022. Applied IAM Policy to restrict resource usage, enhancing security and cost control. Improved cloud operations, deployment, and infrastructure management skills at an advanced practical level. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.4-backend-development/","title":"Backend Development","tags":[],"description":"","content":"In this section, we will write the source code for the Backend using Java 17 and the Spring Cloud Function framework.\nThe goal is to transform business logic into independent functions that can run on AWS Lambda.\nView the backend source code here\n1. Project Structure The project is built based on Maven. Below is the standard directory structure:\nMain Packages: model: Defines Entities mapped to DynamoDB (e.g., UserEntity, ResumeEntity). repository: Interface for communicating with DynamoDB (using AWS SDK v2 Enhanced Client). service: Contains business logic and code to call AI Bedrock. functions: Contains Spring Cloud Function Beans (Lambda entry points). dto: Data Transfer Objects to receive requests from the Frontend. 2. Important Lesson: ObjectMapper Configuration During development, we encountered a serious error: The Backend returns an empty object {} or a 500 error even though the logic runs correctly.\nCause By default, Jackson\u0026rsquo;s ObjectMapper requires classes to have standard Getters/Setters (Java Bean standard) or fields must be Public. If our Entity uses Private fields and is missing Getters, or has a complex structure, Jackson will not be able to convert (serialize) it to JSON.\nSolution: Manual Configuration Instead of using Spring\u0026rsquo;s default ObjectMapper, we manually initialize and configure it more \u0026ldquo;aggressively\u0026rdquo; in the Constructor of the Function classes:\npublic ResumeFunctions(ResumeService resumeService) { this.resumeService = resumeService; // --- CẤU HÌNH JACKSON THỦ CÔNG --- this.objectMapper = new ObjectMapper(); // 1. Cho phép đọc/ghi trực tiếp vào field (kể cả private) mà không cần Getter/Setter this.objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); // 2. Bỏ qua lỗi nếu JSON đầu vào có trường thừa mà Java class không có this.objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); } 3. AbstractDynamoRepository Generic Repository base class for DynamoDB. Provides standard CRUD operations, logging, and validation. @param Entity Type (Example: UserEntity) public abstract class AbstractDynamoRepository\u0026lt;T\u0026gt; { // Logger chuẩn cho môi trường Production protected final Logger logger = LoggerFactory.getLogger(getClass()); protected final DynamoDbTable\u0026lt;T\u0026gt; table; protected final String tableName; public AbstractDynamoRepository(DynamoDbEnhancedClient client, Class\u0026lt;T\u0026gt; type) { this.tableName = System.getenv(\u0026#34;TABLE_NAME\u0026#34;); // 1. Validate Config ngay khi khởi động if (this.tableName == null || this.tableName.isEmpty()) { logger.error(\u0026#34;CRITICAL: Biến môi trường TABLE_NAME chưa được cấu hình!\u0026#34;); throw new RuntimeException(\u0026#34;Missing TABLE_NAME environment variable\u0026#34;); } this.table = client.table(tableName, TableSchema.fromBean(type)); logger.info(\u0026#34;Initialized Repository for entity {} with table {}\u0026#34;, type.getSimpleName(), tableName); } // ================================================================================== // 1. CREATE / UPDATE (Upsert) // ================================================================================== /** * Lưu hoặc cập nhật một Item. * Trong DynamoDB, putItem sẽ ghi đè toàn bộ item nếu PK/SK trùng. */ public void save(T item) { if (item == null) { throw new IllegalArgumentException(\u0026#34;Entity to save cannot be null\u0026#34;); } try { logger.debug(\u0026#34;Saving item to table {}: {}\u0026#34;, tableName, item); table.putItem(item); logger.info(\u0026#34;Successfully saved item.\u0026#34;); } catch (DynamoDbException e) { logger.error(\u0026#34;Failed to save item to DynamoDB: {}\u0026#34;, e.getMessage(), e); throw new RuntimeException(\u0026#34;Database Error: Could not save item\u0026#34;, e); } } /** * Cập nhật item (Chỉ cập nhật các trường có giá trị, giữ nguyên các trường khác). * Yêu cầu Entity phải có đủ PK và SK. */ public T update(T item) { if (item == null) { throw new IllegalArgumentException(\u0026#34;Entity to update cannot be null\u0026#34;); } try { logger.debug(\u0026#34;Updating item in table {}: {}\u0026#34;, tableName, item); // updateItem sẽ trả về item đã được update T updatedItem = table.updateItem(item); logger.info(\u0026#34;Successfully updated item.\u0026#34;); return updatedItem; } catch (DynamoDbException e) { logger.error(\u0026#34;Failed to update item: {}\u0026#34;, e.getMessage(), e); throw new RuntimeException(\u0026#34;Database Error: Could not update item\u0026#34;, e); } } // ================================================================================== // 2. READ (Find) // ================================================================================== public T findById(String pk, String sk) { // Validate input if (pk == null || pk.isEmpty() || sk == null || sk.isEmpty()) { logger.warn(\u0026#34;FindById called with empty keys. PK: {}, SK: {}\u0026#34;, pk, sk); return null; // Hoặc throw Exception tùy logic nghiệp vụ } try { Key key = Key.builder().partitionValue(pk).sortValue(sk).build(); logger.debug(\u0026#34;Fetching item with PK: {}, SK: {}\u0026#34;, pk, sk); T item = table.getItem(key); if (item == null) { logger.info(\u0026#34;Item not found for PK: {}, SK: {}\u0026#34;, pk, sk); } else { logger.debug(\u0026#34;Item found: {}\u0026#34;, item); } return item; } catch (DynamoDbException e) { logger.error(\u0026#34;Failed to find item: {}\u0026#34;, e.getMessage(), e); throw new RuntimeException(\u0026#34;Database Error: Could not fetch item\u0026#34;, e); } } /** * Tìm tất cả các Item có cùng Partition Key (PK). * Đây là thao tác QUERY (Hiệu năng cao, rẻ tiền). * Ví dụ: Lấy tất cả Resume, Letter, Assessment của User X (PK=USER#X) */ public List\u0026lt;T\u0026gt; findAllByPartitionKey(String pk) { if (pk == null || pk.isEmpty()) return new ArrayList\u0026lt;\u0026gt;(); try { QueryConditional queryConditional = QueryConditional.keyEqualTo( Key.builder().partitionValue(pk).build() ); logger.debug(\u0026#34;Querying items with PK: {}\u0026#34;, pk); // SDK trả về Iterable (Lazy load), ta convert sang List để dễ dùng PageIterable\u0026lt;T\u0026gt; result = table.query(queryConditional); List\u0026lt;T\u0026gt; items = result.items().stream().collect(Collectors.toList()); logger.info(\u0026#34;Found {} items for PK: {}\u0026#34;, items.size(), pk); return items; } catch (DynamoDbException e) { logger.error(\u0026#34;Failed to query items by PK: {}\u0026#34;, e.getMessage(), e); throw new RuntimeException(\u0026#34;Database Error: Could not query items\u0026#34;, e); } } /** * ⚠️ CẢNH BÁO: Quét toàn bộ bảng (SCAN). * Rất tốn kém Read Capacity Unit (RCU) và chậm nếu bảng lớn. * Chỉ dùng cho các bảng nhỏ (như Industry) hoặc debug. */ public List\u0026lt;T\u0026gt; findAll() { try { logger.warn(\u0026#34;PERFORMANCE WARNING: Executing full table SCAN on {}\u0026#34;, tableName); return table.scan().items().stream().collect(Collectors.toList()); } catch (DynamoDbException e) { logger.error(\u0026#34;Failed to scan table: {}\u0026#34;, e.getMessage(), e); throw new RuntimeException(\u0026#34;Database Error: Could not scan table\u0026#34;, e); } } // ================================================================================== // 3. DELETE // ================================================================================== public T delete(String pk, String sk) { if (pk == null || sk == null) { throw new IllegalArgumentException(\u0026#34;Keys cannot be null for deletion\u0026#34;); } try { Key key = Key.builder().partitionValue(pk).sortValue(sk).build(); logger.info(\u0026#34;Deleting item with PK: {}, SK: {}\u0026#34;, pk, sk); // deleteItem trả về item cũ trước khi xóa (nếu có) return table.deleteItem(key); } catch (DynamoDbException e) { logger.error(\u0026#34;Failed to delete item: {}\u0026#34;, e.getMessage(), e); throw new RuntimeException(\u0026#34;Database Error: Could not delete item\u0026#34;, e); } } } 4. BedrockService This service class specializes in handling AI-related tasks.\n@Service public class BedrockService { private static final Logger logger = LoggerFactory.getLogger(BedrockService.class); private final BedrockRuntimeClient bedrockClient; private final ObjectMapper objectMapper; // Model ID lấy từ biến môi trường (Config trong template.yaml) private final String modelId = System.getenv(\u0026#34;BEDROCK_MODEL_ID\u0026#34;); public BedrockService(ObjectMapper objectMapper) { this.bedrockClient = BedrockRuntimeClient.builder().build(); // Tự lấy region từ môi trường this.objectMapper = objectMapper; } public IndustryInsightEntity generateIndustryInsights(String industry) { logger.info(\u0026#34;Calling AWS Bedrock to analyze industry: {}\u0026#34;, industry); String prompt = \u0026#34;\u0026#34;\u0026#34; Analyze the current state of the %s industry and provide insights in ONLY the following JSON format without any additional notes or explanations: { \u0026#34;salaryRanges\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;min\u0026#34;: number, \u0026#34;max\u0026#34;: number, \u0026#34;median\u0026#34;: number, \u0026#34;location\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;growthRate\u0026#34;: number, \u0026#34;demandLevel\u0026#34;: \u0026#34;High\u0026#34; | \u0026#34;Medium\u0026#34; | \u0026#34;Low\u0026#34;, \u0026#34;topSkills\u0026#34;: [\u0026#34;skill1\u0026#34;, \u0026#34;skill2\u0026#34;], \u0026#34;marketOutlook\u0026#34;: \u0026#34;Positive\u0026#34; | \u0026#34;Neutral\u0026#34; | \u0026#34;Negative\u0026#34;, \u0026#34;keyTrends\u0026#34;: [\u0026#34;trend1\u0026#34;, \u0026#34;trend2\u0026#34;], \u0026#34;recommendedSkills\u0026#34;: [\u0026#34;skill1\u0026#34;, \u0026#34;skill2\u0026#34;] } IMPORTANT: Return ONLY the JSON. No additional text, notes, or markdown formatting. Include at least 5 common roles for salary ranges. Growth rate should be a percentage float (e.g., 5.5). Include at least 5 skills and trends. \u0026#34;\u0026#34;\u0026#34;.formatted(industry); // Cấu trúc Body cho Claude 3 Map\u0026lt;String, Object\u0026gt; payload = Map.of( \u0026#34;anthropic_version\u0026#34;, \u0026#34;bedrock-2023-05-31\u0026#34;, \u0026#34;max_tokens\u0026#34;, 2000, \u0026#34;messages\u0026#34;, java.util.List.of( Map.of(\u0026#34;role\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;, prompt) ) ); try { String payloadJson = objectMapper.writeValueAsString(payload); InvokeModelRequest request = InvokeModelRequest.builder() .modelId(modelId) .body(SdkBytes.fromUtf8String(payloadJson)) .contentType(\u0026#34;application/json\u0026#34;) .accept(\u0026#34;application/json\u0026#34;) .build(); InvokeModelResponse response = bedrockClient.invokeModel(request); String responseBody = response.body().asString(StandardCharsets.UTF_8); // Parse response của Claude để lấy phần text // Structure: { \u0026#34;content\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;...\u0026#34; } ] } var jsonNode = objectMapper.readTree(responseBody); String aiText = jsonNode.get(\u0026#34;content\u0026#34;).get(0).get(\u0026#34;text\u0026#34;).asText(); // Clean text (remove markdown ```json ... ```) String cleanedJson = aiText.replaceAll(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;).replaceAll(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;).trim(); logger.debug(\u0026#34;Cleaned AI JSON: {}\u0026#34;, cleanedJson); // Parse thành Entity return objectMapper.readValue(cleanedJson, IndustryInsightEntity.class); } catch (Exception e) { logger.error(\u0026#34;Failed to generate AI insights\u0026#34;, e); throw new RuntimeException(\u0026#34;AI Generation Failed: \u0026#34; + e.getMessage()); } } /** * Hàm gọi AI trả về Text thuần (dùng cho Resume improvement) */ public String generateTextCorrection(String prompt) { logger.info(\u0026#34;Calling Bedrock for Text Generation...\u0026#34;); // Cấu trúc Body cho Claude 3 Map\u0026lt;String, Object\u0026gt; payload = Map.of( \u0026#34;anthropic_version\u0026#34;, \u0026#34;bedrock-2023-05-31\u0026#34;, \u0026#34;max_tokens\u0026#34;, 1000, \u0026#34;messages\u0026#34;, java.util.List.of( Map.of(\u0026#34;role\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;, prompt) ) ); try { String payloadJson = objectMapper.writeValueAsString(payload); InvokeModelRequest request = InvokeModelRequest.builder() .modelId(modelId) .body(SdkBytes.fromUtf8String(payloadJson)) .contentType(\u0026#34;application/json\u0026#34;) .accept(\u0026#34;application/json\u0026#34;) .build(); InvokeModelResponse response = bedrockClient.invokeModel(request); String responseBody = response.body().asString(StandardCharsets.UTF_8); // Parse response: { \u0026#34;content\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;...\u0026#34; } ] } var jsonNode = objectMapper.readTree(responseBody); String aiText = jsonNode.get(\u0026#34;content\u0026#34;).get(0).get(\u0026#34;text\u0026#34;).asText(); return aiText.trim(); } catch (Exception e) { logger.error(\u0026#34;Bedrock Text Generation Failed\u0026#34;, e); throw new RuntimeException(\u0026#34;AI Service Unavailable\u0026#34;); } } // Hàm mới: Tạo Quiz Questions public String generateQuizJson(String industry, String skills) { logger.info(\u0026#34;Generating Quiz for {} with skills {}\u0026#34;, industry, skills); String prompt = String.format(\u0026#34;\u0026#34;\u0026#34; Generate 10 technical interview questions for a %s professional with expertise in %s. Each question must be multiple choice with 4 options. Return the response in this JSON format only, no additional text, no markdown: { \u0026#34;questions\u0026#34;: [ { \u0026#34;question\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;options\u0026#34;: [\u0026#34;string\u0026#34;, \u0026#34;string\u0026#34;, \u0026#34;string\u0026#34;, \u0026#34;string\u0026#34;], \u0026#34;correctAnswer\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;explanation\u0026#34;: \u0026#34;string\u0026#34; } ] } \u0026#34;\u0026#34;\u0026#34;, industry, skills); return callBedrock(prompt); } // Hàm tái sử dụng logic gọi Bedrock private String callBedrock(String prompt) { // Logic giống hệt hàm generateTextCorrection cũ, chỉ thay prompt // (Bạn có thể refactor code cũ để dùng chung hàm này cho gọn) Map\u0026lt;String, Object\u0026gt; payload = Map.of( \u0026#34;anthropic_version\u0026#34;, \u0026#34;bedrock-2023-05-31\u0026#34;, \u0026#34;max_tokens\u0026#34;, 4000, // Tăng token vì JSON quiz khá dài \u0026#34;messages\u0026#34;, java.util.List.of(Map.of(\u0026#34;role\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;, prompt)) ); try { String payloadJson = objectMapper.writeValueAsString(payload); InvokeModelRequest request = InvokeModelRequest.builder() .modelId(modelId) .body(SdkBytes.fromUtf8String(payloadJson)) .contentType(\u0026#34;application/json\u0026#34;).accept(\u0026#34;application/json\u0026#34;).build(); InvokeModelResponse response = bedrockClient.invokeModel(request); String responseBody = response.body().asString(StandardCharsets.UTF_8); var jsonNode = objectMapper.readTree(responseBody); return jsonNode.get(\u0026#34;content\u0026#34;).get(0).get(\u0026#34;text\u0026#34;).asText().trim(); } catch (Exception e) { logger.error(\u0026#34;Bedrock Error\u0026#34;, e); throw new RuntimeException(\u0026#34;AI Error\u0026#34;); } } } Content of 5 Lambda Functions UserFunctions IndustryFunctions ResumeFuunctions CoverLetterFunctions AssessmentFunctions "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.4-backend-development/5.4.4-cover-letter-functions/","title":"Cover Letter Functions","tags":[],"description":"","content":"In this lesson, we will build the Cover Letter Generator feature.\nUnlike the Resume (CV), which is static data that rarely changes, the Cover Letter needs to be customized (\u0026ldquo;tailor\u0026rdquo;) for each company and applied position. This is very time-consuming if done manually, but it is a perfect problem for AI.\nData Flow Input: User provides Company Name, Position, and Job Description (JD). Process: Backend combines this information into a Prompt sent to Claude 3. Output: AI returns a sample letter. Backend saves to DB and returns to Frontend. 1. Model (Entity Layer) Since a user can create multiple cover letters for different companies, the SK (Sort Key) will be unique for each letter (using UUID).\n@Data @DynamoDbBean public class CoverLetterEntity { private String pk; // Format: USER#\u0026lt;cognito_sub\u0026gt; private String sk; // Format: LETTER#\u0026lt;uuid\u0026gt; private String content; // Markdown do AI Bedrock viết private String jobDescription; private String companyName; private String jobTitle; private String status; // \u0026#34;draft\u0026#34;, \u0026#34;completed\u0026#34; private String createdAt; private String updatedAt; @DynamoDbPartitionKey @DynamoDbAttribute(\u0026#34;PK\u0026#34;) public String getPk() { return pk; } @DynamoDbSortKey @DynamoDbAttribute(\u0026#34;SK\u0026#34;) public String getSk() { return sk; } } Key Strategy:\nPK: USER#{userId}. SK: LETTER#{uuid} (Example: LETTER#550e8400-e29b\u0026hellip;). 2. Repository (Data Access Layer) We need functions to Save, Retrieve the list, and Delete letters.\nInherits from the parent class AbstractDynamoRepository\n@Repository public class CoverLetterRepository extends AbstractDynamoRepository\u0026lt;CoverLetterEntity\u0026gt; { public CoverLetterRepository(DynamoDbEnhancedClient client) { super(client, CoverLetterEntity.class); } // Tìm tất cả Cover Letter của một User // PK: USER#\u0026lt;userId\u0026gt;, SK bắt đầu bằng LETTER# // Vì AbstractRepository đã có findAllByPartitionKey, ta chỉ cần gọi nó public List\u0026lt;CoverLetterEntity\u0026gt; findAllByUserId(String userId) { String pk = \u0026#34;USER#\u0026#34; + userId; // Lưu ý: findAllByPartitionKey sẽ lấy cả UserEntity và ResumeEntity nếu chung PK // Tuy nhiên, vì ta map TableSchema với CoverLetterEntity class, // SDK sẽ tự động filter hoặc map, nhưng để an toàn nhất với Single Table Design, // Ta nên dùng query với điều kiện SK begins_with \u0026#34;LETTER#\u0026#34; // (Để đơn giản trong demo này, giả sử hàm findAllByPartitionKey của bạn lọc được type, // hoặc ta chấp nhận lấy về rồi filter ở Service). // Cách tốt nhất: Viết query cụ thể ở đây return findAllByPartitionKey(pk); } public CoverLetterEntity findById(String userId, String letterId) { return super.findById(\u0026#34;USER#\u0026#34; + userId, \u0026#34;LETTER#\u0026#34; + letterId); } public void deleteById(String userId, String letterId) { super.delete(\u0026#34;USER#\u0026#34; + userId, \u0026#34;LETTER#\u0026#34; + letterId); } } 3. Service This is the most important part: How to talk to AI.\nCombine with BedrockService to implement the generateCoverLetter function using AI\n@Service public class CoverLetterService { private static final Logger logger = LoggerFactory.getLogger(CoverLetterService.class); private final CoverLetterRepository coverLetterRepository; private final UserRepository userRepository; private final BedrockService bedrockService; public CoverLetterService(CoverLetterRepository coverLetterRepository, UserRepository userRepository, BedrockService bedrockService) { this.coverLetterRepository = coverLetterRepository; this.userRepository = userRepository; this.bedrockService = bedrockService; } // 1. Generate Cover Letter (Create) public CoverLetterEntity generateCoverLetter(String userId, CoverLetterRequest request) { // Validate if (request.getJobTitle() == null || request.getCompanyName() == null || request.getJobDescription() == null) { throw new IllegalArgumentException(\u0026#34;Missing required fields (jobTitle, companyName, jobDescription)\u0026#34;); } // Lấy thông tin User để AI viết cho chuẩn UserEntity user = userRepository.findById(\u0026#34;USER#\u0026#34; + userId, \u0026#34;METADATA\u0026#34;); if (user == null) throw new RuntimeException(\u0026#34;User not found\u0026#34;); String skills = user.getSkills() != null ? String.join(\u0026#34;, \u0026#34;, user.getSkills()) : \u0026#34;Not specified\u0026#34;; // Prompt Engineering (Copy từ logic cũ của bạn) String prompt = String.format(\u0026#34;\u0026#34;\u0026#34; Write a professional cover letter for a %s position at %s. About the candidate: - Industry: %s - Years of Experience: %d - Skills: %s - Professional Background: %s Job Description: %s Requirements: 1. Use a professional, enthusiastic tone 2. Highlight relevant skills and experience 3. Show understanding of the company\u0026#39;s needs 4. Keep it concise (max 400 words) 5. Use proper business letter formatting in markdown 6. Include specific examples of achievements 7. Relate candidate\u0026#39;s background to job requirements Format the letter in markdown. Do not include any preamble or postscript. \u0026#34;\u0026#34;\u0026#34;, request.getJobTitle(), request.getCompanyName(), user.getIndustry(), user.getExperience(), skills, user.getBio(), request.getJobDescription() ); // Gọi Bedrock String aiContent = bedrockService.generateTextCorrection(prompt); // Tạo Entity lưu xuống DB CoverLetterEntity entity = new CoverLetterEntity(); String letterId = UUID.randomUUID().toString(); entity.setPk(\u0026#34;USER#\u0026#34; + userId); entity.setSk(\u0026#34;LETTER#\u0026#34; + letterId); // SK unique entity.setContent(aiContent); entity.setJobTitle(request.getJobTitle()); entity.setCompanyName(request.getCompanyName()); entity.setJobDescription(request.getJobDescription()); entity.setStatus(\u0026#34;completed\u0026#34;); entity.setCreatedAt(Instant.now().toString()); entity.setUpdatedAt(Instant.now().toString()); coverLetterRepository.save(entity); logger.info(\u0026#34;Generated cover letter {} for user {}\u0026#34;, letterId, userId); return entity; } // 2. Get All public List\u0026lt;CoverLetterEntity\u0026gt; getAllCoverLetters(String userId) { // Lấy về tất cả item của user, sau đó lọc ra những cái là Cover Letter // (Trong môi trường production nên dùng Query SK begins_with \u0026#34;LETTER#\u0026#34; để tối ưu) List\u0026lt;CoverLetterEntity\u0026gt; allItems = coverLetterRepository.findAllByUserId(userId); return allItems.stream() .filter(item -\u0026gt; item.getSk().startsWith(\u0026#34;LETTER#\u0026#34;)) .collect(Collectors.toList()); } // 3. Get One public CoverLetterEntity getCoverLetter(String userId, String letterId) { return coverLetterRepository.findById(userId, letterId); } // 4. Delete public void deleteCoverLetter(String userId, String letterId) { coverLetterRepository.deleteById(userId, letterId); logger.info(\u0026#34;Deleted cover letter {} for user {}\u0026#34;, letterId, userId); } } 4. Function (Router Layer) This function needs to handle more API Endpoints (List, Get One, Create, Delete).\n@Configuration public class CoverLetterFunctions { private static final Logger logger = LoggerFactory.getLogger(CoverLetterFunctions.class); private final CoverLetterService coverLetterService; private final ObjectMapper objectMapper; public CoverLetterFunctions(CoverLetterService coverLetterService) { this.coverLetterService = coverLetterService; // --- CẤU HÌNH JACKSON THỦ CÔNG (QUAN TRỌNG) --- // Giúp serialize được các object không có getter/setter chuẩn hoặc field private this.objectMapper = new ObjectMapper(); this.objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); this.objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); } /** * HÀM TỔNG (ROUTER) * Phân phối request dựa trên Path và Method */ @Bean public Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; coverLetterHandler() { return event -\u0026gt; { try { // 1. Trích xuất thông tin Request String path = extractPath(event); String method = extractHttpMethod(event); logger.info(\u0026#34;CoverLetter Router -\u0026gt; Path: [{}], Method: [{}]\u0026#34;, path, method); // 2. Xác thực User (Auth) Map\u0026lt;String, String\u0026gt; headers = normalizeHeaders(event); String userId = extractUserIdOrThrow(headers); // 3. Phân luồng xử lý (Routing) // Case 1: GET /cover-letters (List All) if (path.endsWith(\u0026#34;/cover-letters\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(method)) { return handleListCoverLetters(userId); } // Case 2: POST /cover-letters (Generate) if (path.endsWith(\u0026#34;/cover-letters\u0026#34;) \u0026amp;\u0026amp; \u0026#34;POST\u0026#34;.equalsIgnoreCase(method)) { return handleGenerateCoverLetter(userId, event); } // Case 3: GET /cover-letters/{id} (Get One) if (path.contains(\u0026#34;/cover-letters/\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(method)) { String id = extractId(event, path); return handleGetOneCoverLetter(userId, id); } // Case 4: DELETE /cover-letters/{id} if (path.contains(\u0026#34;/cover-letters/\u0026#34;) \u0026amp;\u0026amp; \u0026#34;DELETE\u0026#34;.equalsIgnoreCase(method)) { String id = extractId(event, path); return handleDeleteCoverLetter(userId, id); } return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Route not found: \u0026#34; + path)); } catch (SecurityException e) { logger.warn(\u0026#34;Auth Error: {}\u0026#34;, e.getMessage()); return buildResponse(401, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (IllegalArgumentException e) { logger.warn(\u0026#34;Validation Error: {}\u0026#34;, e.getMessage()); return buildResponse(400, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (Exception e) { logger.error(\u0026#34;System Error\u0026#34;, e); return buildResponse(500, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } }; } // ========================================================================= // LOGIC CON (SUB-HANDLERS) // ========================================================================= private Map\u0026lt;String, Object\u0026gt; handleListCoverLetters(String userId) { logger.info(\u0026#34;Fetching all cover letters for user: {}\u0026#34;, userId); List\u0026lt;CoverLetterEntity\u0026gt; list = coverLetterService.getAllCoverLetters(userId); return buildResponse(200, list); } private Map\u0026lt;String, Object\u0026gt; handleGenerateCoverLetter(String userId, Map\u0026lt;String, Object\u0026gt; event) throws Exception { String bodyString = extractBodyContent(event); if (bodyString == null || bodyString.trim().isEmpty()) { throw new IllegalArgumentException(\u0026#34;Request body is required\u0026#34;); } logger.debug(\u0026#34;Generating cover letter with body: {}\u0026#34;, bodyString); CoverLetterRequest req = objectMapper.readValue(bodyString, CoverLetterRequest.class); CoverLetterEntity created = coverLetterService.generateCoverLetter(userId, req); logger.info(\u0026#34;Successfully generated cover letter. ID: {}\u0026#34;, created.getSk()); return buildResponse(200, created); } private Map\u0026lt;String, Object\u0026gt; handleGetOneCoverLetter(String userId, String letterId) { if (letterId == null || letterId.isEmpty()) throw new IllegalArgumentException(\u0026#34;ID is missing\u0026#34;); logger.info(\u0026#34;Fetching cover letter ID: {}\u0026#34;, letterId); CoverLetterEntity item = coverLetterService.getCoverLetter(userId, letterId); if (item == null) { return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Cover letter not found\u0026#34;)); } return buildResponse(200, item); } private Map\u0026lt;String, Object\u0026gt; handleDeleteCoverLetter(String userId, String letterId) { if (letterId == null || letterId.isEmpty()) throw new IllegalArgumentException(\u0026#34;ID is missing\u0026#34;); logger.info(\u0026#34;Deleting cover letter ID: {}\u0026#34;, letterId); coverLetterService.deleteCoverLetter(userId, letterId); return buildResponse(200, Map.of(\u0026#34;status\u0026#34;, \u0026#34;deleted\u0026#34;, \u0026#34;id\u0026#34;, letterId)); } // ========================================================================= // HELPERS (Tiện ích) // ========================================================================= private String extractId(Map\u0026lt;String, Object\u0026gt; event, String path) { // Ưu tiên lấy từ Path Parameters của API Gateway if (event.get(\u0026#34;pathParameters\u0026#34;) instanceof Map) { Map\u0026lt;?, ?\u0026gt; params = (Map\u0026lt;?, ?\u0026gt;) event.get(\u0026#34;pathParameters\u0026#34;); if (params != null \u0026amp;\u0026amp; params.get(\u0026#34;id\u0026#34;) != null) { return params.get(\u0026#34;id\u0026#34;).toString(); } } // Fallback: Cắt chuỗi URL String[] parts = path.split(\u0026#34;/\u0026#34;); return parts.length \u0026gt; 0 ? parts[parts.length - 1] : null; } private String extractPath(Map\u0026lt;String, Object\u0026gt; event) { return event.get(\u0026#34;rawPath\u0026#34;) != null ? event.get(\u0026#34;rawPath\u0026#34;).toString() : \u0026#34;\u0026#34;; } private String extractHttpMethod(Map\u0026lt;String, Object\u0026gt; event) { try { Map req = (Map) event.get(\u0026#34;requestContext\u0026#34;); if (req != null) { Map http = (Map) req.get(\u0026#34;http\u0026#34;); if (http != null) return http.get(\u0026#34;method\u0026#34;).toString(); } } catch (Exception e) { /* ignore */ } return \u0026#34;GET\u0026#34;; } private Map\u0026lt;String, String\u0026gt; normalizeHeaders(Map\u0026lt;String, Object\u0026gt; event) { Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); Object headersObj = event.get(\u0026#34;headers\u0026#34;); if (headersObj instanceof Map) { Map\u0026lt;?, ?\u0026gt; rawMap = (Map\u0026lt;?, ?\u0026gt;) headersObj; for (Map.Entry\u0026lt;?, ?\u0026gt; entry : rawMap.entrySet()) { if (entry.getKey() != null \u0026amp;\u0026amp; entry.getValue() != null) { headers.put(entry.getKey().toString().toLowerCase(), entry.getValue().toString()); } } } return headers; } private String extractUserIdOrThrow(Map\u0026lt;String, String\u0026gt; headers) { String authHeader = headers.get(\u0026#34;authorization\u0026#34;); if (authHeader == null || !authHeader.startsWith(\u0026#34;Bearer \u0026#34;)) { throw new SecurityException(\u0026#34;Missing or invalid Authorization header\u0026#34;); } try { String token = authHeader.substring(7); String[] parts = token.split(\u0026#34;\\\\.\u0026#34;); if (parts.length \u0026lt; 2) throw new SecurityException(\u0026#34;Invalid JWT format\u0026#34;); // Dùng getUrlDecoder cho JWT String payloadJson = new String(Base64.getUrlDecoder().decode(parts[1])); return objectMapper.readTree(payloadJson).get(\u0026#34;sub\u0026#34;).asText(); } catch (Exception e) { logger.error(\u0026#34;Token decode error\u0026#34;, e); throw new SecurityException(\u0026#34;Token validation failed\u0026#34;); } } private String extractBodyContent(Map\u0026lt;String, Object\u0026gt; event) { Object bodyObj = event.get(\u0026#34;body\u0026#34;); if (bodyObj == null) return null; String bodyString; if (bodyObj instanceof String) { bodyString = (String) bodyObj; } else { try { bodyString = objectMapper.writeValueAsString(bodyObj); } catch (Exception e) { return \u0026#34;{}\u0026#34;; } } Object isBase64Obj = event.get(\u0026#34;isBase64Encoded\u0026#34;); if (isBase64Obj != null \u0026amp;\u0026amp; Boolean.parseBoolean(isBase64Obj.toString())) { try { bodyString = new String(Base64.getDecoder().decode(bodyString)); } catch (Exception e) { throw new RuntimeException(\u0026#34;Invalid Base64 body\u0026#34;); } } return bodyString; } private Map\u0026lt;String, Object\u0026gt; buildResponse(int statusCode, Object body) { Map\u0026lt;String, Object\u0026gt; response = new HashMap\u0026lt;\u0026gt;(); response.put(\u0026#34;statusCode\u0026#34;, statusCode); response.put(\u0026#34;headers\u0026#34;, Map.of(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;)); try { // Dùng objectMapper thủ công để serialize (tránh lỗi ClassCastException) response.put(\u0026#34;body\u0026#34;, objectMapper.writeValueAsString(body)); } catch (Exception e) { response.put(\u0026#34;statusCode\u0026#34;, 500); response.put(\u0026#34;body\u0026#34;, \u0026#34;{\\\u0026#34;error\\\u0026#34;: \\\u0026#34;JSON Serialization Error\\\u0026#34;}\u0026#34;); } return response; } } "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"AWS First Cloud Journey Workforce OJT Fall 2025 Kick-off Event Name: AWS First Cloud Journey Workforce OJT Fall 2025 Kick-off\nDate \u0026amp; Time: 09:00, September 06, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.4-week4/","title":"Worklog Week 4","tags":[],"description":"","content":"Week 4 Objectives: Understand and practice AWS core storage and content delivery services including S3, CloudFront, Cloud9, RDS, and Lightsail. Learn how to deploy, manage, and secure data in Amazon S3 (including Website Hosting, Versioning, and Cross-Region Replication). Understand how to deploy static and dynamic web applications using S3 + CloudFront + RDS + EC2. Get familiar with the AWS Cloud9 cloud development environment and understand the AWS Well-Architected Framework for optimal system design. Learn how to quickly deploy open-source applications (WordPress, PrestaShop) using Amazon Lightsail. Tasks for this week: Day Task Start Date End Date Reference 2 - Study the basics of AWS Cloud9 and practice: + Create a Cloud9 instance + Use the command line + Work with text files + Use AWS CLI on AWS Cloud9 - Learn the basics of AWS S3 + Concept and purpose of Object Storage + Structure of Bucket and Object + Common Storage Classes + Manage access control and data sharing (Public Access, Bucket Policy) - Practice: + Create an S3 Bucket + Upload data to S3 Bucket + Enable Static Website Hosting + Configure Block Public Access + Configure public object access + Verify hosted Website 29/09/2025 29/09/2025 cloudjourney.awsstudygroup.com 3 - Study the basics of Amazon CloudFront + Understand CDN concepts and CloudFront’s role in content delivery + Basic structure: Origin, Distribution, Edge Location + How CloudFront accelerates S3 content delivery - Learn about S3 Versioning + Key benefits of Versioning + How Versioning works + Versioning states - Practice: + Block all public access to S3 + Create CloudFront Distribution serving an S3 Bucket + Test Amazon CloudFront + Enable Versioning for the Bucket and update content + Test Versioning on S3 and CloudFront 30/09/2025 30/09/2025 cloudjourney.awsstudygroup.com and aws.amazon.com/cloudfront 4 - Learn about Amazon S3 Cross-Region Replication (CRR): + Key benefits + How CRR works - Study the AWS Well-Architected Framework: + Concept and six pillars of AWS Well-Architected Framework + Well-Architected Lenses - Practice: + Move objects to a new Bucket + Replicate S3 objects to another Region - Study Best Practices \u0026amp; Troubleshooting for AWS S3: + Security + Performance + Cost optimization + Common issues and resolutions 01/10/2025 01/10/2025 cloudjourney.awsstudygroup.com and aws.amazon.com/architecture/well-architected 5 - Study the basics of Amazon RDS: + Introduction to Relational Database Service + Supported database engines (MySQL, PostgreSQL, MariaDB, etc.) + Basic structure: DB Instance, Subnet Group, Security Group - Practice: + Create VPC and Security Groups for EC2 and RDS + Create a DB Subnet Group + Launch an EC2 instance + Create an RDS database instance + Deploy an application + Perform Backup and Restore in Amazon RDS 02/10/2025 03/10/2025 cloudjourney.awsstudygroup.com 6 - Practice: Deploy open-source applications on Amazon Lightsail and configure resources: + Deploy a database on Lightsail + Deploy a WordPress server + Configure Ubuntu + Configure Networking + Configure WordPress + Deploy PrestaShop E-Commerce instance 03/10/2025 03/10/2025 cloudjourney.awsstudygroup.com Week 4 Achievements: Became familiar with AWS Cloud9, used the CLI, and managed resources through the cloud development environment. Gained a solid understanding of Amazon S3 — created and configured Buckets, hosted a static website, enabled Block Public Access and Versioning. Understood global content delivery with Amazon CloudFront and integrated it with S3 to accelerate and secure websites. Learned and practiced S3 Cross-Region Replication (CRR), applying best practices for security, performance, and cost optimization. Deployed and connected Amazon RDS with EC2 instances, performed database Backup and Restore successfully. Studied the AWS Well-Architected Framework and understood its six architectural pillars. Successfully deployed and configured WordPress and PrestaShop applications on Amazon Lightsail, mastering resource management and basic security. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.4-backend-development/5.4.5-assessment-functions/","title":"Assessment Functions","tags":[],"description":"","content":"The AssessmentFunctions function acts as a virtual interviewer. It performs two main tasks:\nGenerate Quiz: Generates a \u0026ldquo;fresh\u0026rdquo; set of multiple-choice questions each time, based on the user\u0026rsquo;s industry. Save \u0026amp; History: Saves test results so users can track their progress via charts. 1. Model (Entity Layer) We need to store the results of each interview session.\n@Data @DynamoDbBean public class AssessmentEntity { private String pk; // Format: USER#\u0026lt;cognito_sub\u0026gt; private String sk; // Format: ASSESS#\u0026lt;uuid\u0026gt; private Double quizScore; private String category; // \u0026#34;Technical\u0026#34;, \u0026#34;Behavioral\u0026#34; private String improvementTip; // AI Bedrock generated tip // Nested Object List (JSON) private List\u0026lt;QuestionItem\u0026gt; questions; private String createdAt; private String updatedAt; @DynamoDbPartitionKey @DynamoDbAttribute(\u0026#34;PK\u0026#34;) public String getPk() { return pk; } @DynamoDbSortKey @DynamoDbAttribute(\u0026#34;SK\u0026#34;) public String getSk() { return sk; } // Inner Class cho cấu trúc câu hỏi @Data @DynamoDbBean public static class QuestionItem { private String question; private String answer; // Đáp án mẫu private String userAnswer; // Câu trả lời của user private Boolean isCorrect; private String explanation; // AI giải thích tại sao đúng/sai } } Key Strategy:\nPK: USER#{userId}. SK: ASSESSMENT#{timestamp} (Use timestamp to sort history chronologically). 2. Repository (Data Access Layer) Inherits from the parent class AbstractDynamoRepository\n@Repository public class AssessmentRepository extends AbstractDynamoRepository\u0026lt;AssessmentEntity\u0026gt; { public AssessmentRepository(DynamoDbEnhancedClient client) { super(client, AssessmentEntity.class); } // Lấy lịch sử làm bài của User public List\u0026lt;AssessmentEntity\u0026gt; findAllByUserId(String userId) { // Query theo PK = USER#\u0026lt;id\u0026gt;, sau đó lọc SK bắt đầu bằng ASSESS# // (Cách tối ưu hơn là dùng Query Conditional BeginsWith trong SDK, // nhưng dùng findAllByPartitionKey lọc mềm cũng ổn với số lượng ít) List\u0026lt;AssessmentEntity\u0026gt; allItems = findAllByPartitionKey(\u0026#34;USER#\u0026#34; + userId); return allItems.stream() .filter(item -\u0026gt; item.getSk() != null \u0026amp;\u0026amp; item.getSk().startsWith(\u0026#34;ASSESS#\u0026#34;)) // Sắp xếp theo ngày tạo (Mới nhất lên đầu) - Logic Java .sorted((a, b) -\u0026gt; b.getCreatedAt().compareTo(a.getCreatedAt())) .collect(Collectors.toList()); } } 3. Service Combine with BedrockService to implement the generateQuiz function using AI\n@Service public class AssessmentService { private static final Logger logger = LoggerFactory.getLogger(AssessmentService.class); private final AssessmentRepository assessmentRepository; private final UserRepository userRepository; private final BedrockService bedrockService; private final ObjectMapper objectMapper; public AssessmentService(AssessmentRepository assessmentRepository, UserRepository userRepository, BedrockService bedrockService, ObjectMapper objectMapper) { this.assessmentRepository = assessmentRepository; this.userRepository = userRepository; this.bedrockService = bedrockService; this.objectMapper = objectMapper; } // 1. Generate Quiz public List\u0026lt;QuizQuestion\u0026gt; generateQuiz(String userId) { // Lấy thông tin User UserEntity user = userRepository.findById(\u0026#34;USER#\u0026#34; + userId, \u0026#34;METADATA\u0026#34;); if (user == null) throw new RuntimeException(\u0026#34;User not found\u0026#34;); String industry = user.getIndustry(); String skills = user.getSkills() != null ? String.join(\u0026#34;, \u0026#34;, user.getSkills()) : \u0026#34;\u0026#34;; // Gọi AI String jsonResponse = bedrockService.generateQuizJson(industry, skills); // Parse JSON trả về List Questions try { // Claude có thể trả về text kèm markdown, cần clean String cleanedJson = jsonResponse.replaceAll(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;).replaceAll(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;).trim(); JsonNode root = objectMapper.readTree(cleanedJson); JsonNode questionsNode = root.get(\u0026#34;questions\u0026#34;); return Arrays.asList(objectMapper.treeToValue(questionsNode, QuizQuestion[].class)); } catch (Exception e) { logger.error(\u0026#34;Failed to parse Quiz JSON\u0026#34;, e); throw new RuntimeException(\u0026#34;Failed to parse AI response\u0026#34;); } } // 2. Save Result \u0026amp; Generate Tip public AssessmentEntity saveQuizResult(String userId, SaveAssessmentRequest request) { UserEntity user = userRepository.findById(\u0026#34;USER#\u0026#34; + userId, \u0026#34;METADATA\u0026#34;); if (user == null) throw new RuntimeException(\u0026#34;User not found\u0026#34;); List\u0026lt;QuestionItem\u0026gt; questionResults = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; wrongAnswersText = new ArrayList\u0026lt;\u0026gt;(); // Map DTO sang Entity và tìm câu sai for (int i = 0; i \u0026lt; request.getQuestions().size(); i++) { QuizQuestion q = request.getQuestions().get(i); String userAnswer = request.getUserAnswers().get(i); boolean isCorrect = q.getCorrectAnswer().equals(userAnswer); QuestionItem item = new QuestionItem(); item.setQuestion(q.getQuestion()); item.setAnswer(q.getCorrectAnswer()); item.setUserAnswer(userAnswer); item.setIsCorrect(isCorrect); item.setExplanation(q.getExplanation()); questionResults.add(item); if (!isCorrect) { wrongAnswersText.add(String.format(\u0026#34;Question: \\\u0026#34;%s\\\u0026#34;\\nCorrect: \\\u0026#34;%s\\\u0026#34;\\nUser Answer: \\\u0026#34;%s\\\u0026#34;\u0026#34;, q.getQuestion(), q.getCorrectAnswer(), userAnswer)); } } // Tạo Improvement Tip nếu có câu sai String improvementTip = null; if (!wrongAnswersText.isEmpty()) { String prompt = String.format(\u0026#34;\u0026#34;\u0026#34; The user got the following %s technical interview questions wrong: %s Based on these mistakes, provide a concise, specific improvement tip. Focus on knowledge gaps. Keep it under 2 sentences. Encouraging tone. \u0026#34;\u0026#34;\u0026#34;, user.getIndustry(), String.join(\u0026#34;\\n\\n\u0026#34;, wrongAnswersText)); improvementTip = bedrockService.generateTextCorrection(prompt); // Tái sử dụng hàm sinh text } // Lưu DB AssessmentEntity entity = new AssessmentEntity(); entity.setPk(\u0026#34;USER#\u0026#34; + userId); entity.setSk(\u0026#34;ASSESS#\u0026#34; + UUID.randomUUID().toString()); entity.setQuizScore(request.getScore()); entity.setCategory(\u0026#34;Technical\u0026#34;); entity.setImprovementTip(improvementTip); entity.setQuestions(questionResults); // DynamoDB Enhanced tự convert List sang JSON entity.setCreatedAt(Instant.now().toString()); entity.setUpdatedAt(Instant.now().toString()); assessmentRepository.save(entity); return entity; } // 3. Get History public List\u0026lt;AssessmentEntity\u0026gt; getAssessments(String userId) { return assessmentRepository.findAllByUserId(userId); } } 4. Function (Router Layer) This function handles 3 different endpoints for the interview process.\n@Configuration public class AssessmentFunctions { private static final Logger logger = LoggerFactory.getLogger(AssessmentFunctions.class); private final AssessmentService assessmentService; private final ObjectMapper objectMapper; public AssessmentFunctions(AssessmentService assessmentService) { this.assessmentService = assessmentService; // --- CẤU HÌNH JACKSON THỦ CÔNG --- // Đảm bảo parse được mọi loại object, kể cả private fields this.objectMapper = new ObjectMapper(); this.objectMapper.setVisibility(PropertyAccessor.FIELD, JsonAutoDetect.Visibility.ANY); this.objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); } /** * HÀM TỔNG (ROUTER) CHO ASSESSMENT */ @Bean public Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; assessmentHandler() { return event -\u0026gt; { try { // 1. Trích xuất thông tin Request String path = extractPath(event); String method = extractHttpMethod(event); logger.info(\u0026#34;Assessment Router -\u0026gt; Path: [{}], Method: [{}]\u0026#34;, path, method); // 2. Xác thực User (Auth) Map\u0026lt;String, String\u0026gt; headers = normalizeHeaders(event); String userId = extractUserIdOrThrow(headers); // 3. Phân luồng xử lý (Routing) // Case 1: POST /interview/generate (Generate Quiz) if (path.endsWith(\u0026#34;/interview/generate\u0026#34;) \u0026amp;\u0026amp; \u0026#34;POST\u0026#34;.equalsIgnoreCase(method)) { return handleGenerateQuiz(userId); } // Case 2: POST /interview/save (Save Result) if (path.endsWith(\u0026#34;/interview/save\u0026#34;) \u0026amp;\u0026amp; \u0026#34;POST\u0026#34;.equalsIgnoreCase(method)) { return handleSaveQuizResult(userId, event); } // Case 3: GET /interview/history (Get List) if (path.endsWith(\u0026#34;/interview/history\u0026#34;) \u0026amp;\u0026amp; \u0026#34;GET\u0026#34;.equalsIgnoreCase(method)) { return handleGetAssessmentHistory(userId); } return buildResponse(404, Map.of(\u0026#34;error\u0026#34;, \u0026#34;Route not found: \u0026#34; + path)); } catch (SecurityException e) { logger.warn(\u0026#34;Auth Error: {}\u0026#34;, e.getMessage()); return buildResponse(401, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (IllegalArgumentException e) { logger.warn(\u0026#34;Validation Error: {}\u0026#34;, e.getMessage()); return buildResponse(400, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } catch (Exception e) { logger.error(\u0026#34;System Error\u0026#34;, e); return buildResponse(500, Map.of(\u0026#34;error\u0026#34;, e.getMessage())); } }; } // ========================================================================= // LOGIC CON (SUB-HANDLERS) // ========================================================================= private Map\u0026lt;String, Object\u0026gt; handleGenerateQuiz(String userId) { logger.info(\u0026#34;Generating interview quiz for user: {}\u0026#34;, userId); // Gọi Service (Có thể mất thời gian do gọi AI) List\u0026lt;QuizQuestion\u0026gt; quiz = assessmentService.generateQuiz(userId); logger.info(\u0026#34;Generated {} questions successfully.\u0026#34;, quiz.size()); return buildResponse(200, Map.of(\u0026#34;questions\u0026#34;, quiz)); } private Map\u0026lt;String, Object\u0026gt; handleSaveQuizResult(String userId, Map\u0026lt;String, Object\u0026gt; event) throws Exception { String bodyString = extractBodyContent(event); if (bodyString == null || bodyString.trim().isEmpty()) { throw new IllegalArgumentException(\u0026#34;Request body is required for saving result\u0026#34;); } logger.debug(\u0026#34;Saving quiz result payload: {}\u0026#34;, bodyString); // Parse JSON sang DTO SaveAssessmentRequest req = objectMapper.readValue(bodyString, SaveAssessmentRequest.class); // Validate cơ bản DTO if (req.getQuestions() == null || req.getQuestions().isEmpty()) { throw new IllegalArgumentException(\u0026#34;Questions list cannot be empty\u0026#34;); } // Gọi Service AssessmentEntity result = assessmentService.saveQuizResult(userId, req); logger.info(\u0026#34;Saved assessment result ID: {}\u0026#34;, result.getSk()); return buildResponse(200, result); } private Map\u0026lt;String, Object\u0026gt; handleGetAssessmentHistory(String userId) { logger.info(\u0026#34;Fetching assessment history for user: {}\u0026#34;, userId); List\u0026lt;AssessmentEntity\u0026gt; list = assessmentService.getAssessments(userId); logger.info(\u0026#34;Found {} past assessments.\u0026#34;, list.size()); return buildResponse(200, list); } // ========================================================================= // HELPERS (Tiện ích - Copy y hệt từ các file trước) // ========================================================================= private String extractPath(Map\u0026lt;String, Object\u0026gt; event) { return event.get(\u0026#34;rawPath\u0026#34;) != null ? event.get(\u0026#34;rawPath\u0026#34;).toString() : \u0026#34;\u0026#34;; } private String extractHttpMethod(Map\u0026lt;String, Object\u0026gt; event) { try { Map req = (Map) event.get(\u0026#34;requestContext\u0026#34;); if (req != null) { Map http = (Map) req.get(\u0026#34;http\u0026#34;); if (http != null) return http.get(\u0026#34;method\u0026#34;).toString(); } } catch (Exception e) { /* ignore */ } return \u0026#34;GET\u0026#34;; } private Map\u0026lt;String, String\u0026gt; normalizeHeaders(Map\u0026lt;String, Object\u0026gt; event) { Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); Object headersObj = event.get(\u0026#34;headers\u0026#34;); if (headersObj instanceof Map) { Map\u0026lt;?, ?\u0026gt; rawMap = (Map\u0026lt;?, ?\u0026gt;) headersObj; for (Map.Entry\u0026lt;?, ?\u0026gt; entry : rawMap.entrySet()) { if (entry.getKey() != null \u0026amp;\u0026amp; entry.getValue() != null) { headers.put(entry.getKey().toString().toLowerCase(), entry.getValue().toString()); } } } return headers; } private String extractUserIdOrThrow(Map\u0026lt;String, String\u0026gt; headers) { String authHeader = headers.get(\u0026#34;authorization\u0026#34;); if (authHeader == null || !authHeader.startsWith(\u0026#34;Bearer \u0026#34;)) { throw new SecurityException(\u0026#34;Missing or invalid Authorization header\u0026#34;); } try { String token = authHeader.substring(7); String[] parts = token.split(\u0026#34;\\\\.\u0026#34;); if (parts.length \u0026lt; 2) throw new SecurityException(\u0026#34;Invalid JWT format\u0026#34;); // Dùng getUrlDecoder cho JWT chuẩn String payloadJson = new String(Base64.getUrlDecoder().decode(parts[1])); return objectMapper.readTree(payloadJson).get(\u0026#34;sub\u0026#34;).asText(); } catch (Exception e) { logger.error(\u0026#34;Token decode error\u0026#34;, e); throw new SecurityException(\u0026#34;Token validation failed\u0026#34;); } } private String extractBodyContent(Map\u0026lt;String, Object\u0026gt; event) { Object bodyObj = event.get(\u0026#34;body\u0026#34;); if (bodyObj == null) return null; String bodyString; if (bodyObj instanceof String) { bodyString = (String) bodyObj; } else { try { bodyString = objectMapper.writeValueAsString(bodyObj); } catch (Exception e) { return \u0026#34;{}\u0026#34;; } } Object isBase64Obj = event.get(\u0026#34;isBase64Encoded\u0026#34;); if (isBase64Obj != null \u0026amp;\u0026amp; Boolean.parseBoolean(isBase64Obj.toString())) { try { bodyString = new String(Base64.getDecoder().decode(bodyString)); } catch (Exception e) { throw new RuntimeException(\u0026#34;Invalid Base64 body\u0026#34;); } } return bodyString; } private Map\u0026lt;String, Object\u0026gt; buildResponse(int statusCode, Object body) { Map\u0026lt;String, Object\u0026gt; response = new HashMap\u0026lt;\u0026gt;(); response.put(\u0026#34;statusCode\u0026#34;, statusCode); response.put(\u0026#34;headers\u0026#34;, Map.of(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;)); try { // Dùng objectMapper thủ công để serialize response.put(\u0026#34;body\u0026#34;, objectMapper.writeValueAsString(body)); } catch (Exception e) { response.put(\u0026#34;statusCode\u0026#34;, 500); response.put(\u0026#34;body\u0026#34;, \u0026#34;{\\\u0026#34;error\\\u0026#34;: \\\u0026#34;JSON Serialization Error\\\u0026#34;}\u0026#34;); } return response; } } "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.5-frontend-development/","title":"Frontend Development","tags":[],"description":"","content":"The AI Career Coach Frontend not only needs to be beautiful but also must handle complex logic like a Markdown Editor, Quiz Game, and secure API calls.\nView the full Frontend source code here\nBelow I only present the key points and what to keep in mind when building the frontend.\n1. Project Initialization (Tech Stack Setup) We use Vite to initialize the React project because of its extremely fast build speed.\nMain libraries: Tailwind CSS: A utility-first CSS Framework. Shadcn UI: A beautiful component library (Button, Input, Card, Accordion\u0026hellip;) that helps us avoid coding CSS from scratch. AWS Amplify: A library that helps connect React with Cognito easily. React Router Dom: To navigate between pages. npm create vite@latest frontend -- --template react cd frontend npm install Libraries to install\nnpm install react-router-dom aws-amplify @aws-amplify/ui-react lucide-react react-hook-form zod @hookform/resolvers sonner @uiw/react-md-editor recharts html2pdf.js react-spinners date-fns clsx tailwind-merge class-variance-authority 2. Authentication Configuration with AWS Amplify Instead of manually writing complex Login/Register pages, we use Amplify\u0026rsquo;s \u0026lt;Authenticator\u0026gt; component. It automatically generates a fully functional login/registration interface.\nConfiguration in main.jsx: You need to get the UserPoolId and ClientId from the Output section of the sam deploy command in the previous lesson to fill in here.\nimport { Amplify } from \u0026#39;aws-amplify\u0026#39;; Amplify.configure({ Auth: { Cognito: { userPoolId: \u0026#39;ap-southeast-1_XXXXXXX\u0026#39;, // \u0026lt;-- Thay bằng ID của bạn userPoolClientId: \u0026#39;xxxxxxxxxxxxxxxxx\u0026#39;, // \u0026lt;-- Thay bằng Client ID của bạn loginWith: { email: true } } } }); 3. apiClient This is the most critical part of the integration.\nThe Problem:\nWhen the Java Backend returns data, it sometimes returns a JSON string nested within another JSON string (Double Serialization).\nExample Backend response: { statusCode: 200, body: \u0026quot;{\\\u0026quot;pk\\\u0026quot;: \\\u0026quot;USER#1\\\u0026quot;, ...}\u0026quot; } If the Frontend simply uses response.json(), it will receive a string inside the body and cannot access data.pk. Solution: apiClient Wrapper\nWe write a wrapper function to:\nAutomatically retrieve the JWT Token from the current session. Attach the Token to the Authorization Header. Automatically parse JSON twice if nested data is detected. // src/lib/api.js export const apiClient = async (endpoint, options = {}) =\u0026gt; { // 1. Lấy Token const session = await fetchAuthSession(); const token = session.tokens?.idToken?.toString(); // 2. Gọi API với Token const response = await fetch(`${BASE_URL}${endpoint}`, { headers: { \u0026#39;Authorization\u0026#39;: `Bearer ${token}`, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, ...options, }); // 3. Xử lý \u0026#34;Double JSON\u0026#34; const data = await response.json(); if (data.body \u0026amp;\u0026amp; typeof data.body === \u0026#39;string\u0026#39;) { return JSON.parse(data.body); // \u0026lt;-- \u0026#34;Bóc vỏ\u0026#34; lần 2 } return data; }; 4. Building Feature Pages (Core Features) A. Dashboard The overview page displaying statistics.\nChallenge: Handling asynchronicity when calling the API to fetch activity history. Solution: Use useEffect to fetch data and display BarLoader (loading spinner) while waiting. B. Resume Builder This is the most complex feature in terms of UI.\nInterface: Use Tabs to switch between Edit Form and Markdown Preview modes. Form: Use react-hook-form and zod to validate input data. AI Feature: When the user clicks \u0026ldquo;Improve with AI\u0026rdquo;, the Frontend sends the raw text to the /resume/improve API and populates the input field with the result. Accordion UI: Use Shadcn\u0026rsquo;s Accordion component to group Experience/Education sections neatly. C. Mock Interview Knowledge quiz page.\nScoring Logic: Compare the answer selected by the user with the correct answer from the Backend. Technical Note: The Backend returns the correct answer as the character \u0026ldquo;B\u0026rdquo;, but the Frontend displays \u0026ldquo;B. Content\u0026hellip;\u0026rdquo;. Processing Code: userAnswer.split(\u0026quot;.\u0026quot;)[0].trim() === correctAnswer. D. Cover Letter Generator This feature helps users generate cover letters automatically based on the Job Description (JD).\nProcess Flow:\nUser enters: Company Name, Position, Job Description (JD). Frontend sends POST /cover-letters to Backend. Backend calls Claude 3 to write the letter and saves it to DB. Frontend receives the result and displays it to the user. Technical Note:\nLoading State: Since AI takes about 5-10 seconds to write a letter, the Frontend must have a waiting state (Loading Spinner or Skeleton) so users know the system is processing, preventing them from clicking the button multiple times. Result Display: The returned content is plain text (or Markdown), which needs to be displayed in a textarea or MDEditor so users can edit it before downloading. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.5-week5/","title":"Worklog Week 5","tags":[],"description":"","content":"Week 5 Objectives: Get familiar with system scaling concepts (Load Balancer, Auto Scaling) and know how to practically deploy on AWS. Grasp the process of deploying applications and databases using RDS, managing machine images (AMIs), and creating Launch Templates. Understand and apply CloudWatch to monitor resources, track logs, create metrics, alarms, and dashboards. Learn the basics of Route 53, DNS resolver, and integration with Microsoft AD in a cloud environment. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Practice + Deploy Akaunting Instance + Create instance + Configure Networking + Deploy Prestashop E-Commerce + Secure Wordpress application + Create Snapshot + Migrate to a larger instance + Create alarms to notify administrators if a specific event occurs - Learn about Auto Scaling Group, AMIs, and Launch Template - Practice + Set up basic network infrastructure for FCJ Management application + VPC and Subnet + Internet Gateway + Route Table + Security Groups + Create EC2 Instance + Create DB Subnet Group for Amazon RDS + Create Amazon RDS Database Instance + Install data for Database + Deploy web server + Prepare data for Predictive scaling + Create Amazon Machine Images (AMIs) from EC2 + Create Launch Templates 06/10/2025 06/10/2025 cloudjourney.awsstudygroup.com 3 - Learn about Elastic Load Balancing (ELB) + Target Group + Application Load Balancer + Network Load Balancer + Classic Load Balancer + Gateway Load Balancer - Learn about Scaling solutions / techniques + Manual scaling + Scheduled scaling + Dynamic scaling + Predictive scaling - Practice: + Create Target Group + Create Application Load Balancer + Check Elastic Load Balancing (ELB) deployment results + Create Auto Scaling Group + Connect ASG with Load Balancer + Set up Size and Scaling Policies + Set up notifications - Practice Scaling solutions / techniques + Manual scaling + Scheduled scaling + Dynamic scaling + Predictive scaling 07/10/2025 07/10/2025 cloudjourney.awsstudygroup.com and AWS Study Group Youtube 4 - Learn about AWS CloudWatch + Features + Container Insights + Key benefits - Learn about CloudWatch Metrics, CloudWatch Logs, CloudWatch Alarms, CloudWatch Dashboards 08/10/2025 08/10/2025 cloudjourney.awsstudygroup.com 5 - Practice: + Deploy CloudFormation Stack + View Metrics + Interact with charts in CloudWatch + Perform Metrics searches + Perform math operations + Create dynamic labels + View CloudWatch Logs + Generate logs from an application, then query these logs in CloudWatch Logs Insights + Extract valuable data from logs and convert them into metrics using CloudWatch Metric Filters + Set up Alarm for Error Log Metric + Create a simple Dashboard to centrally manage Metrics and Alarms 09/10/2025 10/10/2025 cloudjourney.awsstudygroup.com 6 - Learn about Route 53 + Outbound Endpoints + Inbound Endpoints + Route 53 Resolver Rules - Learn about AWS Quick Starts, AWS CloudFormation, AWS Directory Service - Practice: + Create Key Pair, initialize CloudFormation Template, configure Security Group + Connect to RDGW + Deploy Microsoft AD + Configure DNS + Create Route 53 Outbound Endpoint + Create Route 53 Resolver Rules + Create Route 53 Inbound Endpoints + Test results 10/10/2025 10/10/2025 cloudjourney.awsstudygroup.com Week 5 Achievements: Deploy and manage web applications on EC2/Lightsail, including Akaunting, WordPress, and Prestashop, along with security configuration, snapshots, and instance upgrades. Set up Auto Scaling Group, Launch Template, and AMI to scale the system, applying scaling methods: manual, scheduled, dynamic, predictive. Create and manage Load Balancers (ALB, NLB) connected to Auto Scaling Group to balance load and ensure system stability. Monitor the system using CloudWatch: Metrics, Logs, Alarms, Dashboards, and extract data from logs to track performance. Deploy database with Amazon RDS, set up DB Subnet Group, and connect EC2 with RDS for complete application operation. Learn and practice Route 53, deploy internal DNS, Microsoft AD, configure Resolver Rules, and check connections. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Building AI Career Coach - a modern Fullstack Serverless application designed to help users enhance their career opportunities through the power of Artificial Intelligence 🎥 Product Demo Watch video\n💡 Problem \u0026amp; Solution The Problem The job market is becoming increasingly competitive. Candidates often face difficulties with:\nWriting a standard, ATS-optimized CV (Resume). Drafting personalized Cover Letters for specific companies. Lacking an environment to practice interviews and receive objective feedback. The Solution: AI Career Coach This project addresses these issues by utilizing Amazon Bedrock (Claude 3) to act as a virtual career coach:\nAI Resume Builder: Assists in writing, editing, and optimizing professional CV content. Cover Letter Generator: Automatically generates cover letters based on Job Descriptions (JD) and user profiles. Mock Interview: Conducts mock interviews with AI tailored to specific industries and provides scoring/feedback. 🛠️ Tech Stack The project adopts a Serverless Microservices architecture, optimizing costs and scalability.\n1. Frontend React (Vite): Fast development speed and high performance. Tailwind CSS \u0026amp; Shadcn UI: For building beautiful, modern, and accessible user interfaces. AWS Amplify: Manages Authentication (Cognito) and API connections. 2. Backend (Java Serverless) Java 17 \u0026amp; Spring Boot: A robust backend platform. Spring Cloud Function: Converts Java logic into Serverless functions. AWS Lambda: Runs code without server management. Includes 5 distinct functions: UserProfileFunction ResumeFunction CoverLetterFunction InterviewFunction IndustryInsightFunction 3. Database \u0026amp; AI Amazon DynamoDB: NoSQL database using high-performance Single Table Design. Amazon Bedrock: The gateway to Foundation Models. We utilize the Claude 3 Haiku model from Anthropic. 4. Infrastructure \u0026amp; DevOps AWS SAM (Serverless Application Model): Defines the entire infrastructure as code (IaC). Amazon S3 \u0026amp; CloudFront: Global storage and content delivery for the Frontend with OAC security. 🎯 Workshop Goals By the end of this workshop, you will master:\nHow to build a complete Fullstack application. Serverless system design thinking on AWS. Prompt Engineering techniques to integrate AI into Java applications. Securing applications with JWT and Cognito. Basic CI/CD processes: Build, Deploy, and Hosting. Content Workshop overview Prerequiste Infrastructure as Code Backend Development Frontend Development Deploy Clean up "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.6-deploy/","title":"Deploy","tags":[],"description":"","content":"We have completed writing the code (Dev) and designing the infrastructure (Ops). Now it is time to combine them (DevOps) to bring the application to the real world.\nThe deployment process consists of 3 main stages:\nBackend Deployment: Push API and Database to AWS. Frontend Configuration: Update connection information (API URL, Cognito ID) in the React code. Frontend Deployment: Build and push the Static Web to S3. Stage 1: Backend Deployment (AWS SAM) Step 1: Build Java source code Before deploying, we need to package the Java source code into an executable .jar file.\nOpen Terminal at the project root directory (where the parent pom.xml file or backend/ directory is located):\ncd backend mvn clean package -DskipTests Explanation:\nclean: Removes old build files. package: Packages into a JAR file (located in target/). -DskipTests: Skips running unit tests to save time for the workshop. Step 2: Deploy to AWS Return to the root directory (where template.yaml is located) and run the command:\ncd .. sam deploy --guided Follow the on-screen instructions (just press Enter to select defaults for most questions):\nStack Name: career-coach-stack (or any name you prefer). AWS Region: ap-southeast-1 (Singapore). Confirm changes before deploy: Y. Allow SAM CLI IAM role creation: Y. Save arguments to configuration file: Y. This process will take about 5-7 minutes for CloudFormation to create the Database, Lambda, API Gateway, and CloudFront.\nStep 3: Save Output Information After successful deployment, the screen will display the Outputs table. Copy the following parameters to Notepad; we will need them immediately:\nApiEndpoint: API Gateway URL (Example: https://xyz.execute-api\u0026hellip;). CognitoUserPoolId: User Pool ID. CognitoClientId: App Client ID. S3BucketName: Bucket name for hosting the web. WebsiteURL: Website URL (CloudFront). Stage 2: Frontend Configuration The Frontend needs to know which API to call and where to log in.\nStep 1: Update API Client Open the file frontend/src/lib/api.js:\n// Thay thế bằng ApiEndpoint bạn vừa copy const BASE_URL = \u0026#34;https://xxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com\u0026#34;; Step 2: Update Auth Config Open the file frontend/src/main.jsx:\nAmplify.configure({ Auth: { Cognito: { userPoolId: \u0026#39;ap-southeast-1_XXXXXXX\u0026#39;, // Paste CognitoUserPoolId userPoolClientId: \u0026#39;xxxxxxxxxxxxxxxxx\u0026#39;, // Paste CognitoClientId loginWith: { email: true } } } }); Stage 3: Frontend Deployment (S3 \u0026amp; CloudFront) Step 1: Build React project (Vite) Navigate to the frontend directory and proceed to build:\ncd frontend npm run build Result: A folder named dist will be created. This is the \u0026ldquo;lean\u0026rdquo; version of the website, which has been size-optimized.\nStep 2: Push code to S3 Use AWS CLI to sync the dist folder to the S3 Bucket (use the bucket name you saved in Stage 1):\naws s3 sync dist s3://career-coach-frontend-123456789 --delete The --delete parameter: Automatically deletes old files on S3 if they no longer exist in the dist directory (helps with cleanup).\nStep 3: Clear CloudFront Cache (Invalidation) This is a mandatory step every time you update the frontend code. If you skip this step, users will still see the old web version due to CloudFront caching.\nGet the CloudFront Distribution ID:\naws cloudfront list-distributions --query \u0026#34;DistributionList.Items[*].{ID:Id, Domain:DomainName}\u0026#34; --output table Run the cache deletion command:\naws cloudfront create-invalidation --distribution-id \u0026lt;DISTRIBUTION_ID\u0026gt; --paths "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at AMAZON WEB SERVICES VIETNAM COMPANY LIMITED from 01/09/2025 to 09/09/2025, I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI gained hands-on experience with AWS services while proactively proposing and developing the \u0026lsquo;AI Career Coach\u0026rsquo; project utilizing AWS serverless architecture, thereby enhancing my programming, analytical, and reporting skills.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ✅ ☐ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ✅ ☐ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ☐ ✅ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Focus on articulating ideas and reporting work in a more coherent, concise, and persuasive manner. Go beyond merely identifying issues; cultivate the ability to propose creative and optimal solutions. Proactively collaborate with colleagues and demonstrate a more open, positive attitude when receiving feedback. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.6-week6/","title":"Worklog Week 6","tags":[],"description":"","content":"Week 6 Objectives: Understand the process of building AMI, Launch Template and deploying WordPress in a scalable environment. Use Lambda Function to optimize costs, automatically start/stop EC2 Instances according to demand. Get familiar with Grafana to monitor data and systems. Know how to manage resources using Tags, Resource Groups and apply access control using IAM. Learn about AWS Systems Manager to run remote commands and manage patches (Patch Manager). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Practice: deploy Wordpress application with Auto Scaling Group to ensure the application\u0026rsquo;s scalability according to visitor demand + Prepare VPC and subnet, create Security Group for EC2, Database and initialize EC2, Database + Install wordpress on EC2 + Perform Autoscaling creation for wordpress Instance + Initialize AMI from Webserver Instance + Initialize Launch Template + Initialize Target Group + Initialize Load Balancer + Initialize Auto Scaling Group + Backup and restore database + Initialize Cloudfront for Web Server 13/10/2025 13/10/2025 cloudjourney.awsstudygroup.com 3 - Learn about Lambda function - Practice: use Lambda function to optimize costs for your system on AWS environment + Create VPC, Security Group, EC2 + Incoming Web-hooks slack + Create tag for instance + Create Role for Lambda + Create Lambda Function performing Stop instances function + Create Lambda Function performing Start instances function + Check results 14/10/2025 14/10/2025 cloudjourney.awsstudygroup.com 4 - Learn about Grafana - Practice: + Create VPC and Subnet, Security Group, Linux EC2 Instance + Create IAM User, IAM Role, assign IAM Role to EC2 Instance + Install Grafana + Perform EC2 connection using MobaXterm + Monitor with Grafana 15/10/2025 15/10/2025 cloudjourney.awsstudygroup.com and grafana.com/grafana 5 - Learn about resource management using Tag and Resource Groups - Practice: + Create EC2 Instance with tag + Add or remove tags on individual resources and on resource groups + Filter resources by tag + Create a Resource Group - Practice: manage access to EC2 Resource Tag service with AWS IAM + Create IAM User + Create IAM Policy + Create IAM Role + Switch Role + Check IAM Policy + Proceed to access EC2 console in AWS Region - Tokyo + Proceed to access EC2 console in AWS Region - North Virginia + Proceed to create EC2 instance when there are no and there are Tags satisfying conditions + Edit Resource Tag on EC2 Instance + Check policy 16/10/2025 16/10/2025 cloudjourney.awsstudygroup.com 6 - Learn about AWS Systems Manager - Practice: manage Patch and run commands on multiple servers with AWS System Manager + Create VPC, Subnet, EC2 Instance, IAM Role and assign IAM Role + Set up Patch Manager + Run Command 17/10/2025 17/10/2025 cloudjourney.awsstudygroup.com Week 6 Achievements: Deploy WordPress according to scalable model including: create VPC/Subnet/SG, install Webserver, create AMI, Launch Template, Target Group, Load Balancer and Auto Scaling Group; simultaneously backup – restore database and configure CloudFront. Build cost optimization automation solution using Lambda, including create Role, assign tag, create Stop/Start EC2 Lambda Function and check activation via Slack Webhook. Deploy Grafana to monitor the system, including create Linux EC2, IAM User/Role, install Grafana and connect to track data. Manage resources using Tag and Resource Groups, simultaneously apply IAM to control access by Tag and test in multiple Regions. Use AWS Systems Manager to manage patches using Patch Manager and run remote commands with Run Command. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/5-workshop/5.7-clean/","title":"Clean up","tags":[],"description":"","content":"After completing the workshop, it is extremely important to delete the created resources to avoid unexpected AWS charges at the end of the month.\nThe cleanup process consists of 2 main steps.\nStep 1: Delete Frontend Bucket (Required) 🗑️ The sam delete command will fail when trying to delete an S3 Bucket if that bucket still contains files (the frontend code you uploaded). Therefore, we need to manually delete this bucket first.\nOpen Terminal. Run the following command to remove all files and delete the bucket (replace with your bucket name): aws s3 rb s3://career-coach-frontend-123456789 --force Explanation:\nrb: Remove Bucket \u0026ndash;force: Force deletion even if the bucket still contains files (dangerous but convenient for workshops). Step 2: Delete Backend Stack (SAM Delete) Once the Bucket is deleted, we can now safely delete the entire remaining infrastructure (Lambda, DynamoDB, API Gateway, Cognito\u0026hellip;).\nAt the project root directory (where the template.yaml file is located), run the command:\nsam delete Confirm action:\nAre you sure you want to delete the stack [career-coach-stack]? -\u0026gt; Enter y (Yes). Are you sure you want to delete the folder [career-coach-stack]\u0026hellip;? -\u0026gt; Enter y. This process will take about 2-3 minutes. SAM will clean up everything defined in template.yaml.\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe workspace is very open and organized, creating a comfortable atmosphere that allows me to focus effectively. The FCJ members are extremely open and supportive, always willing to help each other, even after working hours. However, I hope the program can organize more social or bonding activities to foster better connection and understanding among the team.\n2. Support from Mentor / Team Admin\nI am very impressed with my Mentor’s working style: dedicated guidance, thorough explanations, and constant encouragement to be proactive in asking questions. In particular, instead of simply providing the answers, my Mentor guides me to research and solve problems on my own. Additionally, the Team Admin has been very helpful with administrative procedures and documentation, ensuring my internship proceeds smoothly.\n3. Relevance of Work to Academic Major\nThe assigned tasks are closely aligned with the specialized knowledge I learned at university, while also expanding into new technology areas that I hadn\u0026rsquo;t previously encountered. This has allowed me to both consolidate my theoretical foundation and cultivate valuable practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nThe internship has helped me refine essential skills such as using project management tools, teamwork, and professional corporate communication. Beyond technical knowledge, the practical experiences shared by my Mentor have helped me more clearly define my future career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture radiates positive energy: respect is always a top priority, and while everyone works seriously, the atmosphere remains cheerful. Team spirit shines brightest during urgent projects, where everyone is ready to support one another regardless of their position. This makes me feel truly integrated and part of the team.\n6. Internship Policies / Benefits\nThe company offers great flexibility regarding working hours when interns have necessary personal matters to attend to.\nAdditional Questions 1. What did you find most satisfying during your internship? What I appreciate most is the dedication and enthusiasm of the Mentor and Admin team. They not only provided close support whenever I faced difficulties but also offered an extremely comprehensive library of learning materials. These high-quality resources gave me a solid foundation to implement my project smoothly and effectively.\n2. What do you think the company should improve for future interns? I suggest that the program should align the internship training materials with standard AWS certification paths. Structuring the documentation flow parallel to the exam guides would be a significant improvement, helping interns not only complete their projects successfully but also achieve the goal of obtaining international certifications immediately upon graduating from the FCJ program.\n3. If recommending to a friend, would you suggest they intern here? Why or why not? Definitely, yes. This is the ideal environment for anyone looking to kick-start a career in Cloud Computing. At FCJ, my friends would not only learn hard skills regarding AWS but also cultivate a problem-solving mindset and experience the professional working style of a global technology corporation.\nSuggestions \u0026amp; Expectations 1. Do you have any suggestions to improve the internship experience? I propose organizing small weekly \u0026lsquo;Tech Sharing\u0026rsquo; or \u0026lsquo;Deep-dive Sessions\u0026rsquo; where interns can present their solutions to receive cross-feedback from mentors and other teams. This would help us hone our presentation skills and gain a more multi-dimensional perspective on problem-solving.\n2. Would you like to continue this program in the future? I am very keen on continuing my journey with the company. Post-FCJ, I hope to apply for advanced internship or Fresher positions to apply my learnings to real-world projects.\n3. Any other comments (free sharing): I would like to express my sincere gratitude to my Mentor and the FCJ management team for patiently guiding me throughout this period. This program has truly been a solid kick-start to my career. I wish the FCJ program continued success in future seasons and hope it attracts even more young talent.\n"},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.7-week7/","title":"Worklog Week 7","tags":[],"description":"","content":"Week 7 Objectives: Understand and practice AWS Systems Manager – Session Manager, including public/private EC2 connection, setting up Endpoints, and managing session logs. Grasp concepts and basic \u0026amp; advanced practices of AWS CloudFormation, including creating templates, creating stacks, StackSets, and Drift Detection. Know how to use AWS Cloud9 to work with CloudFormation and the AWS environment. Understand and set up AWS IAM Identity Center (AWS SSO) in AWS Organization: Users, Groups, Permission Sets, and access delegation. Apply Time-based Access Control and Customer Managed Policies to set up advanced Permission Sets for each user group in the Organization. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about Session Manager - Practice: work with Amazon System Manager - Session Manager + Create VPC, Public subnet, Private subnet, security group, public Linux and private Windows servers + Create IAM Role + Create connection to Public EC2 server + Create connection to Private EC2 server + Enable DNS hostnames + Create ssm Endpoint + Create ssmmessages Endpoint + Create ec2messages Endpoint + Assign IAM role and restart EC2 instance + Manage session logs + Update IAM Role + Create S3 bucket and S3 Gateway endpoint + Monitor session logs + Check Session logs in S3 + Port Forwarding + Create IAM User with SSM connection permissions + Install and configure AWS CLI and Session Manager Plugin + Perform Portforwarding 20/10/2025 20/10/2025 cloudjourney.awsstudygroup.com 3 - Learn about AWS CloudFormation and AWS Cloud9 - Practice: create a CloudFormation template and a few basic features of CloudFormation, and how to validate templates + Create IAM User, IAM Role + Create Workspace + Create CloudFormation Template 21/10/2025 21/10/2025 cloudjourney.awsstudygroup.com, https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html, https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-template-resource-type-ref.html 4 - Learn about StackSets, Drift Detection, Simple Queue Service - Practice: Advanced CloudFormation + Create Lambda Function + Create Stack in CloudFormation + Connect EC2 Instance + Mappings and Stacksets + Change resource configuration with Drift 22/10/2025 22/10/2025 cloudjourney.awsstudygroup.com and https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html 5 - Practice: Set up Single Sign-On (Amazon SSO) for Organization + Enable AWS Organizations + Enable IAM Identity Center + Create Users and Groups in IAM Identity Center + Create Permission Sets + Provision Permission Sets + Check access based on user, group, and permission set + Deploy CloudFormation Template + Verify access permissions + Check Administrator permissions + Check ReadOnly permissions + Configure AWS CLI - Manually refresh credentials + Configure AWS CLI - Automatically refresh credentials 23/10/2025 23/10/2025 cloudjourney.awsstudygroup.com 6 - Practice: Set up Single Sign-On (Amazon SSO) for Organization + Use Time-based access control to provide temporary access to AWS accounts for Security Auditor + Create Permission Set with necessary access permissions for Security Auditor as inline policy with time-based access control conditions + Create Group for Security Auditors + Assign users to Security Auditors Group + Assign access to AWS Account for Security Auditors group with newly created permission set + Create CMP, create permission set by attaching created CMP, and finally provision permission set for AWS account + Create Customer Managed IAM Policy + Create permission Set with Customer Managed policy + Create Group and create user and add to Group + Assign Permission set to AWS Account and verify access 24/10/2025 24/10/2025 cloudjourney.awsstudygroup.com Week 7 Achievements: Master Session Manager in AWS Systems Manager: create public/private VPC environment, assign IAM Role, set up SSM, EC2Messages, SSMMessages endpoints, and successfully connect to both Public and Private EC2. Manage and track Session Logs: configure S3 bucket, S3 Gateway Endpoint, update IAM Role to log, and verify logs functioning correctly in S3. Perform Port Forwarding via SSM: create IAM User, configure AWS CLI + SSM Plugin, perform secure port forwarding without opening ports in Security Group. Learn and use AWS CloudFormation: create Cloud9 Workspace, create IAM User/Role, write CloudFormation template, and validate template validity. Deploy advanced CloudFormation: create Lambda Function, build Stack, set up StackSets, map resources, connect EC2, and check Drift Detection when changing configuration. Set up Single Sign-On with IAM Identity Center for the entire AWS Organization: create Users/Groups, Permission Sets, grant Administrator/ReadOnly permissions, and verify permissions by user/group. Configure AWS CLI with IAM Identity Center: test manual and automatic credential refresh, ensuring correct permission set recognition. Apply Time-based Access Control to grant temporary access to Security Auditor: create Permission Set with time-based conditions, categorize Security Auditor group, assign permissions, and verify correct operation. Create Customer Managed Policy (CMP) and combine CMP into Permission Set, assign to AWS Account, and check actual user access permissions. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.8-week8/","title":"Worklog Week 8","tags":[],"description":"","content":"Week 8 Objectives: Understand and practice identity management with IAM Identity Center and User/Group APIs. Grasp the mechanism of limiting permissions using IAM Permission Boundary and conditions when switching Roles (Role Switching). Get familiar with security services: Security Hub, AWS WAF, and security assessment standards. Learn about monitoring – logging – encryption services like CloudTrail, KMS, and Athena. Know how to use AWS Backup and SNS to build backup and notification sending processes. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Practice: IAM Identity Center Identity Store APIs + Environment Setup + Test Setup + Use case Prerequisites + AWS IAM Identity Center User and Group API Operations + Create User and add to the group + Update User’s Group Membership + AWS IAM Identity Center User and Group Audit Operations - Translate Blog: + Announcing Amazon Quick Suite: your agentic teammate for answering questions and taking action + AWS Transfer Family SFTP connectors now support VPC-based connectivity + AWS Weekly Roundup: Amazon Quick Suite, Amazon EC2, Amazon EKS, and more (October 13, 2025) 27/10/2025 27/10/2025 https://cloudjourney.awsstudygroup.com/ and https://aws.amazon.com/vi/blogs/aws/reimagine-the-way-you-work-with-ai-agents-in-amazon-quick-suite/#:~:text=Today%2C%20we%E2%80%99re%20announcing%20Amazon%20Quick%20Suite%2C%20a%20new,and%20turns%20those%20insights%20into%20actions%20for%20you. and https://aws.amazon.com/vi/blogs/aws/aws-transfer-family-sftp-connectors-now-support-vpc-based-connectivity/ and https://aws.amazon.com/vi/blogs/aws/aws-weekly-roundup-amazon-quick-suite-amazon-ec2-amazon-eks-and-more-october-13-2025/ 3 - Learn about IAM Permission Boundary - Practice: Limit User Permissions with IAM Permission Boundary + Create Boundary Policy + Create Limited IAM User + Check if the user assigned permissions is restricted by Permission Boundary - Practice: Limit Role switching by Condition + Create IAM Group + Create IAM Users and check their permissions + Configure Role Condition + Create IAM Role with Administrative permissions + Configure Switch role for IAM User + Limit allowed time to Switch role + Limit allowed IP to Switch role 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn about AWS Security Hub, security standards - Practice: Enable Security Hub via console - Practice: Check assessment by each set of standards - Learn about AWS Web Application Firewall - Practice: perform environment creation for workshop including creating S3 bucket and deploying a Sample Application + Create S3 bucket + Deploy an OWASP Juice Shop Application - Practice: Use AWS WAF + Deploy Web ACLs with managed rules + Create Custom Rule + Define WAF rule in JSON format. Complex logic needs to be defined using AND, OR, and NOT operators + Test new Rule + Log requests 29/10/2025 29/10/2025 https://cloudjourney.awsstudygroup.com/ and https://aws.amazon.com/vi/waf/ 5 - Learn about AWS Key Management Service, AWS CloudTrail, Amazon Athena - Practice: Manage Keys with Key Management Service (AWS KMS) + Create Policy, Role, Group, and User + Create KMS + Create Bucket and upload data to S3 + Create CloudTrail and log into CloudTrail + Create Amazon Athena and query data with Athena + Test and share encrypted data on S3 30/10/2025 30/10/2025 https://cloudjourney.awsstudygroup.com/ and https://docs.aws.amazon.com/kms/latest/developerguide/overview.html and https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html and https://docs.aws.amazon.com/athena/latest/ug/what-is.html 6 - Learn about AWS Backup, AWS Simple Notification Service - Practice: Deploy system backup plan with AWS Backup + Create S3 bucket + Use AWS Backup to create a backup plan for resources running on AWS + Create Backup Plan + Use AWS SNS (Simple Notification Service) to send notifications related to ongoing backup activities + Check backup activity 31/10/2025 31/10/2025 https://cloudjourney.awsstudygroup.com/ and https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html and https://aws.amazon.com/vi/sns/ Week 8 Achievements: Centrally manage users using IAM Identity Center: set up environment, create user/group, update permissions, and perform audit operations via API. Enhance access control using Permission Boundary and Role Condition: limit user permissions, limit switch role by time/IP, and test actual permission delegation. Deploy application layer security solutions: enable Security Hub, assess according to security standards; deploy AWS WAF with managed rules, custom rules, JSON rule logic, and log requests. Manage encryption, monitor, and analyze logs: create KMS key, configure CloudTrail, upload S3 data, query logs using Athena, and test encrypted data sharing. Set up system backup process with AWS Backup: create backup plan, configure backup resources, combine with SNS to send notifications, and check backup results. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.9-week9/","title":"Worklog Week 9","tags":[],"description":"","content":"Week 9 Objectives: Understand and practice connecting multiple VPCs using VPC Peering and Transit Gateway. Grasp the container application deployment process: build, push image to Amazon ECR, run with Docker, Docker Compose, and deploy using Amazon ECS. Get familiar with CI/CD systems using GitLab CI, GitHub Actions, CodeBuild, and CodePipeline. Manage and automate application deployment with CodeCommit – CodeDeploy – CodePipeline, combined with CloudWatch Events. Learn about and configure AWS Storage Gateway and Windows Multi-AZ storage platform (file system, file share, performance, quota, deduplication). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about VPC Peering - Practice: Link Virtual Private Clouds (VPC) with VPC Peering + Initialize CloudFormation Templates + Create Security Group and EC2 instance + Update Network ACL + Create Peering connection + Enable Cross-Peer DNS - Learn about AWS Transit Gateway - Practice: Centrally manage connections with AWS Transit Gateway + Create Key Pair and initialize CloudFormation Template + Create an AWS Transit Gateway to act as a central hub connecting VPCs + Configure Transit Gateway Attachments to connect VPCs with the created Transit Gateway + Create and configure Route Table for Transit Gateway to manage traffic flow between VPCs + Configure Route Table for each VPC to route traffic through Transit Gateway 03/11/2025 03/11/2025 https://cloudjourney.awsstudygroup.com/ and https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html and https://docs.aws.amazon.com/vpc/latest/tgw/what-is-transit-gateway.html 3 - Learn about Amazon ECR, Amazon ECS, Cloud Map - Practice: deploy application on Docker using AWS services like EC2, RDS, and Amazon ECR + Deploy a sample application on the personal computer itself to observe and evaluate + Configure VPC, create Security Group, configure Role for ECR, log in to Docker Hub + Create DB Subnet Group and launch RDS Instance + Launch EC2 Instance, install required application libraries, and add database for testing + Deploy on Docker Image + Deploy with Docker Compose + Push Docker Image to Amazon ECR + Push Docker Image to Docker Hub - Practice: Deploy Application to Amazon Elastic Container Service (Amazon ECS) + Use results from Practice: deploy application on Docker using AWS services like EC2, RDS, and Amazon ECR + Create CodeDeploy role and add Subnet + Configure NAT gateway, Route Table, Security Group + Create namespace in Cloud Map + Create ECS Cluster + Create ECS Task Definition for Frontend and Backend + Create Target Group and configure Application Load Balancer + Deploy Blue/Green and Service Scaling with Backend + Deploy Rolling with Frontend 04/11/2025 04/11/2025 https://cloudjourney.awsstudygroup.com/ and https://aws.amazon.com/vi/ecr/ and https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html and https://docs.amazonaws.cn/en_us/cloud-map/latest/dg/what-is-cloud-map.html 4 - Learn about AWS CodePipeline, AWS CodeBuild - Practice: Deploy Application with AWS CodePipeline + Deploy CI/CD with Gitlab • Fork and Edit Code • Install Gitlab and Runner • Edit and Add Role • Create Tag and Track Pipeline • Check Results + Deploy CI/CD with Github Action • Clone Github template • Create a new project and push code to Github • Create Access key and Secret key in AWS IAM • Check Results + Deploy CI/CD with CodeBuild • Fork github repository • Create CodeBuild Frontend • Create CodeBuild Backend • Create tag for Repository • Check results - Monitor application with Container Insights (CloudWatch) - Route logs with Firelens + Create S3 Bucket and IAM Role for Task + Deploy Service with new Task Definition + Check results 05/11/2025 05/11/2025 https://cloudjourney.awsstudygroup.com/ and https://aws.amazon.com/vi/codepipeline/ and https://docs.aws.amazon.com/codebuild/latest/userguide/welcome.html 5 - Learn about AWS CodeCommit, AWS CodeDeploy, AWS CloudWatch Events - Practice: Automate Application Deployment AWS CodePipeline + Use results from Practice: deploy application on Docker using AWS services like EC2, RDS, and Amazon ECR + Create S3 bucket, Git credentials, Git connection, Service role for CodeDeploy, IAM user, instance profile for Amazon EC2 instance, and assign role to EC2 instance + Install CodeDeploy Agent + AWS CodeCommit to push code from local machine + Build project with CodeBuild + Deployment with AWS CodeDeploy + Use AWS CodePipeline to create CI/CD process deploying application - Learn about AWS Storage Gateway - Practice: Use AWS Storage Gateway + Create Storage Gateway + Create File Share + Connect File shares on On-premise machine 06/11/2025 06/11/2025 https://cloudjourney.awsstudygroup.com/ and https://docs.aws.amazon.com/whitepapers/latest/introduction-devops-aws/cloudwatch-events.html and https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html and https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html and https://docs.aws.amazon.com/storagegateway/ 6 - Practice: Set up shared data storage system for Windows infrastructure. + Create practice environment + Create an SSD Multi-AZ file system + Create an HDD Multi-AZ file system + Create file share + Check performance of STG326 - SAZ. + Monitor performance of STG326 - SAZ + Enable data deduplication + Enable shadow copies + Manage User Sessions and open files + Enable user storage quotas + Enable Continuously Available shares + Expand throughput capacity + Expand storage capacity 07/11/2025 07/11/2025 https://cloudjourney.awsstudygroup.com/ Week 9 Achievements: Establish network connection between VPCs using VPC Peering and Transit Gateway: create CloudFormation, configure Security Group, NACL, Route Tables, Transit Gateway Attachments, and Cross-Peer DNS. Deploy containerized application: build and run application via Docker, Docker Compose; create RDS, EC2, ECR repo; push image to ECR and Docker Hub; deploy to ECS with Cloud Map, ALB, Blue/Green, and Rolling update. Build CI/CD process with GitLab, GitHub Actions, and AWS CodeBuild: configure Runner, Credential, create pipeline, build frontend/backend, and monitor results. Automate deployment using CodeCommit – CodeBuild – CodeDeploy – CodePipeline: create IAM Role, Agent, S3 bucket, Git connection; build and deploy automatically via pipeline; route logs using FireLens. Set up enterprise storage system: create Storage Gateway, File Share; configure Windows Multi-AZ file system; monitor performance, enable deduplication, shadow copies, manage sessions, and expand capacity. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.10-week10/","title":"Worklog Week 10","tags":[],"description":"","content":"Week 10 Objectives: Understand and comprehensively practice Amazon DynamoDB: create tables, read-write data, query, scan, index, backup/restore, and communicate via AWS CLI. Grasp advanced DynamoDB models such as: Global Secondary Index, Sparse Index, Write Sharding, Sequential \u0026amp; Parallel Scan, Streams \u0026amp; Lambda, Adjacency Lists, Composite Keys. Learn about serverless and event-driven solutions based on DynamoDB such as: Global Tables, DynamoDB Streams, Lambda Trigger, Zero-ETL Pipeline with OpenSearch \u0026amp; Bedrock. Master AWS Cost Optimization: Savings Plans, Reserved Instances, EC2 Rightsizing, Cost Explorer, Glue + Athena for advanced cost analysis. Practice deploying the TravelBuddy application to Elastic Beanstalk and configuring automated deployment via CodeStar, CodeCommit, CodeDeploy. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about DynamoDB - Practice: use DynamoDB + Launch CloudFormation stack + Create DynamoDB Tables + Load Sample Data - Practice: Explore DynamoDB with CLI and console + Read sample data + Read Item Collections using Query + Work with Table Scans + Add/Modify data + Delete Data + Transactions + Global Secondary Indexes - Practice: Backup with Amazon DynamoDB + DynamoDB Point-in-time recovery + On-demand backup + Scheduled backup + Restrict backup deletion - Practice: LMIG: Relational Modeling \u0026amp; Migration + Configure MySQL environment + Create DMS resources + Explore Source Model + Explore Target Model + Load DynamoDB Table + Access DynamoDB Table - Practice: LBED: Generative AI with DynamoDB zero-ETL integration into OpenSearch and Amazon Bedrock + Configure OpenSearch Service permissions + Enable Amazon Bedrock model + Load DynamoDB Data + Configure ML connections and Pipeline in OpenSearch Service + Create Zero-ETL Pipeline + Query and conclude 10/11/2025 10/11/2025 https://cloudjourney.awsstudygroup.com/ and https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html and https://www.youtube.com/watch?v=xfxBhvGpoa0 3 - Practice: LADV: Advanced Design Patterns for Amazon DynamoDB + Exercise 1: DynamoDB Capacity Units and Partitioning • Create DynamoDB table • Load sample data into table • Load larger file to compare execution time • View CloudWatch metrics on your table • Increase table capacity • After increasing table capacity, load more data • Create new table with low capacity global secondary index + Exercise 2: Sequential and Parallel Table Scans • Perform sequential scan • Perform parallel scan + Exercise 3: Global Secondary Index Write Sharding • Create GSI • Query GSI using shards + Exercise 4: Global Secondary Index Overloading • Create employees table for overloaded global secondary index key • Load data into new table • Query employees table using global secondary index with overloaded attributes + Exercise 5: Sparse Global Secondary Indexes • Add new global secondary index to employees table • Scan employees table to find managers without using sparse global secondary index • Scan employees table to find managers using sparse global secondary index - Exercise 6: Composite Keys + Create new global secondary index for City-Department + Query all employees from state + Query all employees of a city + Query all employees of a specific city and department - Exercise 7: Adjacency Lists + Create and load InvoiceandBilling table + Review InvoiceAndBills table on DynamoDB console + Query invoice details + Query customer and invoice details using Index - Exercise 8: Amazon DynamoDB Streams and Lambda + Create replica table + Review IAM policy for role + Create Lambda function + Enable DynamoDB Stream + Map source stream to Lambda + Populate logfile table and verify replication to logfile_replica - Practice: LCDC: Change Data Capture for Amazon DynamoDB Start • Cloud9 • EC2 Instance Scenario Overview • Create DynamoDB table • Load sample data Update IAM Role • Enable DynamoDB Stream • Create Dead Letter Queue • Create Lambda Function • Simulate order update Change CDC using Kinesis Data Streams • Enable Kinesis Data Stream • Create DLQ • Create Lambda • Configure Lambda • Simulate order update 11/11/2025 11/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Practice: LMR: Build and deploy global serverless application with DynamoDB Start Explore Global Tables Interact with Globalflix UI Discuss Global Tables Summary - Practice: LEDA: Serverless Event Driven Architecture with DynamoDB Preparation Overview Lab 1: Pipeline Deep Dive • Connect pipeline • Connect StateLambda • Check MapLambda trigger • Connect ReduceLambda Lab 2: Fault Tolerance \u0026amp; Exactly-Once Processing • Prevent duplicates at StateLambda • Ensure idempotency at ReduceLambda Summary 12/11/2025 12/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn about Savings Plan and Reserved Instances, CloudWatch - Practice: EC2 Rightsizing \u0026amp; Compute Optimizer + Create IAM Role for CloudWatch Agent + Attach IAM Role to EC2 instance + Install CloudWatch Agent Bucket + Update Resource Optimization + Best Practices for EC2 sizing + Optimize VM according to Compute Optimizer - Practice: Visualize AWS costs + View costs by service + View costs by account + View Savings Plan coverage + View elasticity + View Reserved Instance coverage + Create custom EC2 reports + Analyze costs using Cost Explorer + Overview of Data Transfer Out in common architectures - Learn about AWS Glue - Practice: Advanced cost analysis with Glue + Athena + Prepare, build DB + Explore data in table + Tagging \u0026amp; Cost Allocation + Savings Plan, RI, On-demand, Spot Usage 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ and https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html and https://docs.aws.amazon.com/glue/latest/dg/what-is-glue.html 6 - Practice: Deploy TravelBuddy application to AWS + Create Key Pair, CloudFormation stack + Connect Windows instance, install RDS + Test locally with Eclipse IDE + Deploy Elastic Beanstalk + Update application + Query API in Eclipse IDE - Practice: Configure automated application release + CloudFormation template + Create AWS CodeStar project + Connect Eclipse IDE with CodeCommit + Update source code and overwrite template page with TravelBuddy + Commit changes to trigger Elastic Beanstalk deployment + Use AWS CodeDeploy to push Windows Service to EC2 + Monitor service 14/11/2025 14/11/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Learn DynamoDB from basic to advanced: create tables, load sample data, CRUD via CLI/Console, Query/Scan, Transactions, Item Collections, and Global Secondary Index. Deploy full DynamoDB backup mechanisms: PITR, backup on-demand, scheduled backup, and restrict backup deletion. Apply advanced design patterns: Capacity Units, Partitioning, Sequential/Parallel Scan, Write Sharding, handle overloaded GSI, Sparse Index, Composite Keys, and Adjacency Lists. Integrate DynamoDB Streams with Lambda to replicate data to replica table; configure IAM; create trigger and verify replication. Build Serverless \u0026amp; Event-Driven architecture: Global Tables, Globalflix lab, StateLambda → MapLambda → ReduceLambda pipeline with idempotency and deduplication; Zero-ETL DynamoDB – OpenSearch – Bedrock. Optimize AWS costs: Savings Plan, RI, Rightsizing, Compute Optimizer, Cost Explorer, analyze Data Transfer Out, Glue + Athena for advanced cost queries. Deploy TravelBuddy: set up environment, deploy Elastic Beanstalk, update, connect CI/CD (CodeStar → CodeCommit → CodeDeploy), push Windows Service, and monitor service. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.11-week11/","title":"Worklog Week 11","tags":[],"description":"","content":"Week 11 Objectives: Finalize Serverless system architecture design on AWS (S3, CloudFront, API Gateway, Lambda, DynamoDB). Design DynamoDB database using Single Table Design model (Access Patterns, PK/SK Design). Design UI/UX for main functional pages: Dashboard, Resume Builder, Mock Interview. Initialize Monorepo project structure (Backend Java Spring Cloud \u0026amp; Frontend React Vite). Set up Infrastructure as Code (IaC) with AWS SAM (template.yaml) and configure IAM/Bedrock permissions. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Draw Data Flow diagram: User -\u0026gt; CloudFront -\u0026gt; API Gateway -\u0026gt; Lambda.\n- Identify necessary AWS services: Bedrock (Claude 3), Cognito, DynamoDB.\n- Analyze business requirements for 4 main modules: Resume, Cover Letter, Interview, Industry Insight.\n- List necessary API Endpoints. 17/11/2025 17/11/2025 3 - Define Entities: User, Resume, Assessment, CoverLetter.\n- Determine Access Patterns (Data querying methods).\n- Design Partition Key (PK) and Sort Key (SK) for each Entity (e.g., USER#{id}, METADATA, RESUME, LETTER#uuid).\n- Design Global Secondary Index (GSI) if needed. 18/11/2025 18/11/2025 4 - Design login/registration flow with Cognito.\n- Sketch statistical Dashboard interface.\n- Design Resume Builder interface (split screen: Form \u0026amp; Preview).\n- Design Mock Interview interface (Quiz form).\n- Select UI library set: Tailwind CSS, Shadcn UI, Lucide Icons. 19/11/2025 19/11/2025 5 - Setup environment: Java 17, Maven, Node.js, AWS CLI, SAM CLI.\n- Initialize Backend structure: Spring Boot 3 + Spring Cloud Function.\n- Initialize Frontend structure: React + Vite.\n- Configure Git Repository and Monorepo directory structure. 20/11/2025 20/11/2025 6 - Create template.yaml file.\n- Declare DynamoDB Table resources (PAY_PER_REQUEST).\n- Declare Cognito User Pool \u0026amp; Client.\n- Declare S3 Bucket \u0026amp; CloudFront Origin Access Control (OAC).\n- Configure IAM Policies for Lambda (permissions to call Bedrock \u0026amp; DynamoDB).\n- Register Model Access (Claude 3 Haiku) on AWS Bedrock. 21/11/2025 21/11/2025 Week 11 Achievements: Complete Serverless system architecture design. DynamoDB Single Table design schema ready for coding. Development Environment fully installed. AWS SAM template.yaml file ready to deploy basic infrastructure. Access rights to AI Claude 3 model on AWS Bedrock activated. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.12-week12/","title":"Worklog Week 12","tags":[],"description":"","content":"Week 12 Objectives: Build and finalize 5 Lambda Functions using Java Spring Cloud Function. Implement Repository layer interacting with DynamoDB (Enhanced Client). Integrate AWS SDK v2 to call Amazon Bedrock (Claude 3 Haiku) for AI features. Handle advanced technical issues: Prompt Engineering, JSON Serialization (ObjectMapper), Error Handling. Deploy Backend to AWS and test API via Postman. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Create UserEntity \u0026amp; UserRepository.\n- Write CRUD logic for user information.\n- Integrate JWT authentication logic from Cognito in Lambda.\n- Handle Onboarding logic for new users.\n- Deploy first test Lambda with SAM. 24/11/2025 24/11/2025 3 - Create ResumeEntity \u0026amp; ResumeRepository.\n- Write logic to save/retrieve Markdown content from DynamoDB.\n- Manually configure ObjectMapper to handle JSON Serialization errors (avoid empty object errors).\n- Write Unit Tests for Service layer. 25/11/2025 25/11/2025 4 - Configure BedrockRuntimeClient in Java.\n- Write improveWithAI Service: Send raw text -\u0026gt; Receive improved text.\n- Perform Prompt Engineering to optimize results from Claude 3.\n- Handle Exceptions and Timeouts when calling AI. 26/11/2025 26/11/2025 5 - CoverLetter: Write Prompt to create cover letter based on JD and Profile.\n- Interview: Write logic to generate multiple-choice questions (Generate Quiz).\n- Interview: Handle Prompt to ensure AI returns correct JSON Array format.\n- Interview: Write logic to save scores (Save Result) into DynamoDB. 27/11/2025 27/11/2025 6 - Build IndustryInsightFunction (Optional - Cache strategy).\n- Review and Refactor code (Clean Code).\n- Build entire project (mvn clean package).\n- Run sam deploy to push entire Backend to AWS.\n- Test all API Endpoints via Postman/Curl. 28/11/2025 28/11/2025 Week 12 Achievements: 5 Lambda Functions operating stably on AWS. API Gateway has exposed necessary endpoints. Successfully integrated Amazon Bedrock to generate CV content, Cover Letter, and Quiz. Data stored and retrieved accurately from DynamoDB. Resolved errors related to JSON Serialization in Serverless environment. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/1-worklog/1.13-week13/","title":"Worklog Week 13","tags":[],"description":"","content":"Week 13 Objectives: Build complete React Frontend with Vite, Tailwind CSS, and Shadcn UI. Integrate AWS Amplify to handle Login/Registration. Connect Frontend with Backend API Gateway (Integration). Finalize core features: Resume Builder, Quiz Game, Dashboard. Build, Deploy Frontend to S3/CloudFront and test the entire system (UAT). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Install Tailwind CSS, Shadcn UI components (Button, Card, Input\u0026hellip;).\n- Configure AWS Amplify (Amplify.configure) with UserPoolId from Backend.\n- Create Login/Register page using Authenticator component.\n- Create Main Layout (Sidebar, Header, Protected Routes). 01/12/2025 01/12/2025 AWS Amplify UI Documentation 3 - Code Dashboard page: Fetch history data and display statistics.\n- Code Resume Builder page: Integrate Markdown Editor (@uiw/react-md-editor).\n- Build CV input Form with React Hook Form \u0026amp; Zod Validation.\n- Integrate PDF export feature (html2pdf.js). 02/12/2025 02/12/2025 React Hook Form Documentation 4 - Write apiClient wrapper: Automatically attach Token and handle \u0026ldquo;Double JSON parsing\u0026rdquo;.\n- Connect \u0026ldquo;Improve with AI\u0026rdquo; button in Resume Builder with Backend API.\n- Build Cover Letter Generator interface: JD Input Form -\u0026gt; Display AI result.\n- Handle loading state (Skeleton/Spinner) while waiting for AI response. 03/12/2025 03/12/2025 5 - Code quiz interface (Radio buttons).\n- Handle scoring logic and display correct/incorrect results (String comparison logic).\n- Draw Performance Chart using Recharts.\n- Review overall interface, fix CSS errors, Mobile Responsive. 04/12/2025 04/12/2025 6 - Run npm run build to package Frontend.\n- Sync code to S3 (aws s3 sync).\n- Invalidate CloudFront Cache to update latest code.\n- Perform End-to-End Testing on Production environment. 05/12/2025 05/12/2025 Week 13 Achievements: Complete AI Career Coach website, operating smoothly on the Internet environment. Users can log in, create CV, write Cover Letter, and practice interviewing. Frontend successfully connected with Serverless Backend and AI Bedrock. System partially deployed automatically via CLI. Ready for demo. "},{"uri":"https://duykhanh07.github.io/workshop-fcaj/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://duykhanh07.github.io/workshop-fcaj/tags/","title":"Tags","tags":[],"description":"","content":""}]